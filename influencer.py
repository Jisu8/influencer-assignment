import streamlit as st
import pandas as pd
import numpy as np
import os
import time
import io
import subprocess
from datetime import datetime, timedelta
import requests
import json
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Snowflake ì—°ê²° (ì„ íƒì )
try:
    import snowflake.connector
    SNOWFLAKE_AVAILABLE = True
except ImportError:
    SNOWFLAKE_AVAILABLE = False

# í™˜ê²½ ê°ì§€ í•¨ìˆ˜
def is_running_on_streamlit_cloud():
    """Streamlit Cloudì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    cloud_indicators = [
        'STREAMLIT_SERVER_HEADLESS',
        'STREAMLIT_SERVER_PORT',
        'STREAMLIT_SERVER_ADDRESS',
        'STREAMLIT_CLOUD_ENVIRONMENT',
        'STREAMLIT_SERVER_RUN_ON_SAVE',
        'STREAMLIT_SERVER_FILE_WATCHER_TYPE'
    ]
    
    cloud_path_indicators = [
        '/app',
        '/home/appuser',
        '/opt/streamlit'
    ]
    
    env_check = any(os.environ.get(indicator) for indicator in cloud_indicators)
    path_check = any(os.path.exists(path) for path in cloud_path_indicators)
    
    return env_check or path_check

# =============================================================================
# íŒŒì¼ ê²½ë¡œ ì„¤ì •
# =============================================================================

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(SCRIPT_DIR, "data")

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ
ASSIGNMENT_FILE = os.path.join(DATA_DIR, "assignment_history.csv")
EXECUTION_FILE = os.path.join(DATA_DIR, "execution_data.csv")
INFLUENCER_FILE = os.path.join(DATA_DIR, "influencer.csv")
SALES_FILE = os.path.join(DATA_DIR, "sales_data.csv")
SEARCH_FILE = os.path.join(DATA_DIR, "search_data.csv")
MONTHLY_TARGETS_FILE = os.path.join(DATA_DIR, "monthly_assignment_targets.csv")
SEARCH_QUERY_FILE = os.path.join(DATA_DIR, "search_query.sql")
SALES_QUERY_FILE = os.path.join(DATA_DIR, "sales_query.sql")

# ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(DATA_DIR, exist_ok=True)

# ìƒìˆ˜ ì •ì˜
BRANDS = ["MLB", "DX", "DV", "ST"]
BRAND_OPTIONS = ["ì „ì²´"] + BRANDS
MONTHS = ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"]

# ì‹œì¦Œë³„ ì›” ë§¤í•‘
SEASON_MONTHS = {
    "25FW": ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"],
    "25SS": ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"],
    "26SS": ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"]
}

# =============================================================================
# ë°ì´í„° ë¡œë“œ ë° ì €ì¥ í•¨ìˆ˜ë“¤
# =============================================================================

@st.cache_data
def load_influencer_data():
    """ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(INFLUENCER_FILE):
        return pd.read_csv(INFLUENCER_FILE)
    return pd.DataFrame()

@st.cache_data
def load_assignment_history():
    """ë°°ì • ì´ë ¥ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(ASSIGNMENT_FILE):
        return pd.read_csv(ASSIGNMENT_FILE)
    return pd.DataFrame()

@st.cache_data
def load_execution_data():
    """ì§‘í–‰ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(EXECUTION_FILE):
        return pd.read_csv(EXECUTION_FILE)
    return pd.DataFrame()

@st.cache_data
def load_sales_data():
    """ë§¤ì¶œ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(SALES_FILE):
        df = pd.read_csv(SALES_FILE)
        
        # ì˜ëª»ëœ ë‚ ì§œ ë°ì´í„° í•„í„°ë§
        if 'DT' in df.columns:
            df['DT'] = pd.to_datetime(df['DT'])
            current_year = pd.Timestamp.now().year
            
            # í˜„ì‹¤ì ì¸ ë‚ ì§œë§Œ ìœ ì§€ (í˜„ì¬ ì—°ë„ + 1ë…„ê¹Œì§€ë§Œ)
            df = df[df['DT'].dt.year <= current_year + 1]
            
            # 1900ë…„ ì´ì „ì˜ ë°ì´í„°ë„ ì œê±°
            df = df[df['DT'].dt.year >= 1900]
        
        return df
    return pd.DataFrame()

def load_influencer_data():
    """ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(INFLUENCER_FILE):
        return pd.read_csv(INFLUENCER_FILE)
    return pd.DataFrame()

def load_assignment_history():
    """ë°°ì • ì´ë ¥ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(ASSIGNMENT_FILE):
        return pd.read_csv(ASSIGNMENT_FILE)
    return pd.DataFrame()

def save_assignment_history(df):
    """ë°°ì • ì´ë ¥ ë°ì´í„° ì €ì¥"""
    df.to_csv(ASSIGNMENT_FILE, index=False, encoding='utf-8-sig')

def load_monthly_targets():
    """ì›”ë³„ ë°°ì • ëª©í‘œ ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(MONTHLY_TARGETS_FILE):
        return pd.read_csv(MONTHLY_TARGETS_FILE)
    return pd.DataFrame()

def save_monthly_targets(df):
    """ì›”ë³„ ë°°ì • ëª©í‘œ ë°ì´í„° ì €ì¥"""
    df.to_csv(MONTHLY_TARGETS_FILE, index=False, encoding='utf-8-sig')


def save_assignment_history(df):
    """ë°°ì • ì´ë ¥ ë°ì´í„° ì €ì¥"""
    df.to_csv(ASSIGNMENT_FILE, index=False, encoding='utf-8-sig')
    st.cache_data.clear()

def save_execution_data(df):
    """ì§‘í–‰ ë°ì´í„° ì €ì¥"""
    df.to_csv(EXECUTION_FILE, index=False, encoding='utf-8-sig')
    st.cache_data.clear()

def save_sales_data(df):
    """ë§¤ì¶œ ë°ì´í„° ì €ì¥"""
    df.to_csv(SALES_FILE, index=False, encoding='utf-8-sig')
    st.cache_data.clear()

def save_monthly_targets(df):
    """ì›”ë³„ ë°°ì • ëª©í‘œ ë°ì´í„° ì €ì¥"""
    df.to_csv(MONTHLY_TARGETS_FILE, index=False, encoding='utf-8-sig')
    st.cache_data.clear()

# =============================================================================
# ëŒ€ì‹œë³´ë“œ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

def render_dashboard_tab():
    """ëŒ€ì‹œë³´ë“œ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ“Š ëŒ€ì‹œë³´ë“œ")
    
    # ë°ì´í„° ë¡œë“œ
    execution_df = load_execution_data()
    sales_df = load_sales_data()
    
    if execution_df.empty:
        st.warning("ì§‘í–‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¸í”Œë£¨ì–¸ì„œ ë…¸ì¶œëŸ‰ ë°ì´í„°ì™€ ì—°ê³„ ë¶„ì„
    st.markdown("## ğŸ“Š ë§¤ì¶œ ì—°ê³„ ë¶„ì„")
    
    # ë¸Œëœë“œ, ì•„ì´í…œ, ì‹œì¦Œ, ê¸°ê°„ í•„í„° ì¶”ê°€
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("#### ğŸ·ï¸ ë¸Œëœë“œ")
        # ë¸Œëœë“œ ë§¤í•‘ ì„¤ì •
        brand_mapping = {
            'MLB': 'M',
            'DX': 'X', 
            'DV': 'V',
            'ST': 'ST'
        }
        
        # ì§‘í–‰ ë°ì´í„°ì—ì„œ ë¸Œëœë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (MLB ìš°ì„ ìˆœìœ„)
        if 'ë¸Œëœë“œ' in execution_df.columns:
            available_brands = execution_df['ë¸Œëœë“œ'].unique().tolist()
            # MLBë¥¼ ì²« ë²ˆì§¸ë¡œ ì •ë ¬
            if 'MLB' in available_brands:
                available_brands.remove('MLB')
                available_brands = ['MLB'] + available_brands
        else:
            available_brands = []
            
        selected_brand = st.selectbox(
            "ë¶„ì„í•  ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", 
            options=available_brands,
            index=0,
            key="brand_filter_trend"
        )
    
    with col2:
        st.markdown("#### ğŸ“¦ ì•„ì´í…œ")
        # ë§¤ì¶œ ë°ì´í„°ì—ì„œ ì•„ì´í…œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        if 'ITEM' in sales_df.columns:
            available_items = sales_df['ITEM'].unique().tolist()
        else:
            available_items = []
            
        selected_item = st.selectbox(
            "ë¶„ì„í•  ì•„ì´í…œì„ ì„ íƒí•˜ì„¸ìš”", 
            options=["ì „ì²´"] + available_items,
            index=0,
            key="item_filter_trend"
        )
    
    with col3:
        st.markdown("#### ğŸŒŸ ì‹œì¦Œ")
        # ì‹œì¦Œ í•„í„° ì˜µì…˜
        season_options = ["ì „ì²´", "24FW", "25SS", "25FW"]
        selected_season = st.selectbox(
            "ë¶„ì„í•  ì‹œì¦Œì„ ì„ íƒí•˜ì„¸ìš”",
            options=season_options,
            index=0,
            key="season_filter_trend"
        )
    
    with col4:
        st.markdown("#### ğŸ“… ê¸°ê°„ ì„ íƒ")
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì • (ë§¤ì¶œ ë°ì´í„°ì™€ ì§‘í–‰ ë°ì´í„° ëª¨ë‘ ê³ ë ¤)
        all_dates = []
        
        # ë§¤ì¶œ ë°ì´í„°ì—ì„œ ë‚ ì§œ ìˆ˜ì§‘
        if not sales_df.empty and 'DT' in sales_df.columns:
            try:
                sales_df['DT'] = pd.to_datetime(sales_df['DT'], errors='coerce')
                sales_dates = sales_df['DT'].dropna()
                all_dates.extend(sales_dates.tolist())
            except Exception as e:
                st.warning(f"ë§¤ì¶œ ë°ì´í„° ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì§‘í–‰ ë°ì´í„°ì—ì„œ ë‚ ì§œ ìˆ˜ì§‘
        execution_df = load_execution_data()
        if not execution_df.empty:
            # ì§‘í–‰ ë°ì´í„°ì˜ ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
            date_columns = ['ì—…ë¡œë“œì¼', 'DT', 'ë‚ ì§œ', 'date']
            for date_col in date_columns:
                if date_col in execution_df.columns:
                    try:
                        execution_df[date_col] = pd.to_datetime(execution_df[date_col], errors='coerce')
                        exec_dates = execution_df[date_col].dropna()
                        all_dates.extend(exec_dates.tolist())
                        break
                    except Exception as e:
                        continue
        
        if all_dates:
            try:
                all_dates = pd.to_datetime(all_dates, errors='coerce').dropna()
                
                # ìœ íš¨í•œ ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ (1900ë…„ ì´ì „ê³¼ 2030ë…„ ì´í›„ ì œì™¸)
                valid_dates = all_dates[
                    (all_dates >= pd.to_datetime('2020-01-01')) & 
                    (all_dates <= pd.to_datetime('2030-12-31'))
                ]
                
                if len(valid_dates) > 0:
                    # ì‹œì¦Œ ì„ íƒì— ë”°ë¥¸ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
                    if selected_season == "24FW":
                        season_min = pd.to_datetime('2024-09-01')
                        season_max = pd.to_datetime('2025-02-28')
                    elif selected_season == "25SS":
                        season_min = pd.to_datetime('2025-03-01')
                        season_max = pd.to_datetime('2025-08-31')
                    elif selected_season == "25FW":
                        season_min = pd.to_datetime('2025-09-01')
                        season_max = pd.to_datetime('2026-02-28')
                    else:
                        # ì „ì²´ ì„ íƒ ì‹œ ëª¨ë“  ë°ì´í„° ë²”ìœ„ ì‚¬ìš©
                        season_min = valid_dates.min()
                        season_max = valid_dates.max()
                    
                    # ì‹œì¦Œ ë²”ìœ„ì™€ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì˜ êµì§‘í•©
                    min_date = max(season_min, valid_dates.min())
                    max_date = min(season_max, valid_dates.max())
                    
                    # ë‚ ì§œ ìŠ¬ë¼ì´ë”
                    date_range = st.slider(
                        "ë¶„ì„í•  ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”",
                        min_value=min_date.date(),
                        max_value=max_date.date(),
                        value=(min_date.date(), max_date.date()),
                        format="YYYY-MM-DD",
                        key="date_range_slider_trend"
                    )
                    
                else:
                    st.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    date_range = None
            except Exception as e:
                st.error(f"ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                date_range = None
        else:
            st.warning("ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            date_range = None
    
    if not sales_df.empty and 'ITEM' in sales_df.columns and not execution_df.empty:
        # ë§ˆì¼€íŒ… ë°ì´í„°ë„ ë¡œë“œ
        marketing_df = load_marketing_data()
        
        # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ì—ì„œ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°
        influencer_exposure_col = None
        influencer_date_col = None
        
        for col in execution_df.columns:
            if 'ë…¸ì¶œìˆ˜' in col:
                influencer_exposure_col = col
            if 'ì—…ë¡œë“œì¼' in col or 'ë‚ ì§œ' in col or 'DT' in col:
                influencer_date_col = col
        
        # ë§ˆì¼€íŒ… ë°ì´í„°ì—ì„œ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°
        marketing_exposure_col = None
        marketing_date_col = None
        
        if not marketing_df.empty:
            for col in marketing_df.columns:
                if 'ë…¸ì¶œìˆ˜' in col:
                    marketing_exposure_col = col
                if 'ì—…ë¡œë“œì¼' in col or 'ë‚ ì§œ' in col or 'DT' in col:
                    marketing_date_col = col
        
        if influencer_exposure_col and influencer_date_col:
            # ì§‘í–‰ ë°ì´í„° ì¼ìë³„ ë…¸ì¶œìˆ˜ ì§‘ê³„
            execution_df_copy = execution_df.copy()
            
            # ì§‘í–‰ ë°ì´í„°ì™€ ë§ˆì¼€íŒ… ë°ì´í„°ì˜ ë…¸ì¶œìˆ˜ë¥¼ í•©ì¹˜ê¸°
            all_exposure_data = []
            
            # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì²˜ë¦¬
            try:
                influencer_df_copy = execution_df.copy()
                influencer_df_copy[influencer_date_col] = pd.to_datetime(influencer_df_copy[influencer_date_col], errors='coerce')
                influencer_df_copy = influencer_df_copy.dropna(subset=[influencer_date_col])
                
                if not influencer_df_copy.empty:
                    influencer_exposure = influencer_df_copy.groupby(influencer_date_col)[influencer_exposure_col].sum().reset_index()
                    influencer_exposure.columns = ['DT', 'ë…¸ì¶œìˆ˜']
                    all_exposure_data.append(influencer_exposure)
            except Exception as e:
                st.warning(f"ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ë§ˆì¼€íŒ… ë°ì´í„° ì²˜ë¦¬
            if marketing_exposure_col and marketing_date_col and not marketing_df.empty:
                try:
                    marketing_df_copy = marketing_df.copy()
                    marketing_df_copy[marketing_date_col] = pd.to_datetime(marketing_df_copy[marketing_date_col], errors='coerce')
                    marketing_df_copy = marketing_df_copy.dropna(subset=[marketing_date_col])
                    
                    # ë§ˆì¼€íŒ… ë°ì´í„°ì—ë„ ì‹œì¦Œ í•„í„° ì ìš©
                    if selected_season != "ì „ì²´":
                        if selected_season == "24FW":
                            season_start = pd.to_datetime('2024-09-01')
                            season_end = pd.to_datetime('2025-02-28')
                        elif selected_season == "25SS":
                            season_start = pd.to_datetime('2025-03-01')
                            season_end = pd.to_datetime('2025-08-31')
                        elif selected_season == "25FW":
                            season_start = pd.to_datetime('2025-09-01')
                            season_end = pd.to_datetime('2026-02-28')
                        else:
                            season_start = None
                            season_end = None
                        
                        if season_start and season_end:
                            marketing_df_copy = marketing_df_copy[
                                (marketing_df_copy[marketing_date_col] >= season_start) & 
                                (marketing_df_copy[marketing_date_col] <= season_end)
                            ]
                    
                    # ê¸°ê°„ í•„í„° ì ìš© (ë§ˆì¼€íŒ… ë°ì´í„°)
                    if date_range:
                        start_date = pd.to_datetime(date_range[0])
                        end_date = pd.to_datetime(date_range[1])
                        marketing_df_copy = marketing_df_copy[
                            (marketing_df_copy[marketing_date_col] >= start_date) & 
                            (marketing_df_copy[marketing_date_col] <= end_date)
                        ]
                    
                    if not marketing_df_copy.empty:
                        marketing_exposure = marketing_df_copy.groupby(marketing_date_col)[marketing_exposure_col].sum().reset_index()
                        marketing_exposure.columns = ['DT', 'ë…¸ì¶œìˆ˜']
                        all_exposure_data.append(marketing_exposure)
                except Exception as e:
                    st.warning(f"ë§ˆì¼€íŒ… ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ë°ì´í„° ì²˜ë¦¬
            if all_exposure_data:
                # ëª¨ë“  ë°ì´í„°ë¥¼ í•©ì¹˜ê³  ìœ í˜•ë³„ë¡œ ë¶„ë¦¬
                all_data = []
                
                # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì²˜ë¦¬
                if not execution_df.empty and 'ìœ í˜•' in execution_df.columns:
                    execution_df_copy = execution_df.copy()
                    execution_df_copy[influencer_date_col] = pd.to_datetime(execution_df_copy[influencer_date_col], errors='coerce')
                    execution_df_copy = execution_df_copy.dropna(subset=[influencer_date_col])
                    
                    # ì‹œì¦Œ í•„í„° ì ìš©
                    if selected_season != "ì „ì²´":
                        if selected_season == "24FW":
                            season_start = pd.to_datetime('2024-09-01')
                            season_end = pd.to_datetime('2025-02-28')
                        elif selected_season == "25SS":
                            season_start = pd.to_datetime('2025-03-01')
                            season_end = pd.to_datetime('2025-08-31')
                        elif selected_season == "25FW":
                            season_start = pd.to_datetime('2025-09-01')
                            season_end = pd.to_datetime('2026-02-28')
                        else:
                            season_start = None
                            season_end = None
                        
                        if season_start and season_end:
                            execution_df_copy = execution_df_copy[
                                (execution_df_copy[influencer_date_col] >= season_start) & 
                                (execution_df_copy[influencer_date_col] <= season_end)
                            ]
                    
                    # ê¸°ê°„ í•„í„° ì ìš©
                    if date_range:
                        start_date = pd.to_datetime(date_range[0])
                        end_date = pd.to_datetime(date_range[1])
                        execution_df_copy = execution_df_copy[
                            (execution_df_copy[influencer_date_col] >= start_date) & 
                            (execution_df_copy[influencer_date_col] <= end_date)
                        ]
                    
                    if not execution_df_copy.empty:
                        all_data.append(execution_df_copy)
                
                # ë§ˆì¼€íŒ… ë°ì´í„° ì²˜ë¦¬
                if not marketing_df.empty and 'ìœ í˜•' in marketing_df.columns:
                    marketing_df_copy = marketing_df.copy()
                    marketing_df_copy[marketing_date_col] = pd.to_datetime(marketing_df_copy[marketing_date_col], errors='coerce')
                    marketing_df_copy = marketing_df_copy.dropna(subset=[marketing_date_col])
                    
                    # ì‹œì¦Œ í•„í„° ì ìš©
                    if selected_season != "ì „ì²´":
                        if selected_season == "24FW":
                            season_start = pd.to_datetime('2024-09-01')
                            season_end = pd.to_datetime('2025-02-28')
                        elif selected_season == "25SS":
                            season_start = pd.to_datetime('2025-03-01')
                            season_end = pd.to_datetime('2025-08-31')
                        elif selected_season == "25FW":
                            season_start = pd.to_datetime('2025-09-01')
                            season_end = pd.to_datetime('2026-02-28')
                        else:
                            season_start = None
                            season_end = None
                        
                        if season_start and season_end:
                            marketing_df_copy = marketing_df_copy[
                                (marketing_df_copy[marketing_date_col] >= season_start) & 
                                (marketing_df_copy[marketing_date_col] <= season_end)
                            ]
                    
                    # ê¸°ê°„ í•„í„° ì ìš©
                    if date_range:
                        start_date = pd.to_datetime(date_range[0])
                        end_date = pd.to_datetime(date_range[1])
                        marketing_df_copy = marketing_df_copy[
                            (marketing_df_copy[marketing_date_col] >= start_date) & 
                            (marketing_df_copy[marketing_date_col] <= end_date)
                        ]
                    
                    if not marketing_df_copy.empty:
                        all_data.append(marketing_df_copy)
                
                if all_data:
                    # ëª¨ë“  ë°ì´í„°ë¥¼ í•©ì¹˜ê³  ìœ í˜•ë³„ë¡œ ë…¸ì¶œìˆ˜ ì§‘ê³„
                    combined_data = pd.concat(all_data, ignore_index=True)
                    
                    # ìœ í˜•ë³„ë¡œ ë…¸ì¶œìˆ˜ ì§‘ê³„
                    exposure_by_type = {}
                    for _, row in combined_data.iterrows():
                        date_val = row.get(influencer_date_col) if influencer_date_col in row else row.get(marketing_date_col)
                        exposure_val = row.get(influencer_exposure_col) if influencer_exposure_col in row else row.get(marketing_exposure_col)
                        type_val = row.get('ìœ í˜•', 'ê¸°íƒ€')
                        
                        if pd.notna(date_val) and pd.notna(exposure_val):
                            date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
                            if date_str not in exposure_by_type:
                                exposure_by_type[date_str] = {}
                            if type_val not in exposure_by_type[date_str]:
                                exposure_by_type[date_str][type_val] = 0
                            exposure_by_type[date_str][type_val] += float(exposure_val)
                    
                    # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    type_dataframes = {}
                    for date_str, types in exposure_by_type.items():
                        for type_name, exposure_val in types.items():
                            if type_name not in type_dataframes:
                                type_dataframes[type_name] = []
                            type_dataframes[type_name].append({
                                'DT': pd.to_datetime(date_str),
                                f'{type_name}_ë…¸ì¶œìˆ˜': exposure_val
                            })
                    
                    # ê° ìœ í˜•ë³„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    daily_exposure = None
                    for type_name, data_list in type_dataframes.items():
                        type_df = pd.DataFrame(data_list)
                        if daily_exposure is None:
                            daily_exposure = type_df
                        else:
                            daily_exposure = pd.merge(daily_exposure, type_df, on='DT', how='outer').fillna(0)
                else:
                    st.warning("ë…¸ì¶œìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return
            else:
                st.warning("ë…¸ì¶œìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # í•„í„° ì ìš©ëœ ë§¤ì¶œ ë°ì´í„° ì¤€ë¹„
            filtered_sales_df = sales_df.copy()
            
            # ë¸Œëœë“œ í•„í„° ì ìš©
            if selected_brand != "ì „ì²´":
                brand_code = brand_mapping.get(selected_brand, selected_brand)
                if 'BRD_CD' in filtered_sales_df.columns:
                    filtered_sales_df = filtered_sales_df[filtered_sales_df['BRD_CD'] == brand_code]
            
            # ì•„ì´í…œ í•„í„° ì ìš©
            if selected_item != "ì „ì²´":
                filtered_sales_df = filtered_sales_df[filtered_sales_df['ITEM'] == selected_item]
            
            # ì‹œì¦Œ í•„í„° ì ìš©
            if selected_season != "ì „ì²´":
                if selected_season == "24FW":
                    season_start = pd.to_datetime('2024-09-01')
                    season_end = pd.to_datetime('2025-02-28')
                elif selected_season == "25SS":
                    season_start = pd.to_datetime('2025-03-01')
                    season_end = pd.to_datetime('2025-08-31')
                elif selected_season == "25FW":
                    season_start = pd.to_datetime('2025-09-01')
                    season_end = pd.to_datetime('2026-02-28')
                else:
                    season_start = None
                    season_end = None
                
                if season_start and season_end:
                    filtered_sales_df = filtered_sales_df[
                        (filtered_sales_df['DT'] >= season_start) & 
                        (filtered_sales_df['DT'] <= season_end)
                    ]
            
            # ê¸°ê°„ í•„í„° ì ìš© (ì‹œì¦Œ í•„í„°ì™€ í•¨ê»˜ ì ìš©)
            if date_range:
                start_date = pd.to_datetime(date_range[0])
                end_date = pd.to_datetime(date_range[1])
                filtered_sales_df = filtered_sales_df[
                    (filtered_sales_df['DT'] >= start_date) & 
                    (filtered_sales_df['DT'] <= end_date)
                ]
            
            # í•„í„°ë§ëœ ë§¤ì¶œ ë°ì´í„° ì¼ìë³„ ì§‘ê³„
            if not filtered_sales_df.empty:
                daily_sales = filtered_sales_df.groupby('DT').agg({
                    'SALE_AMT_TY': 'sum'
                }).reset_index()
                daily_sales['DT'] = pd.to_datetime(daily_sales['DT'])
            else:
                daily_sales = pd.DataFrame(columns=['DT', 'SALE_AMT_TY'])
            
            # ì§‘í–‰ ë°ì´í„°ë„ ë¸Œëœë“œ í•„í„° ì ìš©
            filtered_execution_df = execution_df_copy.copy()
            if selected_brand != "ì „ì²´":
                filtered_execution_df = filtered_execution_df[filtered_execution_df['ë¸Œëœë“œ'] == selected_brand]
            
            # ì‹œì¦Œ í•„í„° ì ìš© (ì§‘í–‰ ë°ì´í„°)
            if selected_season != "ì „ì²´":
                if selected_season == "24FW":
                    season_start = pd.to_datetime('2024-09-01')
                    season_end = pd.to_datetime('2025-02-28')
                elif selected_season == "25SS":
                    season_start = pd.to_datetime('2025-03-01')
                    season_end = pd.to_datetime('2025-08-31')
                elif selected_season == "25FW":
                    season_start = pd.to_datetime('2025-09-01')
                    season_end = pd.to_datetime('2026-02-28')
                else:
                    season_start = None
                    season_end = None
                
                if season_start and season_end:
                    filtered_execution_df = filtered_execution_df[
                        (filtered_execution_df[date_col] >= season_start) & 
                        (filtered_execution_df[date_col] <= season_end)
                    ]
            
            # ê¸°ê°„ í•„í„° ì ìš© (ì§‘í–‰ ë°ì´í„°)
            if date_range:
                filtered_execution_df = filtered_execution_df[
                    (filtered_execution_df[date_col] >= start_date) & 
                    (filtered_execution_df[date_col] <= end_date)
                ]
            
            # ë§¤ì¶œ ë°ì´í„°ì™€ ë…¸ì¶œëŸ‰ ë°ì´í„° ë³‘í•©
            combined_df = pd.merge(daily_sales, daily_exposure, on='DT', how='outer').fillna(0)
            combined_df = combined_df.sort_values('DT')
            
            if not combined_df.empty:
                # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                if len(combined_df) < 2:
                    st.info("ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ê¸°ì—ëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”)")
                    return
                
                # NaN ê°’ ì²˜ë¦¬
                combined_df = combined_df.fillna(0)
                
                
                
                # ì „ì²´ ì•„ì´í…œ ì‚¬ìš© (ë¸Œëœë“œ í•„í„°ê°€ ì ìš©ëœ ë°ì´í„°ì—ì„œ)
                if not filtered_sales_df.empty and 'ITEM' in filtered_sales_df.columns:
                    available_items = filtered_sales_df['ITEM'].unique()
                    selected_items = list(available_items)
                else:
                    selected_items = []
                    # ë¸Œëœë“œ í•„í„°ë¡œ ì¸í•´ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
                    st.warning(f"ì„ íƒëœ ë¸Œëœë“œ '{selected_brand}'ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                if selected_items:
                    # ì„ íƒëœ ì•„ì´í…œìœ¼ë¡œ ë§¤ì¶œ ë°ì´í„° í•„í„°ë§ (ë¸Œëœë“œ í•„í„°ê°€ ì´ë¯¸ ì ìš©ëœ ë°ì´í„° ì‚¬ìš©)
                    filtered_sales_by_item = filtered_sales_df[filtered_sales_df['ITEM'].isin(selected_items)]
                    
                    if not filtered_sales_by_item.empty:
                        # ì„ íƒëœ ì•„ì´í…œì˜ ì¼ìë³„ ë§¤ì¶œ ë°ì´í„° ì§‘ê³„
                        daily_sales_by_item = filtered_sales_by_item.groupby('DT').agg({
                            'SALE_AMT_TY': 'sum',
                            'SALE_AMT_LY': 'sum'  # ì „ë…„ ë°ì´í„°ë„ í¬í•¨
                        }).reset_index()
                        daily_sales_by_item['DT'] = pd.to_datetime(daily_sales_by_item['DT'])
                        
                        # ì „ë…„ ë°ì´í„° ì²˜ë¦¬ (YoY ë¹„êµìš©)
                        daily_sales_ly = None
                        if 'SALE_AMT_LY' in daily_sales_by_item.columns and not daily_sales_by_item['SALE_AMT_LY'].isna().all():
                            # ì „ë…„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° - í˜„ì¬ ë‚ ì§œì— ì „ë…„ ë°ì´í„°ë¥¼ ë§¤ì¹­
                            daily_sales_ly = daily_sales_by_item[['DT', 'SALE_AMT_LY']].copy()
                            # ì „ë…„ ë°ì´í„°ëŠ” í˜„ì¬ ë‚ ì§œì— ê·¸ëŒ€ë¡œ í‘œì‹œ (1ë…„ ì „ ë°ì´í„°ë¥¼ í˜„ì¬ ë‚ ì§œì— í‘œì‹œ)
                            # ë‚ ì§œëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  ì „ë…„ ë§¤ì¶œì•¡ë§Œ ì‚¬ìš©
                        else:
                            st.warning("ì „ë…„ ë°ì´í„°(SALE_AMT_LY)ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ê¸°ê°„ í•„í„°ë§ ì œê±° (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
                        filtered_sales_by_item_period = daily_sales_by_item.copy()
                        filtered_exposure_period = daily_exposure.copy()
                        
                        # ë§¤ì¶œ ë°ì´í„°ì™€ ë…¸ì¶œëŸ‰ ë°ì´í„° ë³‘í•© (ì„ íƒëœ ì•„ì´í…œ ê¸°ì¤€)
                        combined_df_item = pd.merge(filtered_sales_by_item_period, filtered_exposure_period, on='DT', how='outer').fillna(0)
                        combined_df_item = combined_df_item.sort_values('DT')
                        
                        if not combined_df_item.empty:
                            # NaN ê°’ ì²˜ë¦¬
                            combined_df_item = combined_df_item.fillna(0)
                            
                            # êº¾ì€ì„ ê·¸ë˜í”„ ìƒì„±
                            try:
                                fig_trend = go.Figure()
                                
                                # ë§¤ì¶œì•¡ ë¼ì¸ (ì¢Œì¸¡ Yì¶•)
                                fig_trend.add_trace(go.Scatter(
                                    x=combined_df_item['DT'],
                                    y=combined_df_item['SALE_AMT_TY'],
                                    mode='lines+markers',
                                    name='ë‹¹í•´ë§¤ì¶œì•¡',
                                    line=dict(color='blue', width=3),
                                    yaxis='y1',
                                    zorder=3  # ë§‰ëŒ€ê·¸ë˜í”„ë³´ë‹¤ ì•ì— í‘œì‹œ
                                ))
                                
                                # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
                                if daily_sales_ly is not None and not daily_sales_ly.empty:
                                    fig_trend.add_trace(go.Scatter(
                                        x=daily_sales_ly['DT'],
                                        y=daily_sales_ly['SALE_AMT_LY'],
                                        mode='lines+markers',
                                        name='ì „ë…„ë§¤ì¶œì•¡',
                                        line=dict(color='gray', width=2, dash='dash'),
                                        yaxis='y1',
                                        zorder=2  # ë§‰ëŒ€ê·¸ë˜í”„ë³´ë‹¤ ì•ì— í‘œì‹œ
                                    ))
                                
                                # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ìŠ¤íƒí˜• ë§‰ëŒ€ê·¸ë˜í”„ (ìš°ì¸¡ Yì¶•)
                                # ìœ í˜•ë³„ ìƒ‰ìƒ ë§¤í•‘
                                type_colors = {
                                    'ì¸í”Œë£¨ì–¸ì„œ': '#1f77b4',  # íŒŒë€ìƒ‰
                                    'ë§ˆì¼€íŒ…': '#ff7f0e',      # ì£¼í™©ìƒ‰
                                    'ë§¤ì²´SNS': '#2ca02c',    # ì´ˆë¡ìƒ‰
                                    'SEO': '#9467bd',        # ë³´ë¼ìƒ‰
                                    'ìì‚¬IG': '#8c564b',     # ê°ˆìƒ‰
                                    'ì…€ë²”': '#e377c2',       # ë¶„í™ìƒ‰
                                    'ê¸°íƒ€': '#d62728'        # ë¹¨ê°„ìƒ‰
                                }
                                
                                # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°
                                exposure_columns = [col for col in combined_df_item.columns if col.endswith('_ë…¸ì¶œìˆ˜')]
                                
                                if exposure_columns:
                                    # ìŠ¤íƒí˜• ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ìœ„í•´ ê° ìœ í˜•ë³„ë¡œ ë³„ë„ trace ìƒì„±
                                    for col in exposure_columns:
                                        type_name = col.replace('_ë…¸ì¶œìˆ˜', '')
                                        color = type_colors.get(type_name, '#808080')  # ê¸°ë³¸ íšŒìƒ‰
                                        
                                        fig_trend.add_trace(go.Bar(
                                            x=combined_df_item['DT'],
                                            y=combined_df_item[col],
                                            name=f'{type_name}',
                                            marker=dict(color=color, opacity=1.0),
                                            yaxis='y2',
                                            zorder=1  # ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ë’¤ì— í‘œì‹œ
                                        ))
                                else:
                                    # ê¸°ì¡´ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš© (ìœ í˜•ë³„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
                                    if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns:
                                        fig_trend.add_trace(go.Bar(
                                            x=combined_df_item['DT'],
                                            y=combined_df_item['ë…¸ì¶œìˆ˜'],
                                            name='ë…¸ì¶œìˆ˜',
                                            marker=dict(color='gray', opacity=0.7),
                                            yaxis='y2',
                                            zorder=1  # ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ë’¤ì— í‘œì‹œ
                                        ))
                                
                                # Xì¶• ë²”ìœ„ ì„¤ì • (ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê¸°ê°„ë§Œ í‘œì‹œ)
                                x_range = None
                                if selected_season != "ì „ì²´":
                                    # ì‹œì¦Œ ì„ íƒ ì‹œ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ë¡œ Xì¶• ì„¤ì •
                                    if not combined_df_item.empty:
                                        # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
                                        data_dates = pd.to_datetime(combined_df_item['DT'])
                                        min_data_date = data_dates.min()
                                        max_data_date = data_dates.max()
                                        
                                        # ì‹œì¦Œ ë²”ìœ„ì™€ ë°ì´í„° ë²”ìœ„ì˜ êµì§‘í•©
                                        if selected_season == "24FW":
                                            season_start = pd.to_datetime('2024-09-01')
                                            season_end = pd.to_datetime('2025-02-28')
                                        elif selected_season == "25SS":
                                            season_start = pd.to_datetime('2025-03-01')
                                            season_end = pd.to_datetime('2025-08-31')
                                        elif selected_season == "25FW":
                                            season_start = pd.to_datetime('2025-09-01')
                                            season_end = pd.to_datetime('2026-02-28')
                                        else:
                                            season_start = min_data_date
                                            season_end = max_data_date
                                        
                                        # ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì™€ ì‹œì¦Œ ë²”ìœ„ì˜ êµì§‘í•©
                                        actual_start = max(min_data_date, season_start)
                                        actual_end = min(max_data_date, season_end)
                                        
                                        # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ Xì¶• ë²”ìœ„ ì„¤ì •
                                        if actual_start <= actual_end:
                                            x_range = [actual_start.strftime('%Y-%m-%d'), actual_end.strftime('%Y-%m-%d')]
                                elif date_range:
                                    # ê¸°ê°„ ì„ íƒ ì‹œ ì„ íƒëœ ê¸°ê°„ìœ¼ë¡œ Xì¶• ì„¤ì •
                                    x_range = [date_range[0], date_range[1]]
                                
                                # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                fig_trend.update_layout(
                                    title="ì¼ìë³„ ë…¸ì¶œìˆ˜ ë° ë§¤ì¶œì•¡ íŠ¸ë Œë“œ",
                                    xaxis_title="ë‚ ì§œ",
                                    barmode='stack',  # ë§‰ëŒ€ê·¸ë˜í”„ ìŠ¤íƒ ëª¨ë“œ
                                    xaxis=dict(
                                        range=x_range,  # Xì¶• ë²”ìœ„ë¥¼ ì„ íƒëœ ê¸°ê°„ìœ¼ë¡œ ì œí•œ
                                        type='date',
                                        showgrid=False  # Xì¶• ëˆˆê¸ˆì„  ì œê±°
                                    ),
                                    yaxis=dict(
                                        title=dict(
                                            text="ë§¤ì¶œì•¡",
                                            font=dict(color='blue')
                                        ),
                                        tickfont=dict(color='blue'),
                                        showgrid=False  # Yì¶• ëˆˆê¸ˆì„  ì œê±°
                                    ),
                                    yaxis2=dict(
                                        title=dict(
                                            text="ë…¸ì¶œìˆ˜",
                                            font=dict(color='red')
                                        ),
                                        tickfont=dict(color='red'),
                                        overlaying='y',
                                        side='right',
                                        showgrid=False  # Y2ì¶• ëˆˆê¸ˆì„  ì œê±°
                                    ),
                                    hovermode='x unified',
                                    legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),
                                    height=500
                                )
                                
                                # ë¹„ìš© íŠ¸ë Œë“œ ì¶”ê°€ (ë§¤ì¶œ ì—°ê³„ ë¶„ì„ì— ì†í•¨)
                                
                                # ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ë¹„ìš© íŠ¸ë Œë“œ ìƒì„±
                                cost_col = None
                                cost_date_col = None
                                
                                # ë¹„ìš© ì»¬ëŸ¼ ì°¾ê¸°
                                for col in execution_df.columns:
                                    if 'ì „ì²´ë¹„ìš©' in col:
                                        cost_col = col
                                    if 'ì—…ë¡œë“œì¼' in col or 'ë‚ ì§œ' in col or 'DT' in col:
                                        cost_date_col = col
                                
                                if cost_col and cost_date_col:
                                    # ì§‘í–‰ ë°ì´í„° ì¼ìë³„ ë¹„ìš© ì§‘ê³„ (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼í•œ ë¡œì§)
                                    execution_df_cost = execution_df.copy()
                                    
                                    # í•„í„° ì ìš© (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼)
                                    # ë¸Œëœë“œ í•„í„° ì ìš©
                                    if selected_brand != "ì „ì²´":
                                        if 'ë¸Œëœë“œ' in execution_df_cost.columns:
                                            execution_df_cost = execution_df_cost[execution_df_cost['ë¸Œëœë“œ'] == selected_brand]
                                    
                                    # ì•„ì´í…œ í•„í„° ì ìš©
                                    if selected_item != "ì „ì²´":
                                        if 'ì•„ì´í…œ' in execution_df_cost.columns:
                                            # ì•„ì´í…œ ì»¬ëŸ¼ì—ì„œ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ë“¤ì„ ì²˜ë¦¬
                                            execution_df_cost = execution_df_cost[
                                                execution_df_cost['ì•„ì´í…œ'].str.contains(selected_item, na=False)
                                            ]
                                    
                                    # ì‹œì¦Œ í•„í„° ì ìš©
                                    if selected_season != "ì „ì²´":
                                        if 'ì‹œì¦Œ' in execution_df_cost.columns:
                                            execution_df_cost = execution_df_cost[execution_df_cost['ì‹œì¦Œ'] == selected_season]
                                    
                                    # ë‚ ì§œ ë³€í™˜ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼)
                                    try:
                                        execution_df_cost[cost_date_col] = pd.to_datetime(execution_df_cost[cost_date_col], errors='coerce')
                                        # ë³€í™˜ ì‹¤íŒ¨í•œ í–‰ ì œê±°
                                        execution_df_cost = execution_df_cost.dropna(subset=[cost_date_col])
                                        
                                        # ë‚ ì§œ ë²”ìœ„ í•„í„° ì ìš©
                                        if date_range:
                                            execution_df_cost = execution_df_cost[
                                                (execution_df_cost[cost_date_col] >= pd.to_datetime(date_range[0])) &
                                                (execution_df_cost[cost_date_col] <= pd.to_datetime(date_range[1]))
                                            ]
                                        
                                        if execution_df_cost.empty:
                                            st.warning("í•„í„°ë§ í›„ ë¹„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                            # ë¹„ìš© ë°ì´í„°ê°€ ì—†ì–´ë„ ë§¤ì¶œì•¡ ê·¸ë˜í”„ëŠ” í‘œì‹œ
                                            daily_cost = None
                                            
                                            # ë§¤ì¶œ ë°ì´í„° ì¤€ë¹„ (ë¹„ìš© ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ ë§¤ì¶œì•¡ ê·¸ë˜í”„ í‘œì‹œ)
                                            filtered_sales_df_cost = sales_df.copy()
                                            
                                            # ë¸Œëœë“œ í•„í„° ì ìš©
                                            if selected_brand != "ì „ì²´":
                                                brand_code = brand_mapping.get(selected_brand, selected_brand)
                                                if 'BRD_CD' in filtered_sales_df_cost.columns:
                                                    filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['BRD_CD'] == brand_code]
                                            
                                            # ì•„ì´í…œ í•„í„° ì ìš©
                                            if selected_item != "ì „ì²´":
                                                filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['ITEM'] == selected_item]
                                            
                                            # ì‹œì¦Œ í•„í„° ì ìš©
                                            if selected_season != "ì „ì²´":
                                                if 'ì‹œì¦Œ' in filtered_sales_df_cost.columns:
                                                    filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['ì‹œì¦Œ'] == selected_season]
                                            
                                            # ë‚ ì§œ í•„í„° ì ìš©
                                            if date_range:
                                                filtered_sales_df_cost['DT'] = pd.to_datetime(filtered_sales_df_cost['DT'])
                                                filtered_sales_df_cost = filtered_sales_df_cost[
                                                    (filtered_sales_df_cost['DT'] >= pd.to_datetime(date_range[0])) &
                                                    (filtered_sales_df_cost['DT'] <= pd.to_datetime(date_range[1]))
                                                ]
                                            
                                            # ì „ì²´ ë§¤ì¶œ ë°ì´í„° ì¼ìë³„ ì§‘ê³„
                                            daily_sales_cost = filtered_sales_df_cost.groupby('DT').agg({
                                                'SALE_AMT_TY': 'sum',
                                                'SALE_AMT_LY': 'sum'  # ì „ë…„ ë°ì´í„°ë„ í¬í•¨
                                            }).reset_index()
                                            daily_sales_cost['DT'] = pd.to_datetime(daily_sales_cost['DT'])
                                            
                                            # ë¹„ìš© ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ ë§¤ì¶œì•¡ë§Œìœ¼ë¡œ ê·¸ë˜í”„ í‘œì‹œ
                                            if not daily_sales_cost.empty:
                                                # ë§¤ì¶œ ë°ì´í„°ë§Œìœ¼ë¡œ ê·¸ë˜í”„ ìƒì„±
                                                fig_cost = go.Figure()
                                                
                                                # ë§¤ì¶œì•¡ ë¼ì¸ (ì¢Œì¸¡ Yì¶•)
                                                fig_cost.add_trace(go.Scatter(
                                                    x=daily_sales_cost['DT'],
                                                    y=daily_sales_cost['SALE_AMT_TY'],
                                                    mode='lines+markers',
                                                    name='ë‹¹í•´ë§¤ì¶œì•¡',
                                                    line=dict(color='blue', width=3),
                                                    yaxis='y1',
                                                    zorder=3
                                                ))
                                                
                                                # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
                                                if 'SALE_AMT_LY' in daily_sales_cost.columns and not daily_sales_cost['SALE_AMT_LY'].isna().all():
                                                    fig_cost.add_trace(go.Scatter(
                                                        x=daily_sales_cost['DT'],
                                                        y=daily_sales_cost['SALE_AMT_LY'],
                                                        mode='lines+markers',
                                                        name='ì „ë…„ë§¤ì¶œì•¡',
                                                        line=dict(color='gray', width=2, dash='dash'),
                                                        yaxis='y1',
                                                        zorder=2
                                                    ))
                                                
                                                # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                                fig_cost.update_layout(
                                                    title="ì¼ìë³„ ë¹„ìš© ë° ë§¤ì¶œì•¡ íŠ¸ë Œë“œ",
                                                    xaxis_title="ë‚ ì§œ",
                                                    xaxis=dict(
                                                        type='date',
                                                        showgrid=False
                                                    ),
                                                    yaxis=dict(
                                                        title=dict(
                                                            text="ë§¤ì¶œì•¡",
                                                            font=dict(color='blue')
                                                        ),
                                                        tickfont=dict(color='blue'),
                                                        showgrid=False
                                                    ),
                                                    hovermode='x unified',
                                                    legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),
                                                    height=500
                                                )
                                                
                                                st.plotly_chart(fig_cost, use_container_width=True)
                                            return
                                        
                                        # ë§ˆì¼€íŒ… ë°ì´í„°ë„ í¬í•¨í•˜ì—¬ ìœ í˜•ë³„ ë¹„ìš© ë°ì´í„° ì²˜ë¦¬
                                        all_cost_data = []
                                        
                                        # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì²˜ë¦¬
                                        if 'ìœ í˜•' in execution_df_cost.columns:
                                            all_cost_data.append(execution_df_cost)
                                        
                                        # ë§ˆì¼€íŒ… ë°ì´í„° ì²˜ë¦¬
                                        marketing_df = load_marketing_data()
                                        if not marketing_df.empty and 'ìœ í˜•' in marketing_df.columns:
                                            # ë§ˆì¼€íŒ… ë°ì´í„° í•„í„° ì ìš©
                                            marketing_df_cost = marketing_df.copy()
                                            
                                            # ë¸Œëœë“œ í•„í„° ì ìš©
                                            if selected_brand != "ì „ì²´":
                                                if 'ë¸Œëœë“œ' in marketing_df_cost.columns:
                                                    marketing_df_cost = marketing_df_cost[marketing_df_cost['ë¸Œëœë“œ'] == selected_brand]
                                            
                                            # ì•„ì´í…œ í•„í„° ì ìš©
                                            if selected_item != "ì „ì²´":
                                                if 'ì•„ì´í…œ' in marketing_df_cost.columns:
                                                    marketing_df_cost = marketing_df_cost[
                                                        marketing_df_cost['ì•„ì´í…œ'].str.contains(selected_item, na=False)
                                                    ]
                                            
                                            # ì‹œì¦Œ í•„í„° ì ìš©
                                            if selected_season != "ì „ì²´":
                                                if 'ì‹œì¦Œ' in marketing_df_cost.columns:
                                                    marketing_df_cost = marketing_df_cost[marketing_df_cost['ì‹œì¦Œ'] == selected_season]
                                            
                                            # ë§ˆì¼€íŒ… ë°ì´í„°ì˜ ë‚ ì§œ ë° ë¹„ìš© ì»¬ëŸ¼ ì°¾ê¸°
                                            marketing_cost_col = None
                                            marketing_cost_date_col = None
                                            for col in marketing_df_cost.columns:
                                                if 'ë¹„ìš©' in col or 'ì „ì²´ë¹„ìš©' in col:
                                                    marketing_cost_col = col
                                                if 'ì—…ë¡œë“œì¼' in col or 'ë‚ ì§œ' in col or 'DT' in col:
                                                    marketing_cost_date_col = col
                                            
                                            if marketing_cost_col and marketing_cost_date_col:
                                                # ë§ˆì¼€íŒ… ë°ì´í„° ë‚ ì§œ ë³€í™˜
                                                marketing_df_cost[marketing_cost_date_col] = pd.to_datetime(marketing_df_cost[marketing_cost_date_col], errors='coerce')
                                                marketing_df_cost = marketing_df_cost.dropna(subset=[marketing_cost_date_col])
                                                
                                                # ë‚ ì§œ ë²”ìœ„ í•„í„° ì ìš©
                                                if date_range:
                                                    marketing_df_cost = marketing_df_cost[
                                                        (marketing_df_cost[marketing_cost_date_col] >= pd.to_datetime(date_range[0])) &
                                                        (marketing_df_cost[marketing_cost_date_col] <= pd.to_datetime(date_range[1]))
                                                    ]
                                                
                                                if not marketing_df_cost.empty:
                                                    all_cost_data.append(marketing_df_cost)
                                        
                                        if all_cost_data:
                                            # ëª¨ë“  ë°ì´í„°ë¥¼ í•©ì¹˜ê³  ìœ í˜•ë³„ë¡œ ë¹„ìš© ì§‘ê³„
                                            combined_cost_data = pd.concat(all_cost_data, ignore_index=True)
                                            
                                            # ìœ í˜•ë³„ë¡œ ë¹„ìš© ì§‘ê³„
                                            cost_by_type = {}
                                            for _, row in combined_cost_data.iterrows():
                                                # ë‚ ì§œ ê°’ ì°¾ê¸°
                                                date_val = None
                                                for col in [cost_date_col, 'ì—…ë¡œë“œì¼', 'ë‚ ì§œ', 'DT']:
                                                    if col in row and pd.notna(row[col]):
                                                        date_val = row[col]
                                                        break
                                                
                                                # ë¹„ìš© ê°’ ì°¾ê¸°
                                                cost_val = None
                                                for col in [cost_col, 'ë¹„ìš©', 'ì „ì²´ë¹„ìš©']:
                                                    if col in row and pd.notna(row[col]):
                                                        cost_val = row[col]
                                                        break
                                                
                                                type_val = row.get('ìœ í˜•', 'ê¸°íƒ€')
                                                
                                                if pd.notna(date_val) and pd.notna(cost_val):
                                                    # ë¹„ìš© ê°’ì´ ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸
                                                    try:
                                                        cost_float = float(cost_val)
                                                        if cost_float >= 0:  # ìŒìˆ˜ ì œê±°
                                                            date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
                                                            if date_str not in cost_by_type:
                                                                cost_by_type[date_str] = {}
                                                            if type_val not in cost_by_type[date_str]:
                                                                cost_by_type[date_str][type_val] = 0
                                                            cost_by_type[date_str][type_val] += cost_float
                                                    except (ValueError, TypeError):
                                                        # ìœ íš¨í•˜ì§€ ì•Šì€ ìˆ«ìëŠ” ë¬´ì‹œ
                                                        continue
                                            
                                            # ìœ í˜•ë³„ ë¹„ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
                                            type_cost_dataframes = {}
                                            for date_str, types in cost_by_type.items():
                                                for type_name, cost_val in types.items():
                                                    if type_name not in type_cost_dataframes:
                                                        type_cost_dataframes[type_name] = []
                                                    type_cost_dataframes[type_name].append({
                                                        'DT': pd.to_datetime(date_str),
                                                        f'{type_name}_ë¹„ìš©': cost_val
                                                    })
                                            
                                            # ê° ìœ í˜•ë³„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                                            daily_cost = None
                                            for type_name, data_list in type_cost_dataframes.items():
                                                type_df = pd.DataFrame(data_list)
                                                if daily_cost is None:
                                                    daily_cost = type_df
                                                else:
                                                    daily_cost = pd.merge(daily_cost, type_df, on='DT', how='outer').fillna(0)
                                        else:
                                            # ìœ í˜•ë³„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
                                            daily_cost = execution_df_cost.groupby(cost_date_col)[cost_col].sum().reset_index()
                                            daily_cost.columns = ['DT', 'ë¹„ìš©']
                                    except Exception as e:
                                        st.error(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                                        st.info("ì§‘í–‰ ë°ì´í„°ì˜ ë‚ ì§œ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        return
                                    
                                    # í•„í„° ì ìš©ëœ ë§¤ì¶œ ë°ì´í„° ì¤€ë¹„
                                    filtered_sales_df_cost = sales_df.copy()
                                    
                                    # ë¸Œëœë“œ í•„í„° ì ìš©
                                    if selected_brand != "ì „ì²´":
                                        brand_code = brand_mapping.get(selected_brand, selected_brand)
                                        if 'BRD_CD' in filtered_sales_df_cost.columns:
                                            filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['BRD_CD'] == brand_code]
                                    
                                    # ì•„ì´í…œ í•„í„° ì ìš©
                                    if selected_item != "ì „ì²´":
                                        filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['ITEM'] == selected_item]
                                    
                                    # ì‹œì¦Œ í•„í„° ì ìš©
                                    if selected_season != "ì „ì²´":
                                        if 'ì‹œì¦Œ' in filtered_sales_df_cost.columns:
                                            filtered_sales_df_cost = filtered_sales_df_cost[filtered_sales_df_cost['ì‹œì¦Œ'] == selected_season]
                                    
                                    # ë‚ ì§œ í•„í„° ì ìš©
                                    if date_range:
                                        filtered_sales_df_cost['DT'] = pd.to_datetime(filtered_sales_df_cost['DT'])
                                        filtered_sales_df_cost = filtered_sales_df_cost[
                                            (filtered_sales_df_cost['DT'] >= pd.to_datetime(date_range[0])) &
                                            (filtered_sales_df_cost['DT'] <= pd.to_datetime(date_range[1]))
                                        ]
                                    
                                    # ì „ì²´ ë§¤ì¶œ ë°ì´í„° ì¼ìë³„ ì§‘ê³„
                                    daily_sales_cost = filtered_sales_df_cost.groupby('DT').agg({
                                        'SALE_AMT_TY': 'sum',
                                        'SALE_AMT_LY': 'sum'  # ì „ë…„ ë°ì´í„°ë„ í¬í•¨
                                    }).reset_index()
                                    daily_sales_cost['DT'] = pd.to_datetime(daily_sales_cost['DT'])
                                    
                                    # ë§¤ì¶œ ë°ì´í„°ì™€ ë¹„ìš© ë°ì´í„° ë³‘í•©
                                    combined_df_cost = pd.merge(daily_sales_cost, daily_cost, on='DT', how='outer').fillna(0)
                                    combined_df_cost = combined_df_cost.sort_values('DT')
                                    
                                    if not combined_df_cost.empty:
                                        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                                        if len(combined_df_cost) < 2:
                                            st.info("ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ê¸°ì—ëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”)")
                                        else:
                                            # NaN ê°’ ì²˜ë¦¬
                                            combined_df_cost = combined_df_cost.fillna(0)
                                            
                                            # êº¾ì€ì„ ê·¸ë˜í”„ ìƒì„± (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼í•œ êµ¬ì¡°)
                                            try:
                                                fig_cost = go.Figure()
                                                
                                                # ë§¤ì¶œì•¡ ë¼ì¸ (ì¢Œì¸¡ Yì¶•)
                                                fig_cost.add_trace(go.Scatter(
                                                    x=combined_df_cost['DT'],
                                                    y=combined_df_cost['SALE_AMT_TY'],
                                                    mode='lines+markers',
                                                    name='ë‹¹í•´ë§¤ì¶œì•¡',
                                                    line=dict(color='blue', width=3),
                                                    yaxis='y1',
                                                    zorder=3  # ë§‰ëŒ€ê·¸ë˜í”„ë³´ë‹¤ ì•ì— í‘œì‹œ
                                                ))
                                                
                                                # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
                                                if 'SALE_AMT_LY' in combined_df_cost.columns and not combined_df_cost['SALE_AMT_LY'].isna().all():
                                                    fig_cost.add_trace(go.Scatter(
                                                        x=combined_df_cost['DT'],
                                                        y=combined_df_cost['SALE_AMT_LY'],
                                                        mode='lines+markers',
                                                        name='ì „ë…„ë§¤ì¶œì•¡',
                                                        line=dict(color='gray', width=2, dash='dash'),
                                                        yaxis='y1',
                                                        zorder=2  # ë§‰ëŒ€ê·¸ë˜í”„ë³´ë‹¤ ì•ì— í‘œì‹œ
                                                    ))
                                                
                                                # ìœ í˜•ë³„ ë¹„ìš© ìŠ¤íƒí˜• ë§‰ëŒ€ê·¸ë˜í”„ (ìš°ì¸¡ Yì¶•)
                                                # ìœ í˜•ë³„ ìƒ‰ìƒ ë§¤í•‘ (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼)
                                                type_colors = {
                                                    'ì¸í”Œë£¨ì–¸ì„œ': '#1f77b4',  # íŒŒë€ìƒ‰
                                                    'ë§ˆì¼€íŒ…': '#ff7f0e',      # ì£¼í™©ìƒ‰
                                                    'ë§¤ì²´SNS': '#2ca02c',    # ì´ˆë¡ìƒ‰
                                                    'SEO': '#9467bd',        # ë³´ë¼ìƒ‰
                                                    'ìì‚¬IG': '#8c564b',     # ê°ˆìƒ‰
                                                    'ì…€ë²”': '#e377c2',       # ë¶„í™ìƒ‰
                                                    'ê¸°íƒ€': '#d62728'        # ë¹¨ê°„ìƒ‰
                                                }
                                                
                                                # ìœ í˜•ë³„ ë¹„ìš© ì»¬ëŸ¼ ì°¾ê¸°
                                                cost_columns = [col for col in combined_df_cost.columns if col.endswith('_ë¹„ìš©')]
                                                
                                                if cost_columns:
                                                    # ìŠ¤íƒí˜• ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ìœ„í•´ ê° ìœ í˜•ë³„ë¡œ ë³„ë„ trace ìƒì„±
                                                    for i, col in enumerate(cost_columns):
                                                        type_name = col.replace('_ë¹„ìš©', '')
                                                        color = type_colors.get(type_name, '#808080')  # ê¸°ë³¸ íšŒìƒ‰
                                                        
                                                        # ê° ìœ í˜•ë³„ í˜¸ë²„ í…œí”Œë¦¿
                                                        hover_template = f'<b>{type_name}: %{{y:,.0f}}ì›</b><extra></extra>'
                                                        
                                                        fig_cost.add_trace(go.Bar(
                                                            x=combined_df_cost['DT'],
                                                            y=combined_df_cost[col],
                                                            name=f'{type_name}',
                                                            marker=dict(color=color, opacity=1.0),
                                                            yaxis='y2',
                                                            zorder=1,  # ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ë’¤ì— í‘œì‹œ
                                                            hovertemplate=hover_template
                                                        ))
                                                else:
                                                    # ê¸°ì¡´ ë¹„ìš© ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš© (ìœ í˜•ë³„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
                                                    if 'ë¹„ìš©' in combined_df_cost.columns:
                                                        fig_cost.add_trace(go.Bar(
                                                            x=combined_df_cost['DT'],
                                                            y=combined_df_cost['ë¹„ìš©'],
                                                            name='ë¹„ìš©',
                                                            marker=dict(color='red', opacity=0.7),
                                                            yaxis='y2',
                                                            zorder=1,  # ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ë’¤ì— í‘œì‹œ
                                                            hovertemplate='<b>ë¹„ìš©: %{y:,.0f}ì›</b><extra></extra>'
                                                        ))
                                                
                                                # ë ˆì´ì•„ì›ƒ ì„¤ì • (ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œì™€ ë™ì¼)
                                                fig_cost.update_layout(
                                                    title="ì¼ìë³„ ë¹„ìš© ë° ë§¤ì¶œì•¡ íŠ¸ë Œë“œ",
                                                    xaxis_title="ë‚ ì§œ",
                                                    barmode='stack',  # ë§‰ëŒ€ê·¸ë˜í”„ ìŠ¤íƒ ëª¨ë“œ
                                                    xaxis=dict(
                                                        type='date',
                                                        showgrid=False  # Xì¶• ëˆˆê¸ˆì„  ì œê±°
                                                    ),
                                                    yaxis=dict(
                                                        title=dict(
                                                            text="ë§¤ì¶œì•¡",
                                                            font=dict(color='blue')
                                                        ),
                                                        tickfont=dict(color='blue'),
                                                        showgrid=False  # Yì¶• ëˆˆê¸ˆì„  ì œê±°
                                                    ),
                                                    yaxis2=dict(
                                                        title=dict(
                                                            text="ë¹„ìš©",
                                                            font=dict(color='red')
                                                        ),
                                                        tickfont=dict(color='red'),
                                                        overlaying='y',
                                                        side='right',
                                                        showgrid=False  # Y2ì¶• ëˆˆê¸ˆì„  ì œê±°
                                                    ),
                                                    hovermode='x unified',
                                                    legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),
                                                    height=500
                                                )
                                                
                                                st.plotly_chart(fig_cost, use_container_width=True)
                                                
                                            except Exception as e:
                                                st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                                                st.info("ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                    else:
                                        st.info("ë§¤ì¶œê³¼ ë¹„ìš© ë°ì´í„°ë¥¼ ì—°ê³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    st.info("ë¹„ìš© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                
                            except Exception as e:
                                st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                                st.info("ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                return
                            
                            # ë…¸ì¶œìˆ˜ íŠ¸ë Œë“œ ê·¸ë˜í”„ í‘œì‹œ
                            st.plotly_chart(fig_trend, use_container_width=True)
                            
                            # ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ìˆœì„œ ë³€ê²½)
                            if len(combined_df_item) > 1:
                                # ë¹„ìš©-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ë¨¼ì € í‘œì‹œ)
                                if 'daily_cost' in locals() and daily_cost is not None and not daily_cost.empty:
                                    # ë¹„ìš© ë°ì´í„°ì™€ ë§¤ì¶œ ë°ì´í„° ë³‘í•©
                                    cost_sales_df = pd.merge(combined_df_item[['DT', 'SALE_AMT_TY']], daily_cost, on='DT', how='inner')
                                    
                                    if len(cost_sales_df) > 1:
                                        # ìœ í˜•ë³„ ë¹„ìš© ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
                                        cost_columns = [col for col in cost_sales_df.columns if col.endswith('_ë¹„ìš©')]
                                        
                                        if cost_columns:
                                            # ìœ í˜•ë³„ ë¹„ìš©ì˜ í•©ê³„ ê³„ì‚°
                                            total_cost = cost_sales_df[cost_columns].sum(axis=1)
                                            cost_correlation = cost_sales_df['SALE_AMT_TY'].corr(total_cost)
                                            st.metric("ğŸ’° ë¹„ìš©-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜", f"{cost_correlation:.3f}")
                                        elif 'ë¹„ìš©' in cost_sales_df.columns:
                                            # ê¸°ì¡´ ë¹„ìš© ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                                            cost_correlation = cost_sales_df['SALE_AMT_TY'].corr(cost_sales_df['ë¹„ìš©'])
                                            st.metric("ğŸ’° ë¹„ìš©-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜", f"{cost_correlation:.3f}")
                                        else:
                                            st.warning("ë¹„ìš© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    else:
                                        st.warning("ë¹„ìš©ê³¼ ë§¤ì¶œ ë°ì´í„°ë¥¼ ì—°ê³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    st.warning("ë¹„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                
                                # ë…¸ì¶œìˆ˜-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ë‚˜ì¤‘ì— í‘œì‹œ)
                                # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
                                exposure_columns = [col for col in combined_df_item.columns if col.endswith('_ë…¸ì¶œìˆ˜')]
                                
                                if exposure_columns:
                                    # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ì˜ í•©ê³„ ê³„ì‚°
                                    total_exposure = combined_df_item[exposure_columns].sum(axis=1)
                                    correlation = combined_df_item['SALE_AMT_TY'].corr(total_exposure)
                                    st.metric("ğŸ“Š ë…¸ì¶œìˆ˜-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}")
                                elif 'ë…¸ì¶œìˆ˜' in combined_df_item.columns:
                                    # ê¸°ì¡´ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                                    correlation = combined_df_item['SALE_AMT_TY'].corr(combined_df_item['ë…¸ì¶œìˆ˜'])
                                    st.metric("ğŸ“Š ë…¸ì¶œìˆ˜-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}")
                                else:
                                    st.warning("ë…¸ì¶œìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # YoY ì„±ì¥ë¥  ê³„ì‚° (ì „ë…„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
                            if 'SALE_AMT_LY' in combined_df_item.columns and not combined_df_item['SALE_AMT_LY'].isna().all():
                                # í•„í„°ë§ëœ ë°ì´í„°ì—ì„œ ì§ì ‘ YoY ì„±ì¥ë¥  ê³„ì‚°
                                valid_data = combined_df_item[
                                    (combined_df_item['SALE_AMT_TY'] > 0) & 
                                    (combined_df_item['SALE_AMT_LY'] > 0)
                                ]
                                
                                if not valid_data.empty:
                                    # YoY ì„±ì¥ë¥  ê³„ì‚°
                                    yoy_growth = ((valid_data['SALE_AMT_TY'] - valid_data['SALE_AMT_LY']) / valid_data['SALE_AMT_LY'] * 100).mean()
                                    st.metric("ğŸ“ˆ YoY ë§¤ì¶œ ë¹„êµ", f"{yoy_growth:.1f}%")
                                else:
                                    st.warning("YoY ì„±ì¥ë¥  ê³„ì‚°ì„ ìœ„í•œ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.warning("ì „ë…„ ë°ì´í„°(SALE_AMT_LY)ê°€ ì—†ì–´ YoY ì„±ì¥ë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            
                            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
                            st.markdown("#### ğŸ“‹ ì¼ìë³„ ìƒì„¸ ë°ì´í„°")
                            display_df = combined_df_item.copy()
                            display_df['DT'] = display_df['DT'].dt.strftime('%Y-%m-%d')
                            
                            # ìœ í˜•ë³„ ë¹„ìš© ë°ì´í„° ì¶”ê°€
                            if 'daily_cost' in locals() and daily_cost is not None:
                                # DT ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… í†µì¼ (datetimeìœ¼ë¡œ ë³€í™˜)
                                display_df['DT'] = pd.to_datetime(display_df['DT'], errors='coerce')
                                daily_cost['DT'] = pd.to_datetime(daily_cost['DT'], errors='coerce')
                                
                                # ë¹„ìš© ë°ì´í„°ì™€ ë§¤ì¶œ ë°ì´í„° ë³‘í•©
                                display_df = pd.merge(display_df, daily_cost, on='DT', how='left')
                            
                            # ì»¬ëŸ¼ëª… ë³€ê²½ (ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ ì²˜ë¦¬)
                            column_mapping = {'DT': 'ë‚ ì§œ', 'SALE_AMT_TY': 'ë‹¹í•´ë§¤ì¶œì•¡'}
                            
                            # ì „ë…„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                            if daily_sales_ly is not None and not daily_sales_ly.empty:
                                # ì „ë…„ ë°ì´í„°ì™€ ì˜¬í•´ ë°ì´í„°ë¥¼ ê°™ì€ ë‚ ì§œë¡œ ë§¤ì¹­í•˜ì—¬ í‘œì‹œ
                                current_sales = combined_df_item[['DT', 'SALE_AMT_TY']].copy()
                                current_sales['DT'] = current_sales['DT'] - pd.DateOffset(years=1)
                                yoy_comparison = pd.merge(current_sales, daily_sales_ly, on='DT', how='inner')
                                if not yoy_comparison.empty:
                                    # YoY ë¹„êµ ë°ì´í„°ë¥¼ ì›ë˜ ë‚ ì§œë¡œ ë³µì›
                                    yoy_comparison['DT'] = yoy_comparison['DT'] + pd.DateOffset(years=1)
                                    
                                    # DT ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… í†µì¼ (datetimeìœ¼ë¡œ ë³€í™˜)
                                    display_df['DT'] = pd.to_datetime(display_df['DT'], errors='coerce')
                                    yoy_comparison['DT'] = pd.to_datetime(yoy_comparison['DT'], errors='coerce')
                                    
                                    display_df = pd.merge(display_df, yoy_comparison[['DT', 'SALE_AMT_LY']], on='DT', how='left')
                                    column_mapping['SALE_AMT_LY'] = 'ì „ë…„ë§¤ì¶œì•¡'
                            
                            
                            # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                            exposure_columns = [col for col in display_df.columns if col.endswith('_ë…¸ì¶œìˆ˜')]
                            if exposure_columns:
                                # ìœ í˜•ë³„ ë…¸ì¶œìˆ˜ ì»¬ëŸ¼ëª…ì„ í•œêµ­ì–´ë¡œ ë³€ê²½
                                for col in exposure_columns:
                                    type_name = col.replace('_ë…¸ì¶œìˆ˜', '')
                                    column_mapping[col] = f'{type_name} ë…¸ì¶œìˆ˜'
                            elif 'ë…¸ì¶œìˆ˜' in display_df.columns:
                                column_mapping['ë…¸ì¶œìˆ˜'] = 'ë…¸ì¶œìˆ˜'
                            
                            # ìœ í˜•ë³„ ë¹„ìš© ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                            cost_columns = [col for col in display_df.columns if col.endswith('_ë¹„ìš©')]
                            if cost_columns:
                                # ìœ í˜•ë³„ ë¹„ìš© ì»¬ëŸ¼ëª…ì„ í•œêµ­ì–´ë¡œ ë³€ê²½
                                for col in cost_columns:
                                    type_name = col.replace('_ë¹„ìš©', '')
                                    column_mapping[col] = f'{type_name} ë¹„ìš©'
                            elif 'ë¹„ìš©' in display_df.columns:
                                column_mapping['ë¹„ìš©'] = 'ë¹„ìš©'
                            
                            # ì»¬ëŸ¼ëª… ë³€ê²½ ì ìš©
                            display_df = display_df.rename(columns=column_mapping)
                            display_df = display_df.sort_values('ë‚ ì§œ', ascending=False)
                            
                            st.dataframe(display_df, use_container_width=True, hide_index=True)
                        else:
                            st.info("ë§¤ì¶œê³¼ ë…¸ì¶œëŸ‰ ë°ì´í„°ë¥¼ ì—°ê³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ì„ íƒëœ ì•„ì´í…œì— ëŒ€í•œ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì•„ì´í…œì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"ì§‘í–‰ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë…¸ì¶œìˆ˜: {exposure_col}, ë‚ ì§œ: {date_col}")
        else:
            st.info("ì§‘í–‰ ë°ì´í„°ê°€ ì—†ì–´ ë…¸ì¶œëŸ‰ ì—°ê³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë§¤ì¶œ ë°ì´í„°ì— ì•„ì´í…œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # AI ì¸ì‚¬ì´íŠ¸ ë° ë„¥ìŠ¤íŠ¸ ìŠ¤í… ì œì•ˆ (í•„í„°ë§ëœ ë°ì´í„° ê¸°ë°˜)
    st.markdown("---")
    st.markdown("## ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ & ë„¥ìŠ¤íŠ¸ ìŠ¤í…")
    
    # í˜„ì¬ í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë¶„ì„
    try:
        # í•„í„°ë§ëœ ë°ì´í„° í™•ì¸
        if 'combined_df_item' in locals() and not combined_df_item.empty:
            # í˜„ì¬ í•„í„° ì¡°ê±´ í‘œì‹œ
            filter_info = []
            if selected_brand != "ì „ì²´":
                filter_info.append(f"ë¸Œëœë“œ: {selected_brand}")
            if selected_item != "ì „ì²´":
                filter_info.append(f"ì•„ì´í…œ: {selected_item}")
            if selected_season != "ì „ì²´":
                filter_info.append(f"ì‹œì¦Œ: {selected_season}")
            if date_range:
                filter_info.append(f"ê¸°ê°„: {date_range[0]} ~ {date_range[1]}")
            
            if filter_info:
                st.markdown(f"**ğŸ“Š ë¶„ì„ ëŒ€ìƒ**: {', '.join(filter_info)}")
            
            # í•„í„°ë§ëœ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
            insights = []
            recommendations = []
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì»¬ëŸ¼ í™•ì¸ (ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©)
            available_columns = list(combined_df_item.columns)
            
            # ë§¤ì¶œì•¡ ì»¬ëŸ¼ í™•ì¸
            sales_columns = [col for col in available_columns if 'SALE_AMT' in col]
            
            # ë…¸ì¶œìˆ˜ ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
            exposure_columns = [col for col in available_columns if 'ë…¸ì¶œìˆ˜' in col or 'ë…¸ì¶œ' in col]
            
            # ë¹„ìš© ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
            cost_columns = [col for col in available_columns if 'ë¹„ìš©' in col or 'COST' in col]
            
            # 1. ë…¸ì¶œìˆ˜-ë§¤ì¶œì•¡ ìƒê´€ê´€ê³„ ë¶„ì„ (ëª¨ë“  ë…¸ì¶œìˆ˜ ì»¬ëŸ¼)
            if 'SALE_AMT_TY' in combined_df_item.columns:
                for exposure_col in exposure_columns:
                    if exposure_col in combined_df_item.columns:
                        # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
                        valid_data = combined_df_item[[exposure_col, 'SALE_AMT_TY']].dropna()
                        if len(valid_data) > 1:
                            correlation = valid_data[exposure_col].corr(valid_data['SALE_AMT_TY'])
                            
                            if not pd.isna(correlation):
                                # ë…¸ì¶œìˆ˜ ìœ í˜•ë³„ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
                                type_names = {
                                    'ì¸í”Œë£¨ì–¸ì„œ_ë…¸ì¶œìˆ˜': 'ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…',
                                    'ìì‚¬IG_ë…¸ì¶œìˆ˜': 'ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨',
                                    'SEO_ë…¸ì¶œìˆ˜': 'ê²€ìƒ‰ì—”ì§„ ìµœì í™”',
                                    'ì…€ëŸ½_ë…¸ì¶œìˆ˜': 'ì…€ëŸ½ ë§ˆì¼€íŒ…',
                                    'ë§¤ì²´SNS_ë…¸ì¶œìˆ˜': 'ë§¤ì²´ SNS'
                                }
                                type_name = type_names.get(exposure_col, exposure_col)
                                
                                if correlation > 0.7:
                                    insights.append(f"ğŸ¯ **{type_name}ì´ ë§¤ì¶œì— ê°•ë ¥í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤!** ë…¸ì¶œì´ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ë§¤ì¶œì´ í™•ì‹¤íˆ ì¦ê°€í•˜ëŠ” íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤. ì´ ì±„ë„ì— ë” ì§‘ì¤‘í•˜ì„¸ìš”.")
                                elif correlation > 0.3:
                                    insights.append(f"ğŸ“ˆ **{type_name}ì´ ë§¤ì¶œ ì¦ê°€ì— ë„ì›€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.** ì–´ëŠ ì •ë„ íš¨ê³¼ê°€ ìˆì§€ë§Œ, ë” ê°•í•œ ì—°ê´€ì„±ì„ ìœ„í•´ ì½˜í…ì¸  í’ˆì§ˆì„ ë†’ì—¬ë³´ì„¸ìš”.")
                                elif correlation > -0.3:
                                    insights.append(f"âš ï¸ **{type_name}ì˜ ë§¤ì¶œ ê¸°ì—¬ë„ê°€ ì œí•œì ì…ë‹ˆë‹¤.** ë…¸ì¶œìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë„ ë§¤ì¶œì— í° ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. íƒ€ê²ŸíŒ…ê³¼ ë©”ì‹œì§€ë¥¼ ì¬ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.")
                                else:
                                    insights.append(f"ğŸ“‰ **{type_name}ì´ ì˜¤íˆë ¤ ë§¤ì¶œì— ë¶€ì •ì  ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.** ë…¸ì¶œì´ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ë§¤ì¶œì´ ê°ì†Œí•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì „ëµì„ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.")
            
            # 2. ë¹„ìš©-ë§¤ì¶œì•¡ ìƒê´€ê´€ê³„ ë¶„ì„ (ëª¨ë“  ë¹„ìš© ì»¬ëŸ¼)
            if 'SALE_AMT_TY' in combined_df_item.columns:
                for cost_col in cost_columns:
                    if cost_col in combined_df_item.columns:
                        # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
                        valid_data = combined_df_item[[cost_col, 'SALE_AMT_TY']].dropna()
                        if len(valid_data) > 1:
                            correlation = valid_data[cost_col].corr(valid_data['SALE_AMT_TY'])
                            
                            if not pd.isna(correlation):
                                if correlation > 0.5:
                                    insights.append(f"ğŸ’° **{cost_col} íˆ¬ìê°€ ë§¤ì¶œì— í° ë„ì›€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤!** ë¹„ìš©ì„ ëŠ˜ë¦´ìˆ˜ë¡ ë§¤ì¶œì´ í™•ì‹¤íˆ ì¦ê°€í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ì´ ì±„ë„ì— ë” íˆ¬ìí•˜ì„¸ìš”.")
                                elif correlation > 0:
                                    insights.append(f"ğŸ’¸ **{cost_col} íˆ¬ìì˜ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.** ë¹„ìš©ì„ ëŠ˜ë ¤ë„ ë§¤ì¶œ ì¦ê°€ê°€ ë¯¸ë¯¸í•©ë‹ˆë‹¤. ROIë¥¼ ë†’ì´ê¸° ìœ„í•´ ì „ëµì„ ê°œì„ í•˜ì„¸ìš”.")
                                else:
                                    insights.append(f"âš ï¸ **{cost_col} íˆ¬ìê°€ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.** ë¹„ìš©ì„ ëŠ˜ë¦´ìˆ˜ë¡ ì˜¤íˆë ¤ ë§¤ì¶œì´ ê°ì†Œí•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ì¦‰ì‹œ íˆ¬ì ì „ëµì„ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.")
            
            # 3. ë…¸ì¶œìˆ˜-ë¹„ìš© ìƒê´€ê´€ê³„ ë¶„ì„ (ë…¸ì¶œìˆ˜ì™€ ë¹„ìš© ê°„ì˜ ê´€ê³„)
            for exposure_col in exposure_columns:
                for cost_col in cost_columns:
                    if exposure_col in combined_df_item.columns and cost_col in combined_df_item.columns:
                        valid_data = combined_df_item[[exposure_col, cost_col]].dropna()
                        if len(valid_data) > 1:
                            correlation = valid_data[exposure_col].corr(valid_data[cost_col])
                            
                            if not pd.isna(correlation):
                                # ë…¸ì¶œìˆ˜ ìœ í˜•ë³„ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
                                type_names = {
                                    'ì¸í”Œë£¨ì–¸ì„œ_ë…¸ì¶œìˆ˜': 'ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…',
                                    'ìì‚¬IG_ë…¸ì¶œìˆ˜': 'ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨',
                                    'SEO_ë…¸ì¶œìˆ˜': 'ê²€ìƒ‰ì—”ì§„ ìµœì í™”',
                                    'ì…€ëŸ½_ë…¸ì¶œìˆ˜': 'ì…€ëŸ½ ë§ˆì¼€íŒ…',
                                    'ë§¤ì²´SNS_ë…¸ì¶œìˆ˜': 'ë§¤ì²´ SNS'
                                }
                                exposure_name = type_names.get(exposure_col, exposure_col)
                                
                                if correlation > 0.7:
                                    insights.append(f"ğŸ¯ **{exposure_name}ì— íˆ¬ìí• ìˆ˜ë¡ ë…¸ì¶œì´ í™•ì‹¤íˆ ëŠ˜ì–´ë‚©ë‹ˆë‹¤!** ë¹„ìš© ëŒ€ë¹„ ë…¸ì¶œ íš¨ê³¼ê°€ ë§¤ìš° ì¢‹ìŠµë‹ˆë‹¤. ì´ ì±„ë„ì— ë” ì§‘ì¤‘í•˜ì„¸ìš”.")
                                elif correlation > 0.3:
                                    insights.append(f"ğŸ“Š **{exposure_name} íˆ¬ìê°€ ë…¸ì¶œ ì¦ê°€ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.** ì–´ëŠ ì •ë„ íš¨ê³¼ê°€ ìˆì§€ë§Œ, ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì„ ì°¾ì•„ë³´ì„¸ìš”.")
                                elif correlation > -0.3:
                                    insights.append(f"âš ï¸ **{exposure_name} íˆ¬ìì˜ ë…¸ì¶œ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.** ë¹„ìš©ì„ ëŠ˜ë ¤ë„ ë…¸ì¶œì´ í¬ê²Œ ëŠ˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „ëµì„ ì¬ê²€í† í•˜ì„¸ìš”.")
                                else:
                                    insights.append(f"ğŸ“‰ **{exposure_name} íˆ¬ìê°€ ì˜¤íˆë ¤ ë…¸ì¶œì„ ì¤„ì´ê³  ìˆìŠµë‹ˆë‹¤.** ë¹„ìš©ì„ ëŠ˜ë¦´ìˆ˜ë¡ ë…¸ì¶œì´ ê°ì†Œí•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì ‘ê·¼ë²•ì„ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.")
            
            # 3. YoY ì„±ì¥ë¥  ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if 'SALE_AMT_LY' in combined_df_item.columns:
                valid_yoy_data = combined_df_item[
                    (combined_df_item['SALE_AMT_TY'] > 0) & 
                    (combined_df_item['SALE_AMT_LY'] > 0)
                ]
                if not valid_yoy_data.empty:
                    yoy_growth = ((valid_yoy_data['SALE_AMT_TY'] - valid_yoy_data['SALE_AMT_LY']) / valid_yoy_data['SALE_AMT_LY'] * 100).mean()
                    
                    if yoy_growth > 20:
                        insights.append(f"ğŸš€ **ëŒ€ë°•! ì „ë…„ ëŒ€ë¹„ {yoy_growth:.1f}% ì„±ì¥í–ˆìŠµë‹ˆë‹¤!** í˜„ì¬ ë§ˆì¼€íŒ… ì „ëµì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. ì´ ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•´ì„œ ë” í™•ì¥í•˜ì„¸ìš”.")
                    elif yoy_growth > 0:
                        insights.append(f"ğŸ“ˆ **ì¢‹ì€ ì„±ì¥ì„¸ì…ë‹ˆë‹¤! ì „ë…„ ëŒ€ë¹„ {yoy_growth:.1f}% ì„±ì¥í–ˆìŠµë‹ˆë‹¤.** í˜„ì¬ ë°©í–¥ì´ ë§ìŠµë‹ˆë‹¤. ë” ì ê·¹ì ìœ¼ë¡œ ë§ˆì¼€íŒ…ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
                    else:
                        insights.append(f"âš ï¸ **ì„±ì¥ì´ ë‘”í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ë…„ ëŒ€ë¹„ {yoy_growth:.1f}% ë³€í™”ì…ë‹ˆë‹¤.** í˜„ì¬ ì „ëµì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ì¸ì„ ë¶„ì„í•˜ê³  ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            
            # 4. ìœ í˜•ë³„ ì„±ê³¼ ë¶„ì„ (ë…¸ì¶œìˆ˜ ê¸°ì¤€)
            exposure_columns = [col for col in combined_df_item.columns if col.endswith('_ë…¸ì¶œìˆ˜')]
            if exposure_columns:
                type_performance = {}
                for col in exposure_columns:
                    type_name = col.replace('_ë…¸ì¶œìˆ˜', '')
                    type_exposure = combined_df_item[col].sum()
                    if type_exposure > 0:
                        type_performance[type_name] = type_exposure
                
                if type_performance:
                    best_type = max(type_performance, key=type_performance.get)
                    worst_type = min(type_performance, key=type_performance.get)
                    
                    # ìœ í˜•ë³„ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
                    type_names = {
                        'ì¸í”Œë£¨ì–¸ì„œ': 'ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…',
                        'ìì‚¬IG': 'ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨',
                        'SEO': 'ê²€ìƒ‰ì—”ì§„ ìµœì í™”',
                        'ì…€ëŸ½': 'ì…€ëŸ½ ë§ˆì¼€íŒ…',
                        'ë§¤ì²´SNS': 'ë§¤ì²´ SNS'
                    }
                    best_name = type_names.get(best_type, best_type)
                    worst_name = type_names.get(worst_type, worst_type)
                    
                    insights.append(f"ğŸ† **{best_name}ì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤!** {type_performance[best_type]:,.0f}íšŒì˜ ë…¸ì¶œì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ ì±„ë„ì˜ ì„±ê³µ ë¹„ë²•ì„ ë‹¤ë¥¸ ì±„ë„ì—ë„ ì ìš©í•´ë³´ì„¸ìš”.")
                    
                    if type_performance[best_type] > type_performance[worst_type] * 3:
                        insights.append(f"ğŸ’¡ **{best_name}ì˜ ì„±ê³µ ìš”ì¸ì„ {worst_name}ì— ì ìš©í•˜ì„¸ìš”.** ì„±ê³¼ ì°¨ì´ê°€ 3ë°° ì´ìƒ ë‚©ë‹ˆë‹¤. ì„±ê³µí•œ ì „ëµì„ ë³µì‚¬í•´ë³´ì„¸ìš”.")
                    else:
                        insights.append(f"âš–ï¸ **ê° ì±„ë„ë³„ë¡œ ì°¨ë³„í™”ëœ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.** ëª¨ë“  ì±„ë„ì´ ë¹„ìŠ·í•œ ì„±ê³¼ë¥¼ ë³´ì´ë¯€ë¡œ, ê°ê°ì˜ íŠ¹ì„±ì— ë§ëŠ” ë§ì¶¤í˜• ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            # 5. ì•„ì´í…œë³„ ë¶„ì„ ì¶”ê°€ (ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… í™•ì¸)
            item_column = None
            if 'ITEM' in combined_df_item.columns:
                item_column = 'ITEM'
            elif 'ì•„ì´í…œ' in combined_df_item.columns:
                item_column = 'ì•„ì´í…œ'
            elif 'item' in combined_df_item.columns:
                item_column = 'item'
            
            if item_column:
                # ì•„ì´í…œë³„ ë…¸ì¶œìˆ˜ ë¶„ì„
                if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns:
                    item_exposure = combined_df_item.groupby(item_column)['ë…¸ì¶œìˆ˜'].sum()
                    if not item_exposure.empty and item_exposure.sum() > 0:
                        best_item = item_exposure.idxmax()
                        best_exposure = item_exposure.max()
                        insights.append(f"ğŸ“¦ **{best_item} ì•„ì´í…œì´ ê°€ì¥ ë§ì€ ê´€ì‹¬ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤!** {best_exposure:,.0f}íšŒì˜ ë…¸ì¶œì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ ì•„ì´í…œì˜ ë§ˆì¼€íŒ… ì „ëµì„ ë‹¤ë¥¸ ì•„ì´í…œì—ë„ ì ìš©í•´ë³´ì„¸ìš”.")

                # ì•„ì´í…œë³„ ë§¤ì¶œì•¡ ë¶„ì„
                if 'SALE_AMT_TY' in combined_df_item.columns:
                    item_sales = combined_df_item.groupby(item_column)['SALE_AMT_TY'].sum()
                    if not item_sales.empty and item_sales.sum() > 0:
                        best_sales_item = item_sales.idxmax()
                        best_sales = item_sales.max()
                        insights.append(f"ğŸ’° **{best_sales_item} ì•„ì´í…œì´ ë§¤ì¶œì˜ ì£¼ë ¥êµ°ì…ë‹ˆë‹¤!** {best_sales:,.0f}ì›ì˜ ë§¤ì¶œì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ ì•„ì´í…œì— ë” ì§‘ì¤‘í•˜ì„¸ìš”.")

                # ì•„ì´í…œë³„ íš¨ìœ¨ì„± ë¶„ì„ (ë…¸ì¶œìˆ˜ ëŒ€ë¹„ ë§¤ì¶œì•¡)
                if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns and 'SALE_AMT_TY' in combined_df_item.columns:
                    item_exposure = combined_df_item.groupby(item_column)['ë…¸ì¶œìˆ˜'].sum()
                    item_sales = combined_df_item.groupby(item_column)['SALE_AMT_TY'].sum()

                    if not item_exposure.empty and not item_sales.empty:
                        item_efficiency = {}
                        for item in item_exposure.index:
                            if item in item_sales.index and item_exposure[item] > 0:
                                efficiency = item_sales[item] / item_exposure[item]
                                item_efficiency[item] = efficiency

                        if item_efficiency:
                            best_efficiency_item = max(item_efficiency, key=item_efficiency.get)
                            best_efficiency = item_efficiency[best_efficiency_item]
                            insights.append(f"âš¡ **{best_efficiency_item} ì•„ì´í…œì´ ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤!** ë…¸ì¶œ 1íšŒë‹¹ {best_efficiency:,.0f}ì›ì˜ ë§¤ì¶œì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ì´ ì•„ì´í…œì˜ ì„±ê³µ ê³µì‹ì„ ë¶„ì„í•´ë³´ì„¸ìš”.")
            else:
                # ì•„ì´í…œ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°
                insights.append(f"ğŸ“Š **ì•„ì´í…œë³„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.** í˜„ì¬ ë°ì´í„°ë¡œëŠ” ì•„ì´í…œë³„ ì„±ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # 6. í†µí•©ì  ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            if insights:
                st.markdown("### ğŸ§  AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸")
                
                # í•µì‹¬ ì„±ê³¼ ì§€í‘œ ì¶”ì¶œ
                best_channel = None
                worst_channel = None
                growth_rate = None
                total_exposure = 0
                total_sales = 0
                
                # ë°ì´í„°ì—ì„œ í•µì‹¬ ì§€í‘œ ì¶”ì¶œ
                for insight in insights:
                    if "ê°€ì¥ íš¨ê³¼ì " in insight and "ì¸í”Œë£¨ì–¸ì„œ" in insight:
                        best_channel = "ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…"
                    elif "ê°€ì¥ íš¨ê³¼ì " in insight:
                        best_channel = insight.split("ì´ ê°€ì¥ íš¨ê³¼ì ")[0].split("**")[-1]
                    elif "ëŒ€ë°•" in insight and "ì„±ì¥" in insight:
                        growth_rate = insight.split("ëŒ€ë°•! ì „ë…„ ëŒ€ë¹„ ")[1].split("%")[0] if "ëŒ€ë°•! ì „ë…„ ëŒ€ë¹„ " in insight else None
                    elif "ì„±ì¥" in insight and "%" in insight:
                        growth_rate = insight.split("ì „ë…„ ëŒ€ë¹„ ")[1].split("%")[0] if "ì „ë…„ ëŒ€ë¹„ " in insight else None
                
                # ë…¸ì¶œìˆ˜ í•©ê³„ ê³„ì‚°
                if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns:
                    total_exposure = combined_df_item['ë…¸ì¶œìˆ˜'].sum()
                elif any('_ë…¸ì¶œìˆ˜' in col for col in combined_df_item.columns):
                    exposure_cols = [col for col in combined_df_item.columns if '_ë…¸ì¶œìˆ˜' in col]
                    total_exposure = combined_df_item[exposure_cols].sum().sum()
                
                # ë§¤ì¶œì•¡ í•©ê³„ ê³„ì‚°
                if 'SALE_AMT_TY' in combined_df_item.columns:
                    total_sales = combined_df_item['SALE_AMT_TY'].sum()
                
                # í†µí•© ì¸ì‚¬ì´íŠ¸ ìƒì„±
                st.markdown("#### ğŸ“Š í•µì‹¬ ì„±ê³¼ ì§€í‘œ")
                
                # 1. ì „ì²´ ì„±ê³¼ ìš”ì•½
                if total_exposure > 0 and total_sales > 0:
                    efficiency = total_sales / total_exposure
                    st.markdown(f"**ğŸ’° ë§¤ì¶œ ì„±ê³¼**: {total_sales:,.0f}ì› (ë…¸ì¶œë‹¹ {efficiency:,.0f}ì›)")
                    st.markdown(f"**ğŸ“ˆ ë…¸ì¶œ ì„±ê³¼**: {total_exposure:,.0f}íšŒ ë…¸ì¶œ")
                
                # 2. ì„±ì¥ë¥  ë¶„ì„
                if growth_rate:
                    if float(growth_rate) > 50:
                        st.markdown(f"**ğŸ“ˆ YoY ì„±ì¥ë¥ **: {growth_rate}% (50% ì´ìƒ ê³ ì„±ì¥)")
                    elif float(growth_rate) > 20:
                        st.markdown(f"**ğŸ“ˆ YoY ì„±ì¥ë¥ **: {growth_rate}% (20% ì´ìƒ ì–‘í˜¸í•œ ì„±ì¥)")
                    else:
                        st.markdown(f"**ğŸ“ˆ YoY ì„±ì¥ë¥ **: {growth_rate}% (20% ë¯¸ë§Œ ì €ì„±ì¥)")
                
                # 3. ìµœê³  ì„±ê³¼ ì±„ë„
                if best_channel:
                    st.markdown(f"**ğŸ† ìµœê³  ì„±ê³¼ ì±„ë„**: {best_channel}")
                
                # 4. êµ¬ì²´ì  ì±„ë„ë³„ ìƒê´€ê´€ê³„ ë¶„ì„
                st.markdown("#### ğŸ¯ ì±„ë„ë³„ ë§¤ì¶œ ê¸°ì—¬ë„")
                
                # ìƒê´€ê´€ê³„ê°€ ê°•í•œ ì±„ë„ë“¤ë§Œ í•„í„°ë§
                strong_correlations = []
                moderate_correlations = []
                
                for insight in insights:
                    if "ê°•ë ¥í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤" in insight:
                        strong_correlations.append(insight)
                    elif "ë§¤ì¶œ ì¦ê°€ì— ë„ì›€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤" in insight:
                        moderate_correlations.append(insight)
                
                if strong_correlations:
                    st.markdown("**ğŸ“Š ë†’ì€ ë§¤ì¶œ ê¸°ì—¬ë„ (ìƒê´€ê³„ìˆ˜ 0.7+):**")
                    for insight in strong_correlations:
                        # êµ¬ì²´ì ì¸ ìƒê´€ê³„ìˆ˜ì™€ í•´ì„ ì¶”ê°€
                        if "ì¸í”Œë£¨ì–¸ì„œ" in insight:
                            st.markdown(f"- **ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…**: ë…¸ì¶œìˆ˜ì™€ ë§¤ì¶œì•¡ ê°„ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ í™•ì¸")
                        elif "SEO" in insight:
                            st.markdown(f"- **ê²€ìƒ‰ì—”ì§„ ìµœì í™”**: ê²€ìƒ‰ ë…¸ì¶œê³¼ ë§¤ì¶œ ê°„ ë†’ì€ ìƒê´€ê´€ê³„ í™•ì¸")
                        elif "ìì‚¬" in insight:
                            st.markdown(f"- **ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨**: ë¸Œëœë“œ ê³„ì • ë…¸ì¶œê³¼ ë§¤ì¶œ ê°„ ê°•í•œ ì—°ê´€ì„± í™•ì¸")
                        else:
                            st.markdown(f"- {insight}")
                
                if moderate_correlations:
                    st.markdown("**ğŸ“ˆ ì¤‘ê°„ ë§¤ì¶œ ê¸°ì—¬ë„ (ìƒê´€ê³„ìˆ˜ 0.3-0.7):**")
                    for insight in moderate_correlations:
                        if "SEO" in insight:
                            st.markdown(f"- **ê²€ìƒ‰ì—”ì§„ ìµœì í™”**: ë…¸ì¶œìˆ˜ì™€ ë§¤ì¶œ ê°„ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì–‘ì˜ ìƒê´€ê´€ê³„ í™•ì¸")
                        elif "ìì‚¬" in insight:
                            st.markdown(f"- **ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨**: ë…¸ì¶œìˆ˜ì™€ ë§¤ì¶œ ê°„ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì–‘ì˜ ìƒê´€ê´€ê³„ í™•ì¸")
                        else:
                            st.markdown(f"- {insight}")
                
                # 5. ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„
                cost_insights = [insight for insight in insights if "íˆ¬ìê°€ ë§¤ì¶œì— í° ë„ì›€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤" in insight]
                if cost_insights:
                    st.markdown("**ğŸ’° ë†’ì€ ë¹„ìš© íš¨ìœ¨ì„±:**")
                    for insight in cost_insights:
                        st.markdown(f"- {insight}")
                
            # 6. AI ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ì„
            st.markdown("#### ğŸ¤– AI ì•Œê³ ë¦¬ì¦˜ ë¶„ì„")
            
            # ë‹¤ì°¨ì› ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
            ai_insights = []
            
            # 1. íŒ¨í„´ ì¸ì‹ ì•Œê³ ë¦¬ì¦˜ - ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„
            if 'DT' in combined_df_item.columns and 'SALE_AMT_TY' in combined_df_item.columns:
                # ë‚ ì§œë³„ ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„
                daily_sales = combined_df_item.groupby('DT')['SALE_AMT_TY'].sum().reset_index()
                daily_sales['DT'] = pd.to_datetime(daily_sales['DT'])
                daily_sales = daily_sales.sort_values('DT')
                
                if len(daily_sales) > 1:
                    # ë§¤ì¶œ ì¦ê°€/ê°ì†Œ íŒ¨í„´ ë¶„ì„
                    daily_sales['ë§¤ì¶œ_ë³€í™”ìœ¨'] = daily_sales['SALE_AMT_TY'].pct_change() * 100
                    avg_growth = daily_sales['ë§¤ì¶œ_ë³€í™”ìœ¨'].mean()
                    volatility = daily_sales['ë§¤ì¶œ_ë³€í™”ìœ¨'].std()
                    
                    if avg_growth > 5:
                        ai_insights.append(f"ğŸ“ˆ **ìƒìŠ¹ íŠ¸ë Œë“œ**: ì¼í‰ê·  {avg_growth:.1f}% ë§¤ì¶œ ì¦ê°€ íŒ¨í„´ ê°ì§€")
                    elif avg_growth < -5:
                        ai_insights.append(f"ğŸ“‰ **í•˜ë½ íŠ¸ë Œë“œ**: ì¼í‰ê·  {abs(avg_growth):.1f}% ë§¤ì¶œ ê°ì†Œ íŒ¨í„´ ê°ì§€")
                    
                    if volatility > 50:
                        ai_insights.append(f"âš¡ **ë†’ì€ ë³€ë™ì„±**: ë§¤ì¶œ ë³€ë™í­ì´ {volatility:.0f}%ë¡œ ë¶ˆì•ˆì •í•œ íŒ¨í„´")
                    elif volatility < 10:
                        ai_insights.append(f"ğŸ“Š **ì•ˆì •ì  íŒ¨í„´**: ë§¤ì¶œ ë³€ë™í­ì´ {volatility:.0f}%ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´")
            
            # 2. í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ - ì„±ê³¼ ê·¸ë£¹ ë¶„ì„
            performance_metrics = []
            
            # ìº í˜ì¸ë³„ ì„±ê³¼ í´ëŸ¬ìŠ¤í„°ë§
            if 'ìº í˜ì¸ëª…' in combined_df_item.columns or 'ìº í˜ì¸' in combined_df_item.columns:
                campaign_col = 'ìº í˜ì¸ëª…' if 'ìº í˜ì¸ëª…' in combined_df_item.columns else 'ìº í˜ì¸'
                if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns and 'SALE_AMT_TY' in combined_df_item.columns:
                    campaign_data = combined_df_item.groupby(campaign_col).agg({
                        'ë…¸ì¶œìˆ˜': 'sum',
                        'SALE_AMT_TY': 'sum'
                    }).reset_index()
                    campaign_data['íš¨ìœ¨ì„±'] = campaign_data['SALE_AMT_TY'] / campaign_data['ë…¸ì¶œìˆ˜']
                    
                    # K-means í´ëŸ¬ìŠ¤í„°ë§ ì‹œë®¬ë ˆì´ì…˜ (ê°„ë‹¨í•œ ë¶„ìœ„ìˆ˜ ê¸°ë°˜)
                    campaign_data['ì„±ê³¼_ë“±ê¸‰'] = pd.qcut(campaign_data['íš¨ìœ¨ì„±'], q=3, labels=['ì €ì„±ê³¼', 'ì¤‘ì„±ê³¼', 'ê³ ì„±ê³¼'])
                    
                    high_performers = campaign_data[campaign_data['ì„±ê³¼_ë“±ê¸‰'] == 'ê³ ì„±ê³¼']
                    if not high_performers.empty:
                        ai_insights.append(f"ğŸ¯ **ê³ ì„±ê³¼ ìº í˜ì¸ ê·¸ë£¹**: {len(high_performers)}ê°œ ìº í˜ì¸ì´ í‰ê·  íš¨ìœ¨ì„± {high_performers['íš¨ìœ¨ì„±'].mean():,.0f}ì›/ë…¸ì¶œ ë‹¬ì„±")
            
            # 3. ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ - ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€
            if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns and 'SALE_AMT_TY' in combined_df_item.columns:
                # Z-score ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€
                exposure_z = (combined_df_item['ë…¸ì¶œìˆ˜'] - combined_df_item['ë…¸ì¶œìˆ˜'].mean()) / combined_df_item['ë…¸ì¶œìˆ˜'].std()
                sales_z = (combined_df_item['SALE_AMT_TY'] - combined_df_item['SALE_AMT_TY'].mean()) / combined_df_item['SALE_AMT_TY'].std()
                
                outliers = combined_df_item[(abs(exposure_z) > 2) | (abs(sales_z) > 2)]
                if not outliers.empty:
                    ai_insights.append(f"ğŸ” **ì´ìƒì¹˜ ê°ì§€**: {len(outliers)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ì—ì„œ ë¹„ì •ìƒì  íŒ¨í„´ ë°œê²¬")
            
            # 4. ìƒê´€ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
            correlation_matrix = combined_df_item.select_dtypes(include=[np.number]).corr()
            
            # ê°•í•œ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸°
            strong_pairs = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    corr_val = correlation_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7 and not pd.isna(corr_val):
                        strong_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_val))
            
            if strong_pairs:
                ai_insights.append(f"ğŸ”— **ê°•í•œ ìƒê´€ê´€ê³„ ë„¤íŠ¸ì›Œí¬**: {len(strong_pairs)}ê°œ ë³€ìˆ˜ ê°„ ê°•í•œ ì—°ê´€ì„± ë°œê²¬")
                for var1, var2, corr in strong_pairs[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    ai_insights.append(f"   - {var1} â†” {var2}: {corr:.3f}")
            
            # 5. ê³ ê¸‰ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë¶„ì„
            if len(combined_df_item) > 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                try:
                    from sklearn.linear_model import LinearRegression, Ridge, Lasso
                    from sklearn.ensemble import RandomForestRegressor
                    from sklearn.metrics import r2_score, mean_absolute_error
                    from sklearn.preprocessing import StandardScaler
                    from sklearn.model_selection import cross_val_score
                    
                    # ë‹¤ì¤‘ ë³€ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸
                    numeric_cols = combined_df_item.select_dtypes(include=[np.number]).columns
                    feature_cols = [col for col in numeric_cols if col != 'SALE_AMT_TY' and col != 'SALE_AMT_LY']
                    
                    if len(feature_cols) > 0 and 'SALE_AMT_TY' in combined_df_item.columns:
                        X = combined_df_item[feature_cols].fillna(0)
                        y = combined_df_item['SALE_AMT_TY'].fillna(0)
                        
                        # ë°ì´í„° ì •ê·œí™”
                        scaler = StandardScaler()
                        X_scaled = scaler.fit_transform(X)
                        
                        # ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ
                        models = {
                            'Linear Regression': LinearRegression(),
                            'Ridge Regression': Ridge(alpha=1.0),
                            'Lasso Regression': Lasso(alpha=1.0),
                            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
                        }
                        
                        best_model = None
                        best_score = -np.inf
                        model_scores = {}
                        
                        for name, model in models.items():
                            try:
                                # êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
                                scores = cross_val_score(model, X_scaled, y, cv=3, scoring='r2')
                                avg_score = scores.mean()
                                model_scores[name] = avg_score
                                
                                if avg_score > best_score:
                                    best_score = avg_score
                                    best_model = name
                            except:
                                continue
                        
                        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²°ê³¼
                        if best_model and best_score > 0:
                            ai_insights.append(f"ğŸ¤– **ìµœê³  ì˜ˆì¸¡ ëª¨ë¸**: {best_model} (RÂ² = {best_score:.3f})")
                            
                            # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
                            if len(model_scores) > 1:
                                sorted_models = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)
                                ai_insights.append(f"ğŸ“Š **ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„**:")
                                for i, (model_name, score) in enumerate(sorted_models[:3], 1):
                                    ai_insights.append(f"   {i}. {model_name}: {score:.3f}")
                            
                            # ì˜ˆì¸¡ë ¥ í•´ì„
                            if best_score > 0.8:
                                ai_insights.append(f"ğŸ¯ **ë§¤ìš° ë†’ì€ ì˜ˆì¸¡ë ¥**: {best_score:.1%}ë¡œ ë§¤ìš° ì •í™•í•œ ì˜ˆì¸¡ ê°€ëŠ¥")
                            elif best_score > 0.6:
                                ai_insights.append(f"ğŸ“ˆ **ë†’ì€ ì˜ˆì¸¡ë ¥**: {best_score:.1%}ë¡œ ìƒë‹¹íˆ ì •í™•í•œ ì˜ˆì¸¡ ê°€ëŠ¥")
                            elif best_score > 0.3:
                                ai_insights.append(f"ğŸ“Š **ì¤‘ê°„ ì˜ˆì¸¡ë ¥**: {best_score:.1%}ë¡œ ì–´ëŠ ì •ë„ ì˜ˆì¸¡ ê°€ëŠ¥")
                            else:
                                ai_insights.append(f"âš ï¸ **ë‚®ì€ ì˜ˆì¸¡ë ¥**: {best_score:.1%}ë¡œ ì˜ˆì¸¡ì´ ì–´ë ¤ì›€")
                        
                        # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (Random Forest)
                        if 'Random Forest' in models:
                            try:
                                rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
                                rf_model.fit(X_scaled, y)
                                feature_importance = rf_model.feature_importances_
                                
                                # ìƒìœ„ 3ê°œ ì¤‘ìš” íŠ¹ì„±
                                importance_pairs = list(zip(feature_cols, feature_importance))
                                importance_pairs.sort(key=lambda x: x[1], reverse=True)
                                
                                if importance_pairs:
                                    ai_insights.append(f"ğŸ” **íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„**:")
                                    for i, (feature, importance) in enumerate(importance_pairs[:3], 1):
                                        ai_insights.append(f"   {i}. {feature}: {importance:.3f}")
                            except:
                                pass
                                
                except ImportError:
                    # sklearnì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¶„ì„
                    if 'ë…¸ì¶œìˆ˜' in combined_df_item.columns and 'SALE_AMT_TY' in combined_df_item.columns:
                        correlation = combined_df_item['ë…¸ì¶œìˆ˜'].corr(combined_df_item['SALE_AMT_TY'])
                        if not pd.isna(correlation):
                            ai_insights.append(f"ğŸ“Š **ê¸°ë³¸ ìƒê´€ê´€ê³„**: ë…¸ì¶œìˆ˜-ë§¤ì¶œì•¡ ìƒê´€ê³„ìˆ˜ {correlation:.3f}")
            
            # 6. ë™ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±
            if ai_insights:
                st.markdown("**ğŸ§  AI ì•Œê³ ë¦¬ì¦˜ ë¶„ì„ ê²°ê³¼:**")
                for insight in ai_insights:
                    st.markdown(f"- {insight}")
            else:
                st.markdown("**ğŸ“Š ë°ì´í„° ë¶„ì„**: í˜„ì¬ ë°ì´í„°ë¡œëŠ” AI ì•Œê³ ë¦¬ì¦˜ ë¶„ì„ì´ ì œí•œì ì…ë‹ˆë‹¤.")
            
            # 7. ì „ëµì  ì œì•ˆ
            st.markdown("#### ğŸ“‹ ì „ëµì  ì œì•ˆ")
            
            if strong_correlations:
                st.markdown("**ğŸ“ˆ í™•ì¥ ê¶Œì¥ ì±„ë„:**")
                if any("ì¸í”Œë£¨ì–¸ì„œ" in insight for insight in strong_correlations):
                    st.markdown("- ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ…: ì˜ˆì‚° ì¦ì•¡ ë° íŒŒíŠ¸ë„ˆì‹­ í™•ëŒ€ ê²€í† ")
                if any("SEO" in insight for insight in strong_correlations):
                    st.markdown("- SEO: ì½˜í…ì¸  ì œì‘ ë° í‚¤ì›Œë“œ ìµœì í™” ê°•í™”")
            
            if moderate_correlations:
                st.markdown("**ğŸ”§ ê°œì„  ê¶Œì¥ ì±„ë„:**")
                if any("SEO" in insight for insight in moderate_correlations):
                    st.markdown("- SEO: ì½˜í…ì¸  í’ˆì§ˆ í–¥ìƒ ë° ë°±ë§í¬ êµ¬ì¶•")
                if any("ìì‚¬" in insight for insight in moderate_correlations):
                    st.markdown("- ìì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨: íƒ€ê²ŸíŒ… ì •êµí™” ë° ì½˜í…ì¸  ì „ëµ ê°œì„ ")
                
            else:
                st.info("í˜„ì¬ í•„í„° ì¡°ê±´ì—ì„œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        else:
            st.info("ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.warning(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# =============================================================================
# F&F CREW LIST ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

def prepare_influencer_summary(df, brand_filter=None, season_filter=None):
    """ì¸í”Œë£¨ì–¸ì„œ ìš”ì•½ ë°ì´í„° ì¤€ë¹„"""
    if df.empty:
        return pd.DataFrame()
    
    # í•„í„°ë§
    filtered_df = df.copy()
    if brand_filter and brand_filter != "ì „ì²´":
        filtered_df = filtered_df[filtered_df['ë¸Œëœë“œ'] == brand_filter]
    if season_filter and season_filter != "ì „ì²´":
        filtered_df = filtered_df[filtered_df['ì‹œì¦Œ'] == season_filter]
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸ ë° ì„ íƒ
    required_columns = ["sns_id", "name", "follower", "unit_fee", "sec_usage", "sec_period"]
    available_columns = [col for col in required_columns if col in filtered_df.columns]
    
    if not available_columns:
        st.error("í•„ìš”í•œ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    influencer_summary = filtered_df[available_columns].copy()
    
    # ì¤‘ë³µ ì œê±°
    influencer_summary = influencer_summary.drop_duplicates()
    
    return influencer_summary

def render_influencer_tab(df):
    """F&F CREW LIST íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ‘¥ F&F CREW LIST")
    
    if df.empty:
        st.warning("ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•„í„° ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ·ï¸ ë¸Œëœë“œ**")
        brands = df['ë¸Œëœë“œ'].unique() if 'ë¸Œëœë“œ' in df.columns else []
        selected_brand = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + list(brands), key="crew_brand_filter", label_visibility="collapsed")
    
    with col2:
        st.markdown("**ğŸ“… ì‹œì¦Œ**")
        seasons = df['ì‹œì¦Œ'].unique() if 'ì‹œì¦Œ' in df.columns else []
        selected_season = st.selectbox("ì‹œì¦Œì„ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + list(seasons), key="crew_season_filter", label_visibility="collapsed")
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì¤€ë¹„
    influencer_summary = prepare_influencer_summary(df, selected_brand, selected_season)
    
    if influencer_summary.empty:
        st.warning("ì„ íƒëœ ì¡°ê±´ì— ë§ëŠ” ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° í‘œì‹œ
    st.dataframe(influencer_summary, use_container_width=True)
    
    # í†µê³„ ì •ë³´
    st.markdown("## ğŸ“Š í†µê³„ ì •ë³´")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ì¸í”Œë£¨ì–¸ì„œ ìˆ˜", len(influencer_summary))
    with col2:
        avg_followers = influencer_summary['follower'].mean() if 'follower' in influencer_summary.columns else 0
        st.metric("í‰ê·  íŒ”ë¡œì›Œ ìˆ˜", f"{avg_followers:,.0f}")
    with col3:
        avg_fee = influencer_summary['unit_fee'].mean() if 'unit_fee' in influencer_summary.columns else 0
        st.metric("í‰ê·  ê³„ì•½ë‹¨ê°€", f"{avg_fee:,.0f}ì›")

# =============================================================================
# ìë™ ë°°ì • ì‹œìŠ¤í…œ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

def execute_optimal_assignment(month, targets_df, influencer_df):
    """ìµœì  ë°°ì • ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰"""
    try:
        import pulp
        
        # ë¬¸ì œ ìƒì„±
        prob = pulp.LpProblem("OptimalAssignment", pulp.LpMaximize)
        
        # ë³€ìˆ˜ ìƒì„±
        assignments = {}
        for _, target in targets_df.iterrows():
            brand = target['ë¸Œëœë“œ']
            for _, influencer in influencer_df.iterrows():
                influencer_id = influencer['sns_id']
                var_name = f"assign_{brand}_{influencer_id}"
                assignments[(brand, influencer_id)] = pulp.LpVariable(var_name, cat='Binary')
        
        # ëª©ì í•¨ìˆ˜: ì´ ê³„ì•½ìˆ˜ëŸ‰ ìµœëŒ€í™”
        prob += pulp.lpSum([assignments[(brand, influencer_id)] * target['ê³„ì•½ìˆ˜ëŸ‰'] 
                      for (brand, influencer_id), var in assignments.items()
                      for _, target in targets_df.iterrows()
                      if target['ë¸Œëœë“œ'] == brand])
        
        # ì œì•½ì¡°ê±´
        # 1. ê° ì¸í”Œë£¨ì–¸ì„œëŠ” í•œ ë¸Œëœë“œì—ë§Œ ë°°ì •
        for influencer_id in influencer_df['sns_id']:
            prob += pulp.lpSum([assignments[(brand, influencer_id)] for brand in targets_df['ë¸Œëœë“œ']]) <= 1
        
        # 2. ê° ë¸Œëœë“œì˜ ìš”ì²­ìˆ˜ëŸ‰ ì¶©ì¡±
        for _, target in targets_df.iterrows():
            brand = target['ë¸Œëœë“œ']
            prob += pulp.lpSum([assignments[(brand, influencer_id)] * target['ê³„ì•½ìˆ˜ëŸ‰'] 
                          for influencer_id in influencer_df['sns_id']]) >= target['ìš”ì²­ìˆ˜ëŸ‰']
        
        # ë¬¸ì œ í•´ê²°
        prob.solve()
        
        # ê²°ê³¼ ì¶”ì¶œ
        results = []
        for (brand, influencer_id), var in assignments.items():
            if var.varValue == 1:
                influencer_info = influencer_df[influencer_df['sns_id'] == influencer_id].iloc[0]
                results.append({
                    'sns_id': influencer_id,
                    'ë¸Œëœë“œ': brand,
                    'ë°°ì •ì›”': month,
                    'ì´ë¦„': influencer_info['name'],
                    'FLW': influencer_info['follower'],
                    '1íšŒê³„ì•½ë‹¨ê°€': influencer_info['unit_fee'],
                    '2ì°¨í™œìš©': influencer_info['sec_usage'],
                    '2ì°¨ê¸°ê°„': influencer_info['sec_period'],
                    'ê³„ì•½ìˆ˜ëŸ‰': target['ê³„ì•½ìˆ˜ëŸ‰'],
                    'ë°°ì •ì—¬ë¶€': 'ë°°ì •',
                    'ì§‘í–‰ìƒíƒœ': 'ë¯¸ì§‘í–‰',
                    'ì§‘í–‰ìˆ˜ëŸ‰': 0,
                    'ìµœì¢…ìƒíƒœ': 'ë°°ì •'
                })
        
        return results
        
    except ImportError:
        st.error("PuLP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pulpë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return []
    except Exception as e:
        st.error(f"ìµœì  ë°°ì • ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return []

def render_assignment_tab():
    """ìë™ ë°°ì • íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ¯ ìë™ ë°°ì • ì‹œìŠ¤í…œ")
    
    # ì›”ë³„ ë°°ì • ëª©í‘œ ë°ì´í„° ë¡œë“œ
    targets_df = load_monthly_targets()
    influencer_df = load_influencer_data()
    
    if targets_df.empty:
        st.warning("ì›”ë³„ ë°°ì • ëª©í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if influencer_df.empty:
        st.warning("ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì›” ì„ íƒ
    if 'month' in targets_df.columns:
        months = targets_df['month'].unique()
        selected_month = st.selectbox("ë°°ì •í•  ì›”ì„ ì„ íƒí•˜ì„¸ìš”", months)
        
        # í•´ë‹¹ ì›”ì˜ ëª©í‘œ ë°ì´í„°
        month_targets = targets_df[targets_df['month'] == selected_month]
    else:
        st.warning("ë°°ì • ëª©í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°°ì • ëª©í‘œë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    # ëª©í‘œ ë°ì´í„° í‘œì‹œ
    st.markdown("## ğŸ“‹ ë°°ì • ëª©í‘œ")
    st.dataframe(month_targets, use_container_width=True)
    
    # ìë™ ë°°ì • ì‹¤í–‰
    if st.button("ğŸ¯ ìë™ ë°°ì • ì‹¤í–‰", type="primary"):
        with st.spinner("ìµœì  ë°°ì •ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            results = execute_optimal_assignment(selected_month, month_targets, influencer_df)
            
            if results:
                st.success(f"âœ… {len(results)}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œê°€ ë°°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ê²°ê³¼ ì €ì¥
                results_df = pd.DataFrame(results)
                existing_assignments = load_assignment_history()
                updated_assignments = pd.concat([existing_assignments, results_df], ignore_index=True)
                save_assignment_history(updated_assignments)
                
                # ê²°ê³¼ í‘œì‹œ
                st.markdown("## ğŸ“Š ë°°ì • ê²°ê³¼")
                st.dataframe(results_df, use_container_width=True)
            else:
                st.warning("ë°°ì • ê°€ëŠ¥í•œ ì¸í”Œë£¨ì–¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

# =============================================================================
# ì „ì²´ ì§‘í–‰ ë°ì´í„° ê´€ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

# ë§ˆì¼€íŒ… ë°ì´í„° íŒŒì¼ ê²½ë¡œ
MARKETING_FILE = 'data/marketing_data.csv'

def load_marketing_data():
    """ë§ˆì¼€íŒ… ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(MARKETING_FILE):
        try:
            return pd.read_csv(MARKETING_FILE, encoding='utf-8')
        except:
            return pd.read_csv(MARKETING_FILE, encoding='cp949')
    return pd.DataFrame()

def save_marketing_data(df):
    """ë§ˆì¼€íŒ… ë°ì´í„° ì €ì¥"""
    os.makedirs('data', exist_ok=True)
    df.to_csv(MARKETING_FILE, index=False, encoding='utf-8')

def render_execution_data_management_tab():
    """ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ“ˆ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬")
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° í‘œì‹œ
    execution_df = load_execution_data()
    if not execution_df.empty:
        st.markdown("## ğŸ“Š ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°")
        st.success(f"ì´ {len(execution_df)}ê±´ì˜ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„í„°
        col1, col2, col3 = st.columns(3)
        
        with col1:
            seasons = execution_df['ì‹œì¦Œ'].unique() if 'ì‹œì¦Œ' in execution_df.columns else []
            selected_season = st.selectbox("ğŸ“… ì‹œì¦Œ", ["ì „ì²´"] + list(seasons), key="execution_season_filter")
        
        with col2:
            brands = execution_df['ë¸Œëœë“œ'].unique() if 'ë¸Œëœë“œ' in execution_df.columns else []
            selected_brand = st.selectbox("ğŸ·ï¸ ë¸Œëœë“œ", ["ì „ì²´"] + list(brands), key="execution_brand_filter")
        
        with col3:
            # ì•„ì´í…œ í•„í„° (ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬)
            if 'ì•„ì´í…œ' in execution_df.columns:
                # ëª¨ë“  ì•„ì´í…œ ê°’ì„ ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ê°œë³„ ì•„ì´í…œ ëª©ë¡ ìƒì„±
                all_items = []
                for items_str in execution_df['ì•„ì´í…œ'].dropna():
                    if isinstance(items_str, str):
                        # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°
                        items = [item.strip() for item in items_str.split(',')]
                        all_items.extend(items)
                
                # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
                unique_items = sorted(list(set(all_items)))
                selected_execution_items = st.multiselect(
                    "ğŸ“¦ ì•„ì´í…œ", 
                    unique_items, 
                    key="execution_item_filter",
                    placeholder="ì•„ì´í…œì„ ì„ íƒí•˜ì„¸ìš”"
                )
            else:
                selected_execution_items = []
        
        # ë°ì´í„° í•„í„°ë§
        filtered_execution_df = execution_df.copy()
        if selected_season != "ì „ì²´":
            filtered_execution_df = filtered_execution_df[filtered_execution_df['ì‹œì¦Œ'] == selected_season]
        if selected_brand != "ì „ì²´":
            filtered_execution_df = filtered_execution_df[filtered_execution_df['ë¸Œëœë“œ'] == selected_brand]
        
        # ì•„ì´í…œ í•„í„°ë§ (ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì„ íƒëœ ì•„ì´í…œê³¼ ì¼ì¹˜í•˜ë©´ í¬í•¨)
        if selected_execution_items and 'ì•„ì´í…œ' in filtered_execution_df.columns:
            def contains_selected_item(items_str):
                if pd.isna(items_str) or not isinstance(items_str, str):
                    return False
                items = [item.strip() for item in items_str.split(',')]
                return any(item in selected_execution_items for item in items)
            
            filtered_execution_df = filtered_execution_df[filtered_execution_df['ì•„ì´í…œ'].apply(contains_selected_item)]
        
        # ì‹œíŠ¸ëª… ì»¬ëŸ¼ ì œê±° ë° ì•„ì´í…œ ì»¬ëŸ¼ ì¶”ê°€ (ë‚´ë¶€ ì²˜ë¦¬ìš©ì´ë¯€ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ)
        display_df = filtered_execution_df.copy()
        if 'ì‹œíŠ¸ëª…' in display_df.columns:
            display_df = display_df.drop(columns=['ì‹œíŠ¸ëª…'])
        
        # ì•„ì´í…œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€ (ë©”ì¸ì œí’ˆ ì•ì— ìœ„ì¹˜)
        if 'ì•„ì´í…œ' not in display_df.columns:
            # ë©”ì¸ì œí’ˆ ì»¬ëŸ¼ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ ê·¸ ì•ì— ì•„ì´í…œ ì»¬ëŸ¼ ì¶”ê°€
            if 'ë©”ì¸ì œí’ˆ' in display_df.columns:
                main_product_idx = display_df.columns.get_loc('ë©”ì¸ì œí’ˆ')
                display_df.insert(main_product_idx, 'ì•„ì´í…œ', None)
            else:
                display_df['ì•„ì´í…œ'] = None
        
        st.dataframe(display_df, use_container_width=True)
        
        # ê´€ë¦¬ ì˜µì…˜
        col1, col2 = st.columns(2)
        
        with col1:
            # ì—‘ì…€ íŒŒì¼ ìƒì„± (ì‹œíŠ¸ëª… ì»¬ëŸ¼ ì œê±° ë° ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬)
            download_df = filtered_execution_df.copy()
            if 'ì‹œíŠ¸ëª…' in download_df.columns:
                download_df = download_df.drop(columns=['ì‹œíŠ¸ëª…'])
            
            # í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œ ì •ì˜ (ì•„ì´í…œì´ ë©”ì¸ì œí’ˆ ì•ì— ì˜¤ë„ë¡)
            standard_columns = [
                'ìœ í˜•', 'ë¸Œëœë“œ', 'ì‹œì¦Œ', 'ì—°ë„', 'ìº í˜ì¸ì›”', 'ì—…ë¡œë“œì›”', 'ì—…ë¡œë“œì¼',
                'ì±„ë„', 'ì´ë¦„', 'sns_id', 'ìº í˜ì¸ëª…', 'ì•„ì´í…œ', 'ë©”ì¸ì œí’ˆ',
                'ì»¨í…ì¸ URL', 'ì»¨í…ì¸ ìœ í˜•', 'íŒ”ë¡œì›Œ', 'ë…¸ì¶œìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ì¡°íšŒìˆ˜', 'ì „ì²´ë¹„ìš©'
            ]
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ìˆœì„œ ì •ë¦¬
            existing_columns = [col for col in standard_columns if col in download_df.columns]
            other_columns = [col for col in download_df.columns if col not in standard_columns]
            final_columns = existing_columns + other_columns
            
            download_df = download_df[final_columns]
            
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                download_df.to_excel(writer, index=False, sheet_name='ì§‘í–‰ë°ì´í„°')
            output.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"ì§‘í–‰ë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        
        with col2:
            if st.button("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ", use_container_width=True):
                if os.path.exists(EXECUTION_FILE):
                    os.remove(EXECUTION_FILE)
                    st.success("ì§‘í–‰ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë¡œë“œ
    st.markdown("---")
    st.markdown("### ğŸ“¤ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë¡œë“œ")
    
    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ (ì—‘ì…€ ë‹¤ìš´ë¡œë“œì™€ ë™ì¼í•œ ì»¬ëŸ¼ êµ¬ì¡°)
        template_data = {
            'ìœ í˜•': ['ì¸í”Œë£¨ì–¸ì„œ', 'ì¸í”Œë£¨ì–¸ì„œ', 'ì¸í”Œë£¨ì–¸ì„œ', 'ì¸í”Œë£¨ì–¸ì„œ'],
            'ë¸Œëœë“œ': ['MLB', 'DX', 'DV', 'ST'],
            'ì‹œì¦Œ': ['25FW', '25FW', '25FW', '25FW'],
            'ì—°ë„': [2025, 2025, 2025, 2025],
            'ìº í˜ì¸ì›”': ['5ì›”', '5ì›”', '6ì›”', '6ì›”'],
            'ì—…ë¡œë“œì›”': ['5ì›”', '5ì›”', '6ì›”', '6ì›”'],
            'ì—…ë¡œë“œì¼': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'],
            'ì±„ë„': ['ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨'],
            'ì´ë¦„': ['ì¸í”Œë£¨ì–¸ì„œ1', 'ì¸í”Œë£¨ì–¸ì„œ2', 'ì¸í”Œë£¨ì–¸ì„œ3', 'ì¸í”Œë£¨ì–¸ì„œ4'],
            'sns_id': ['influencer1', 'influencer2', 'influencer3', 'influencer4'],
            'ìº í˜ì¸ìœ í˜•': ['5ì›”ì¸í”Œë£¨ì–¸ì„œ', '5ì›”ì¸í”Œë£¨ì–¸ì„œ', '6ì›”ì¸í”Œë£¨ì–¸ì„œ', '6ì›”ì¸í”Œë£¨ì–¸ì„œ'],
            'ìº í˜ì¸ëª…': ['ìº í˜ì¸1', 'ìº í˜ì¸2', 'ìº í˜ì¸3', 'ìº í˜ì¸4'],
            'ì•„ì´í…œ': ['ì•„ì´í…œ1', 'ì•„ì´í…œ2', 'ì•„ì´í…œ3', 'ì•„ì´í…œ4'],
            'ë©”ì¸ì œí’ˆ': ['ì œí’ˆ1', 'ì œí’ˆ2', 'ì œí’ˆ3', 'ì œí’ˆ4'],
            'ì„œë¸Œì œí’ˆ1': ['ì„œë¸Œì œí’ˆ1-1', 'ì„œë¸Œì œí’ˆ1-2', 'ì„œë¸Œì œí’ˆ1-3', 'ì„œë¸Œì œí’ˆ1-4'],
            'ì„œë¸Œì œí’ˆ2': ['ì„œë¸Œì œí’ˆ2-1', 'ì„œë¸Œì œí’ˆ2-2', 'ì„œë¸Œì œí’ˆ2-3', 'ì„œë¸Œì œí’ˆ2-4'],
            'ì»¨í…ì¸ URL': ['https://instagram.com/1', 'https://instagram.com/2', 'https://instagram.com/3', 'https://instagram.com/4'],
            'ì»¨í…ì¸ ìœ í˜•': ['PHOTO', 'PHOTO', 'VIDEO', 'VIDEO'],
            'íŒ”ë¡œì›Œ': [10000, 20000, 15000, 30000],
            'ë…¸ì¶œìˆ˜': [1000, 2000, 1500, 3000],
            'ì¢‹ì•„ìš”': [100, 200, 150, 300],
            'ëŒ“ê¸€ìˆ˜': [50, 100, 75, 150],
            'ì¡°íšŒìˆ˜': [5000, 10000, 7500, 15000],
            'ì „ì²´ë¹„ìš©': [100000, 200000, 150000, 300000]
        }
        
        template_df = pd.DataFrame(template_data)
        template_output = io.BytesIO()
        with pd.ExcelWriter(template_output, engine='openpyxl') as writer:
            template_df.to_excel(writer, index=False, sheet_name='ì§‘í–‰ë°ì´í„°í…œí”Œë¦¿')
        template_output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            data=template_output.getvalue(),
            file_name="ì¸í”Œë£¨ì–¸ì„œë°ì´í„°_í…œí”Œë¦¿.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # ì‚¬ìš© ê°€ì´ë“œ
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼:**")
        st.markdown("""
        - **ìœ í˜•**: ë°ì´í„° ìœ í˜• (ì¸í”Œë£¨ì–¸ì„œ, ë§ˆì¼€íŒ… ë“±)
        - **ì‹œì¦Œ**: ì‹œì¦Œ ì •ë³´ (25FW, 26SS ë“±)
        - **ì—…ë¡œë“œì¼**: ì—…ë¡œë“œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
        - **sns_id**: SNS ì•„ì´ë””
        """)
    
    with col2:
        # ì—…ë¡œë“œ ëª¨ë“œ ì„ íƒ ë° íŒŒì¼ ì—…ë¡œë“œ
        upload_mode_exec = st.radio("ì—…ë¡œë“œ ëª¨ë“œ", ["ì¶”ê°€", "êµì²´"], horizontal=True, key="exec_upload_mode")
        uploaded_file = st.file_uploader(
            "ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['xlsx', 'csv'],
            help="Excel ë˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="execution_upload"
        )
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                new_execution_df = pd.read_csv(uploaded_file)
            else:
                # ì—‘ì…€ íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
                excel_file = pd.ExcelFile(uploaded_file)
                sheet_names = excel_file.sheet_names
                
                # ëª¨ë“  ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ í†µí•©
                all_sheets_data = []
                for sheet_name in sheet_names:
                    try:
                        sheet_df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                        if not sheet_df.empty:
                            # ì‹œíŠ¸ëª…ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€ (ì„ íƒì‚¬í•­)
                            sheet_df['ì‹œíŠ¸ëª…'] = sheet_name
                            all_sheets_data.append(sheet_df)
                    except Exception as e:
                        st.warning(f"ì‹œíŠ¸ '{sheet_name}' ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                
                if all_sheets_data:
                    new_execution_df = pd.concat(all_sheets_data, ignore_index=True)
                    st.info(f"ğŸ“Š ì´ {len(sheet_names)}ê°œ ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤: {', '.join(sheet_names)}")
                else:
                    st.error("ì½ì„ ìˆ˜ ìˆëŠ” ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
            
            # ë°ì´í„° ê²€ì¦
            required_columns = ['ìœ í˜•', 'ì‹œì¦Œ', 'ì—…ë¡œë“œì¼', 'sns_id']
            missing_columns = [col for col in required_columns if col not in new_execution_df.columns]
            
            if missing_columns:
                st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
                st.info(f"ğŸ“‹ í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì»¬ëŸ¼: {list(new_execution_df.columns)}")
                st.info(f"ğŸ“‹ í•„ìš”í•œ í•„ìˆ˜ ì»¬ëŸ¼: {required_columns}")
                st.warning("ğŸ’¡ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.")
            else:
                # ì—…ë¡œë“œì¼ì—ì„œ ì›” ì¶”ì¶œí•˜ì—¬ ìº í˜ì¸ì›”, ì—…ë¡œë“œì›” ìë™ ì±„ìš°ê¸°
                if 'ì—…ë¡œë“œì¼' in new_execution_df.columns:
                    # ì—…ë¡œë“œì¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    new_execution_df['ì—…ë¡œë“œì¼'] = pd.to_datetime(new_execution_df['ì—…ë¡œë“œì¼'], errors='coerce')
                    
                    # ìº í˜ì¸ì›”ì´ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œì¼ì˜ ì›”ë¡œ ì±„ìš°ê¸°
                    if 'ìº í˜ì¸ì›”' in new_execution_df.columns:
                        mask_campaign = new_execution_df['ìº í˜ì¸ì›”'].isna() | (new_execution_df['ìº í˜ì¸ì›”'] == '') | (new_execution_df['ìº í˜ì¸ì›”'] == 0)
                        new_execution_df.loc[mask_campaign, 'ìº í˜ì¸ì›”'] = new_execution_df.loc[mask_campaign, 'ì—…ë¡œë“œì¼'].dt.month
                    
                    # ì—…ë¡œë“œì›”ì´ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œì¼ì˜ ì›”ë¡œ ì±„ìš°ê¸°
                    if 'ì—…ë¡œë“œì›”' in new_execution_df.columns:
                        mask_upload = new_execution_df['ì—…ë¡œë“œì›”'].isna() | (new_execution_df['ì—…ë¡œë“œì›”'] == '') | (new_execution_df['ì—…ë¡œë“œì›”'] == 0)
                        new_execution_df.loc[mask_upload, 'ì—…ë¡œë“œì›”'] = new_execution_df.loc[mask_upload, 'ì—…ë¡œë“œì¼'].dt.month
                
                # ì—…ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬ (ì¶”ê°€/êµì²´)
                if upload_mode_exec == "ì¶”ê°€":
                    existing = load_execution_data()
                    combined = pd.concat([existing, new_execution_df], ignore_index=True)
                    # ì¤‘ë³µ ì œê±° ê¸°ì¤€: ['ìœ í˜•','ë¸Œëœë“œ','ì‹œì¦Œ','ì—°ë„','ì—…ë¡œë“œì¼','sns_id','ìº í˜ì¸ëª…','ì»¨í…ì¸ URL'] ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
                    dedup_keys = [c for c in ['ìœ í˜•','ë¸Œëœë“œ','ì‹œì¦Œ','ì—°ë„','ì—…ë¡œë“œì¼','sns_id','ìº í˜ì¸ëª…','ì»¨í…ì¸ URL'] if c in combined.columns]
                    if dedup_keys:
                        combined = combined.drop_duplicates(subset=dedup_keys, keep='last')
                    save_execution_data(combined)
                else:
                    save_execution_data(new_execution_df)
                st.success("ì§‘í–‰ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ë§ˆì¼€íŒ… ë°ì´í„° ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ“Š ë§ˆì¼€íŒ… ë°ì´í„°")
    
    # ë§ˆì¼€íŒ… ë°ì´í„° í‘œì‹œ
    marketing_df = load_marketing_data()
    if not marketing_df.empty:
        st.success(f"ì´ {len(marketing_df)}ê±´ì˜ ë§ˆì¼€íŒ… ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„í„°
        col1, col2, col3 = st.columns(3)
        
        with col1:
            seasons = marketing_df['ì‹œì¦Œ'].unique() if 'ì‹œì¦Œ' in marketing_df.columns else []
            selected_marketing_season = st.selectbox("ğŸ“… ì‹œì¦Œ", ["ì „ì²´"] + list(seasons), key="marketing_season_filter")
        
        with col2:
            brands = marketing_df['ë¸Œëœë“œ'].unique() if 'ë¸Œëœë“œ' in marketing_df.columns else []
            selected_marketing_brand = st.selectbox("ğŸ·ï¸ ë¸Œëœë“œ", ["ì „ì²´"] + list(brands), key="marketing_brand_filter")
        
        with col3:
            # ì•„ì´í…œ í•„í„° (ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬)
            if 'ì•„ì´í…œ' in marketing_df.columns:
                # ëª¨ë“  ì•„ì´í…œ ê°’ì„ ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ê°œë³„ ì•„ì´í…œ ëª©ë¡ ìƒì„±
                all_items = []
                for items_str in marketing_df['ì•„ì´í…œ'].dropna():
                    if isinstance(items_str, str):
                        # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°
                        items = [item.strip() for item in items_str.split(',')]
                        all_items.extend(items)
                
                # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
                unique_items = sorted(list(set(all_items)))
                selected_marketing_items = st.multiselect(
                    "ğŸ“¦ ì•„ì´í…œ", 
                    unique_items, 
                    key="marketing_item_filter",
                    placeholder="ì•„ì´í…œì„ ì„ íƒí•˜ì„¸ìš”"
                )
            else:
                selected_marketing_items = []
        
        # ë°ì´í„° í•„í„°ë§
        filtered_marketing_df = marketing_df.copy()
        if selected_marketing_season != "ì „ì²´":
            filtered_marketing_df = filtered_marketing_df[filtered_marketing_df['ì‹œì¦Œ'] == selected_marketing_season]
        if selected_marketing_brand != "ì „ì²´":
            filtered_marketing_df = filtered_marketing_df[filtered_marketing_df['ë¸Œëœë“œ'] == selected_marketing_brand]
        
        # ì•„ì´í…œ í•„í„°ë§ (ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì„ íƒëœ ì•„ì´í…œê³¼ ì¼ì¹˜í•˜ë©´ í¬í•¨)
        if selected_marketing_items and 'ì•„ì´í…œ' in filtered_marketing_df.columns:
            def contains_selected_item(items_str):
                if pd.isna(items_str) or not isinstance(items_str, str):
                    return False
                items = [item.strip() for item in items_str.split(',')]
                return any(item in selected_marketing_items for item in items)
            
            filtered_marketing_df = filtered_marketing_df[filtered_marketing_df['ì•„ì´í…œ'].apply(contains_selected_item)]
        
        # ë°ì´í„° í‘œì‹œ
        # ì‹œíŠ¸ëª… ì»¬ëŸ¼ ì œê±° ë° ì•„ì´í…œ ì»¬ëŸ¼ ì¶”ê°€ (ë‚´ë¶€ ì²˜ë¦¬ìš©ì´ë¯€ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ)
        display_marketing_df = filtered_marketing_df.copy()
        if 'ì‹œíŠ¸ëª…' in display_marketing_df.columns:
            display_marketing_df = display_marketing_df.drop(columns=['ì‹œíŠ¸ëª…'])
        
        # ì•„ì´í…œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€ (ë©”ì¸ì œí’ˆ ì•ì— ìœ„ì¹˜)
        if 'ì•„ì´í…œ' not in display_marketing_df.columns:
            # ë©”ì¸ì œí’ˆ ì»¬ëŸ¼ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ ê·¸ ì•ì— ì•„ì´í…œ ì»¬ëŸ¼ ì¶”ê°€
            if 'ë©”ì¸ì œí’ˆ' in display_marketing_df.columns:
                main_product_idx = display_marketing_df.columns.get_loc('ë©”ì¸ì œí’ˆ')
                display_marketing_df.insert(main_product_idx, 'ì•„ì´í…œ', None)
            else:
                display_marketing_df['ì•„ì´í…œ'] = None
        
        st.dataframe(display_marketing_df, use_container_width=True)
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë° ë°ì´í„° ì‚­ì œ ë²„íŠ¼ (ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ì™€ ë™ì¼í•œ í˜•ì‹)
        col1, col2 = st.columns(2)
        
        with col1:
            # ì—‘ì…€ íŒŒì¼ ìƒì„± (ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬)
            download_df = display_marketing_df.copy()
            
            # í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œ ì •ì˜ (ì•„ì´í…œì´ ë©”ì¸ì œí’ˆ ì•ì— ì˜¤ë„ë¡)
            standard_columns = [
                'ìœ í˜•', 'ë¸Œëœë“œ', 'ì‹œì¦Œ', 'ì—°ë„', 'ìº í˜ì¸ì›”', 'ì—…ë¡œë“œì›”', 'ì—…ë¡œë“œì¼',
                'ì±„ë„', 'ì´ë¦„', 'sns_id', 'ìº í˜ì¸ëª…', 'ì•„ì´í…œ', 'ë©”ì¸ì œí’ˆ',
                'ì»¨í…ì¸ URL', 'ì»¨í…ì¸ ìœ í˜•', 'íŒ”ë¡œì›Œ', 'ë…¸ì¶œìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ì¡°íšŒìˆ˜', 'ì „ì²´ë¹„ìš©'
            ]
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ìˆœì„œ ì •ë¦¬
            existing_columns = [col for col in standard_columns if col in download_df.columns]
            other_columns = [col for col in download_df.columns if col not in standard_columns]
            final_columns = existing_columns + other_columns
            
            download_df = download_df[final_columns]
            
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                download_df.to_excel(writer, index=False, sheet_name='ë§ˆì¼€íŒ…ë°ì´í„°')
            output.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"ë§ˆì¼€íŒ…ë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="marketing_excel_download",
                use_container_width=True
            )
        
        with col2:
            if st.button("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ", key="marketing_delete", use_container_width=True):
                if os.path.exists(MARKETING_FILE):
                    os.remove(MARKETING_FILE)
                    st.success("ë§ˆì¼€íŒ… ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
    else:
        st.info("ë§ˆì¼€íŒ… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    # ë§ˆì¼€íŒ… ë°ì´í„° ì—…ë¡œë“œ ì„¹ì…˜
    st.markdown("---")
    st.markdown("### ğŸ“¤ ë§ˆì¼€íŒ… ë°ì´í„° ì—…ë¡œë“œ")
    
    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ (ë§ˆì¼€íŒ… ë°ì´í„° ì»¬ëŸ¼ êµ¬ì¡°)
        marketing_template_data = {
            'ìœ í˜•': ['ë§ˆì¼€íŒ…', 'ë§ˆì¼€íŒ…', 'ë§ˆì¼€íŒ…', 'ë§ˆì¼€íŒ…'],
            'ë¸Œëœë“œ': ['MLB', 'DX', 'DV', 'ST'],
            'ì‹œì¦Œ': ['25FW', '25FW', '25FW', '25FW'],
            'ì—°ë„': [2025, 2025, 2025, 2025],
            'ìº í˜ì¸ì›”': ['5ì›”', '5ì›”', '6ì›”', '6ì›”'],
            'ì—…ë¡œë“œì›”': ['5ì›”', '5ì›”', '6ì›”', '6ì›”'],
            'ì—…ë¡œë“œì¼': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'],
            'ì±„ë„': ['ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'ì¸ìŠ¤íƒ€ê·¸ë¨'],
            'ì´ë¦„': ['ë§ˆì¼€í„°1', 'ë§ˆì¼€í„°2', 'ë§ˆì¼€í„°3', 'ë§ˆì¼€í„°4'],
            'sns_id': ['marketer1', 'marketer2', 'marketer3', 'marketer4'],
            'ìº í˜ì¸ëª…': ['ë§ˆì¼€íŒ…ìº í˜ì¸1', 'ë§ˆì¼€íŒ…ìº í˜ì¸2', 'ë§ˆì¼€íŒ…ìº í˜ì¸3', 'ë§ˆì¼€íŒ…ìº í˜ì¸4'],
            'ì•„ì´í…œ': ['ì•„ì´í…œ1', 'ì•„ì´í…œ2', 'ì•„ì´í…œ3', 'ì•„ì´í…œ4'],
            'ë©”ì¸ì œí’ˆ': ['ì œí’ˆ1', 'ì œí’ˆ2', 'ì œí’ˆ3', 'ì œí’ˆ4'],
            'ì»¨í…ì¸ URL': ['https://instagram.com/1', 'https://instagram.com/2', 'https://instagram.com/3', 'https://instagram.com/4'],
            'ì»¨í…ì¸ ìœ í˜•': ['PHOTO', 'PHOTO', 'VIDEO', 'VIDEO'],
            'íŒ”ë¡œì›Œ': [10000, 20000, 15000, 30000],
            'ë…¸ì¶œìˆ˜': [1000, 2000, 1500, 3000],
            'ì¢‹ì•„ìš”': [100, 200, 150, 300],
            'ëŒ“ê¸€ìˆ˜': [50, 100, 75, 150],
            'ì¡°íšŒìˆ˜': [5000, 10000, 7500, 15000],
            'ì „ì²´ë¹„ìš©': [100000, 200000, 150000, 300000]
        }
        
        marketing_template_df = pd.DataFrame(marketing_template_data)
        marketing_template_output = io.BytesIO()
        with pd.ExcelWriter(marketing_template_output, engine='openpyxl') as writer:
            marketing_template_df.to_excel(writer, index=False, sheet_name='ë§ˆì¼€íŒ…ë°ì´í„°í…œí”Œë¦¿')
        marketing_template_output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ë§ˆì¼€íŒ… ë°ì´í„° í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            data=marketing_template_output.getvalue(),
            file_name="ë§ˆì¼€íŒ…ë°ì´í„°_í…œí”Œë¦¿.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # ì‚¬ìš© ê°€ì´ë“œ
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼:**")
        st.markdown("""
        - **ìœ í˜•**: ë°ì´í„° ìœ í˜• (ì¸í”Œë£¨ì–¸ì„œ, ë§ˆì¼€íŒ… ë“±)
        - **ì‹œì¦Œ**: ì‹œì¦Œ ì •ë³´ (25FW, 26SS ë“±)
        - **ì—…ë¡œë“œì¼**: ì—…ë¡œë“œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
        - **sns_id**: SNS ì•„ì´ë””
        """)
    
    with col2:
        # ì—…ë¡œë“œ ëª¨ë“œ ì„ íƒ ë° íŒŒì¼ ì—…ë¡œë“œ
        upload_mode_mkt = st.radio("ì—…ë¡œë“œ ëª¨ë“œ", ["ì¶”ê°€", "êµì²´"], horizontal=True, key="mkt_upload_mode")
        marketing_uploaded_file = st.file_uploader(
            "ë§ˆì¼€íŒ… ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['xlsx', 'csv'],
            help="Excel ë˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="marketing_upload"
        )
    
    if marketing_uploaded_file is not None:
        try:
            if marketing_uploaded_file.name.endswith('.csv'):
                new_marketing_df = pd.read_csv(marketing_uploaded_file)
            else:
                # ì—‘ì…€ íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
                excel_file = pd.ExcelFile(marketing_uploaded_file)
                sheet_names = excel_file.sheet_names
                
                # ëª¨ë“  ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ í†µí•©
                all_sheets_data = []
                for sheet_name in sheet_names:
                    try:
                        sheet_df = pd.read_excel(marketing_uploaded_file, sheet_name=sheet_name)
                        if not sheet_df.empty:
                            # ì‹œíŠ¸ëª…ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€ (ì„ íƒì‚¬í•­)
                            sheet_df['ì‹œíŠ¸ëª…'] = sheet_name
                            all_sheets_data.append(sheet_df)
                    except Exception as e:
                        st.warning(f"ì‹œíŠ¸ '{sheet_name}' ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                
                if all_sheets_data:
                    new_marketing_df = pd.concat(all_sheets_data, ignore_index=True)
                    st.info(f"ğŸ“Š ì´ {len(sheet_names)}ê°œ ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤: {', '.join(sheet_names)}")
                else:
                    st.error("ì½ì„ ìˆ˜ ìˆëŠ” ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
            
            # ë°ì´í„° ê²€ì¦
            required_columns = ['ìœ í˜•', 'ì‹œì¦Œ', 'ì—…ë¡œë“œì¼', 'sns_id']
            missing_columns = [col for col in required_columns if col not in new_marketing_df.columns]
            
            if missing_columns:
                st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
                st.info(f"ğŸ“‹ í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì»¬ëŸ¼: {list(new_marketing_df.columns)}")
                st.info(f"ğŸ“‹ í•„ìš”í•œ í•„ìˆ˜ ì»¬ëŸ¼: {required_columns}")
                st.warning("ğŸ’¡ ë§ˆì¼€íŒ… ë°ì´í„° í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.")
            else:
                # ì—…ë¡œë“œì¼ì—ì„œ ì›” ì¶”ì¶œí•˜ì—¬ ìº í˜ì¸ì›”, ì—…ë¡œë“œì›” ìë™ ì±„ìš°ê¸°
                if 'ì—…ë¡œë“œì¼' in new_marketing_df.columns:
                    # ì—…ë¡œë“œì¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    new_marketing_df['ì—…ë¡œë“œì¼'] = pd.to_datetime(new_marketing_df['ì—…ë¡œë“œì¼'], errors='coerce')
                    
                    # ìº í˜ì¸ì›”ì´ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œì¼ì˜ ì›”ë¡œ ì±„ìš°ê¸°
                    if 'ìº í˜ì¸ì›”' in new_marketing_df.columns:
                        mask_campaign = new_marketing_df['ìº í˜ì¸ì›”'].isna() | (new_marketing_df['ìº í˜ì¸ì›”'] == '') | (new_marketing_df['ìº í˜ì¸ì›”'] == 0)
                        new_marketing_df.loc[mask_campaign, 'ìº í˜ì¸ì›”'] = new_marketing_df.loc[mask_campaign, 'ì—…ë¡œë“œì¼'].dt.month
                    
                    # ì—…ë¡œë“œì›”ì´ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œì¼ì˜ ì›”ë¡œ ì±„ìš°ê¸°
                    if 'ì—…ë¡œë“œì›”' in new_marketing_df.columns:
                        mask_upload = new_marketing_df['ì—…ë¡œë“œì›”'].isna() | (new_marketing_df['ì—…ë¡œë“œì›”'] == '') | (new_marketing_df['ì—…ë¡œë“œì›”'] == 0)
                        new_marketing_df.loc[mask_upload, 'ì—…ë¡œë“œì›”'] = new_marketing_df.loc[mask_upload, 'ì—…ë¡œë“œì¼'].dt.month
                
                # ì—…ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬ (ì¶”ê°€/êµì²´)
                if upload_mode_mkt == "ì¶”ê°€":
                    existing = load_marketing_data()
                    combined = pd.concat([existing, new_marketing_df], ignore_index=True)
                    dedup_keys = [c for c in ['ìœ í˜•','ë¸Œëœë“œ','ì‹œì¦Œ','ì—°ë„','ì—…ë¡œë“œì¼','sns_id','ìº í˜ì¸ëª…','ì»¨í…ì¸ URL'] if c in combined.columns]
                    if dedup_keys:
                        combined = combined.drop_duplicates(subset=dedup_keys, keep='last')
                    save_marketing_data(combined)
                else:
                    save_marketing_data(new_marketing_df)
                st.success("ë§ˆì¼€íŒ… ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ’° ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬")
    
    
    # ë§¤ì¶œ ë°ì´í„° í‘œì‹œ
    sales_df = load_sales_data()
    if not sales_df.empty:
        st.markdown("### ğŸ“Š ë§¤ì¶œ ë°ì´í„°")
        st.success(f"ì´ {len(sales_df)}ê±´ì˜ ë§¤ì¶œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„í„°
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'BRD_CD' in sales_df.columns:
                valid_brands = ['M', 'X', 'V', 'ST']
                sales_df_filtered = sales_df[sales_df['BRD_CD'].isin(valid_brands)]
                brand_mapping = {'M': 'MLB', 'X': 'DX', 'V': 'DV', 'ST': 'ST'}
                unique_brands = sales_df_filtered['BRD_CD'].unique()
                brand_names = [brand_mapping.get(brand, brand) for brand in unique_brands]
                brand_order = ['MLB', 'DX', 'DV', 'ST']
                ordered_brands = [brand for brand in brand_order if brand in brand_names]
                selected_brd = st.selectbox("ğŸ·ï¸ ë¸Œëœë“œ", ordered_brands, key="execution_sales_brand_filter")
            else:
                selected_brd = "MLB"
        
        with col2:
            if 'DT' in sales_df.columns:
                sales_df['ì›”'] = pd.to_datetime(sales_df['DT']).dt.to_period('M')
                months = sorted(sales_df['ì›”'].unique())
                selected_month = st.selectbox("ğŸ“… ì›”", months, key="execution_sales_month_filter")
            else:
                selected_month = None
        
        with col3:
            if 'ITEM_NM' in sales_df.columns:
                categories = sales_df['ITEM_NM'].unique()
                selected_item = st.selectbox("ğŸ“¦ ì¹´í…Œê³ ë¦¬", ["ì „ì²´"] + list(categories), key="execution_sales_item_filter")
            else:
                selected_item = "ì „ì²´"
        
        # ë°ì´í„° í•„í„°ë§
        filtered_sales_df = sales_df.copy()
        if 'BRD_CD' in sales_df.columns:
            brand_reverse_mapping = {'MLB': 'M', 'DX': 'X', 'DV': 'V', 'ST': 'ST'}
            brand_code = brand_reverse_mapping.get(selected_brd, selected_brd)
            filtered_sales_df = filtered_sales_df[filtered_sales_df['BRD_CD'] == brand_code]
        
        if selected_month and 'ì›”' in sales_df.columns:
            filtered_sales_df = filtered_sales_df[filtered_sales_df['ì›”'] == selected_month]
        
        if selected_item != "ì „ì²´" and 'ITEM_NM' in sales_df.columns:
            filtered_sales_df = filtered_sales_df[filtered_sales_df['ITEM_NM'] == selected_item]
        
        # í‘œì‹œìš© ë°ì´í„° ì¤€ë¹„
        display_sales_df = filtered_sales_df.copy()
        if 'DT' in display_sales_df.columns:
            display_sales_df['DT'] = pd.to_datetime(display_sales_df['DT'], errors='coerce').dt.date
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        column_order = ['BRD_CD', 'DT', 'ITEM', 'ITEM_NM', 'SALE_AMT_TY', 'SALE_QTY_TY', 'SALE_AMT_LY', 'SALE_QTY_LY']
        available_columns = [col for col in column_order if col in display_sales_df.columns]
        display_sales_df = display_sales_df[available_columns]
        
        st.dataframe(display_sales_df, use_container_width=True)
        
        # ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬ ì˜µì…˜
        col1, col2 = st.columns(2)
        
        with col1:
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                display_sales_df.to_excel(writer, index=False, sheet_name='ë§¤ì¶œë°ì´í„°')
            output.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ë§¤ì¶œ ë°ì´í„° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"ë§¤ì¶œë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        
        with col2:
            if st.button("ğŸ—‘ï¸ ë§¤ì¶œ ë°ì´í„° ì‚­ì œ", use_container_width=True):
                # ë¨¼ì € ìºì‹œ ì´ˆê¸°í™”
                st.cache_data.clear()
                
                deleted_files = []
                if os.path.exists(SALES_FILE):
                    os.remove(SALES_FILE)
                    deleted_files.append("sales_data.csv")
                
                # ëª¨ë“  ë§¤ì¶œ ë°ì´í„° íŒŒì¼ ì‚­ì œ
                import glob
                sales_files = glob.glob(os.path.join(DATA_DIR, "*sales*.csv"))
                for file in sales_files:
                    if os.path.exists(file):
                        os.remove(file)
                        deleted_files.append(os.path.basename(file))
                
                if deleted_files:
                    st.success(f"âœ… ë‹¤ìŒ íŒŒì¼ë“¤ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(deleted_files)}")
                    # ì¦‰ì‹œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.rerun()
                else:
                    st.info("ì‚­ì œí•  ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë§¤ì¶œ ë°ì´í„° ì—…ë¡œë“œ
    st.markdown("---")
    st.markdown("### ğŸ“¤ ë§¤ì¶œ ë°ì´í„° ì—…ë¡œë“œ")
    
    # Snowflake ì—°ë™ ì„¹ì…˜
    if SNOWFLAKE_AVAILABLE:
        st.markdown("#### â„ï¸ Snowflake ì—°ë™")

        # 2ì—´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë‚˜ë€íˆ ë°°ì¹˜
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # Snowflake ì—°ê²° ìƒíƒœ ë° ì •ë³´
            with st.expander("â„¹ï¸ Snowflake ì—°ê²° ì •ë³´ & ì¿¼ë¦¬ ê´€ë¦¬", expanded=False):
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                conn = get_snowflake_connection()
                if conn:
                    try:
                        # ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        account = conn.account
                        user = conn.user
                        database = conn.database
                        schema = conn.schema
                        warehouse = conn.warehouse
                        
                        st.success("âœ… Snowflake ì—°ê²°ë¨")
                        st.markdown(f"""
                        **ì—°ê²° ì •ë³´:**
                        - **Account**: {account}
                        - **User**: {user}
                        - **Database**: {database}
                        - **Schema**: {schema}
                        - **Warehouse**: {warehouse}
                        """)
                        
                        # í…Œì´ë¸” ì •ë³´ í™•ì¸
                        try:
                            cursor = conn.cursor()
                            cursor.execute("SHOW TABLES LIKE 'SALES_DATA'")
                            tables = cursor.fetchall()
                            if tables:
                                st.info("âœ… sales_data í…Œì´ë¸” í™•ì¸ë¨")
                            else:
                                st.warning("âš ï¸ sales_data í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            cursor.close()
                        except Exception as e:
                            st.warning(f"âš ï¸ í…Œì´ë¸” ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
                        
                        # ì—°ê²°ì„ ë‹«ì§€ ì•Šê³  ìœ ì§€
                        # conn.close() ì œê±°
                        
                    except Exception as e:
                        st.error(f"âŒ ì—°ê²° ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                        if conn:
                            conn.close()
                else:
                    st.error("âŒ Snowflake ì—°ê²° ì‹¤íŒ¨")
                    st.markdown("""
                    **ì—°ê²° ì„¤ì • ë°©ë²•:**
                    1. `.streamlit/secrets.toml` íŒŒì¼ì— ë‹¤ìŒ ì •ë³´ë¥¼ ì„¤ì •í•˜ì„¸ìš”:
                    ```toml
                    [snowflake]
                    account = "your_account"
                    user = "your_username"
                    password = "your_password"
                    database = "your_database"
                    schema = "your_schema"
                    warehouse = "your_warehouse"
                    ```
                    2. í•„ìš”í•œ í…Œì´ë¸”: `sales_data` (BRD_CD, DT, ITEM, ITEM_NM, SALE_AMT_TY, SALE_QTY_TY, SALE_AMT_LY, SALE_QTY_LY ì»¬ëŸ¼ í¬í•¨)
                    """)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸ ë²„íŠ¼
                st.markdown("---")
                if st.button("ğŸ”— Snowflake ì—°ê²° í…ŒìŠ¤íŠ¸", use_container_width=True, key="sales_snowflake_connection_test"):
                    conn = get_snowflake_connection()
                    if conn:
                        st.success("âœ… Snowflake ì—°ê²° ì„±ê³µ!")
                        conn.close()
                    else:
                        st.error("âŒ Snowflake ì—°ê²° ì‹¤íŒ¨")
                
                # ì¿¼ë¦¬ ê´€ë¦¬ ì„¹ì…˜
                st.markdown("---")
                st.markdown("#### ğŸ”§ ì¿¼ë¦¬ ê´€ë¦¬")
                
                col_query1, col_query2 = st.columns([1, 1])
                
                with col_query1:
                    if st.button("ğŸ“‹ í˜„ì¬ ì¿¼ë¦¬ í™•ì¸", use_container_width=True, key="sales_current_query_check"):
                        st.markdown("**í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ Snowflake ì¿¼ë¦¬:**")
                        
                        # ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¿¼ë¦¬ í‘œì‹œ
                        if hasattr(st.session_state, 'custom_query') and st.session_state.custom_query:
                            st.code(st.session_state.custom_query, language='sql')
                            st.success("âœ… ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ê°€ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ë³¸ ì¿¼ë¦¬ í•¨ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                            current_query = get_default_sales_query()
                            st.code(current_query, language='sql')
                            st.info("â„¹ï¸ ê¸°ë³¸ ì¿¼ë¦¬ê°€ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
                
                with col_query2:
                    if st.button("âœï¸ ì¿¼ë¦¬ ìˆ˜ì •", use_container_width=True, key="sales_query_edit"):
                        st.session_state.show_query_editor = True
                
                # ì¿¼ë¦¬ ìˆ˜ì • ì—ë””í„°
                if st.session_state.get('show_query_editor', False):
                    st.markdown("**ì¿¼ë¦¬ ìˆ˜ì •:**")
                    st.warning("âš ï¸ ì¿¼ë¦¬ ìˆ˜ì •ì€ ê³ ê¸‰ ì‚¬ìš©ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ëª»ëœ ì¿¼ë¦¬ëŠ” ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ê¸°ë³¸ ì¿¼ë¦¬ í•¨ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    default_query = get_default_sales_query()
                    
                    modified_query = st.text_area(
                        "ìˆ˜ì •í•  ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                        value=default_query,
                        height=400,
                        help="í•„ìˆ˜ ì»¬ëŸ¼: BRD_CD, DT, ITEM, ITEM_NM, SALE_AMT_TY, SALE_QTY_TY, SALE_AMT_LY, SALE_QTY_LY"
                    )
                    
                    col_save, col_cancel = st.columns([1, 1])
                    
                    with col_save:
                        if st.button("ğŸ’¾ ì¿¼ë¦¬ ì €ì¥", use_container_width=True, key="sales_query_save"):
                            # ì¿¼ë¦¬ë¥¼ ì„¸ì…˜ì— ì €ì¥ (ì‹¤ì œë¡œëŠ” íŒŒì¼ì— ì €ì¥í•˜ê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥)
                            st.session_state.custom_query = modified_query
                            # ê¸°ë³¸ ì¿¼ë¦¬ë„ ì—…ë°ì´íŠ¸ (ë‹¤ìŒì— ê¸°ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œ ë°˜ì˜ë¨)
                            st.session_state.default_sales_query = modified_query
                            st.success("ì¿¼ë¦¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.session_state.show_query_editor = False
                            st.rerun()
                    
                    with col_cancel:
                        if st.button("âŒ ì·¨ì†Œ", use_container_width=True, key="sales_query_cancel"):
                            st.session_state.show_query_editor = False
                            st.rerun()
        
        with col2:
            # Snowflake ì‘ì—… ë²„íŠ¼
            if st.button("ğŸ”„ Snowflakeì—ì„œ ë§¤ì¶œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True, key="sales_snowflake_load"):
                with st.spinner("Snowflakeì—ì„œ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    snowflake_sales_df = load_snowflake_sales_data()
                    if not snowflake_sales_df.empty:
                        # Snowflake ë°ì´í„°ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
                        save_sales_data(snowflake_sales_df)
                        st.success(f"âœ… Snowflakeì—ì„œ {len(snowflake_sales_df)}ê±´ì˜ ë§¤ì¶œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("âŒ Snowflakeì—ì„œ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì—‘ì…€ ì—…ë¡œë“œ ì„¹ì…˜
    st.markdown("#### ğŸ“Š ì—‘ì…€ ì—…ë¡œë“œ")
    
    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # ë§¤ì¶œ ë°ì´í„° í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ
        sales_template_data = {
            'BRD_CD': ['M', 'X', 'V', 'ST'],
            'DT': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'],
            'ITEM': ['A001', 'A002', 'A003', 'A004'],
            'ITEM_NM': ['ì¹´í…Œê³ ë¦¬1', 'ì¹´í…Œê³ ë¦¬2', 'ì¹´í…Œê³ ë¦¬3', 'ì¹´í…Œê³ ë¦¬4'],
            'SALE_AMT_TY': [1000000, 2000000, 1500000, 3000000],
            'SALE_QTY_TY': [100, 200, 150, 300],
            'SALE_AMT_LY': [800000, 1800000, 1200000, 2500000],
            'SALE_QTY_LY': [80, 180, 120, 250]
        }
        
        sales_template_df = pd.DataFrame(sales_template_data)
        sales_template_output = io.BytesIO()
        with pd.ExcelWriter(sales_template_output, engine='openpyxl') as writer:
            sales_template_df.to_excel(writer, index=False, sheet_name='ë§¤ì¶œë°ì´í„°í…œí”Œë¦¿')
        sales_template_output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ë§¤ì¶œ ë°ì´í„° í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            data=sales_template_output.getvalue(),
            file_name="ë§¤ì¶œë°ì´í„°_í…œí”Œë¦¿.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # ë§¤ì¶œ ë°ì´í„° ì‚¬ìš© ê°€ì´ë“œ
        st.markdown("**í•„ìˆ˜ ì»¬ëŸ¼:**")
        st.markdown("""
        - BRD_CD: ë¸Œëœë“œ ì½”ë“œ (M=MLB, X=DX, V=DV, ST=ST)
        - DT: ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
        - ITEM: ì¹´í…Œê³ ë¦¬ ì½”ë“œ
        - ITEM_NM: ì¹´í…Œê³ ë¦¬ëª…
        - SALE_AMT_TY: ì˜¬í•´ ë§¤ì¶œì•¡
        - SALE_QTY_TY: ì˜¬í•´ íŒë§¤ìˆ˜ëŸ‰
        - SALE_AMT_LY: ì‘ë…„ ë§¤ì¶œì•¡
        - SALE_QTY_LY: ì‘ë…„ íŒë§¤ìˆ˜ëŸ‰
        """)
    
    with col2:
        # ë§¤ì¶œ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ
        sales_uploaded_file = st.file_uploader(
            "ë§¤ì¶œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['xlsx', 'csv'],
            help="Excel ë˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="sales_upload"
        )
    
    if sales_uploaded_file is not None:
        try:
            if sales_uploaded_file.name.endswith('.csv'):
                new_sales_df = pd.read_csv(sales_uploaded_file)
            else:
                new_sales_df = pd.read_excel(sales_uploaded_file)
            
            # ë°ì´í„° ê²€ì¦
            required_columns = ['BRD_CD', 'DT', 'ITEM', 'ITEM_NM', 'SALE_AMT_TY', 'SALE_QTY_TY', 'SALE_AMT_LY', 'SALE_QTY_LY']
            missing_columns = [col for col in required_columns if col not in new_sales_df.columns]
            
            if missing_columns:
                st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            else:
                # ë°ì´í„° ì €ì¥
                save_sales_data(new_sales_df)
                st.success("ë§¤ì¶œ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—…ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
    st.markdown("---")
    st.markdown("### ğŸ“¤ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—…ë¡œë“œ")
    
    # Snowflake ì—°ë™ ì„¹ì…˜
    if SNOWFLAKE_AVAILABLE:
        st.markdown("#### â„ï¸ Snowflake ì—°ë™")
        
        # 2ì—´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë‚˜ë€íˆ ë°°ì¹˜
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # Snowflake ì—°ê²° ìƒíƒœ ë° ì •ë³´
            with st.expander("â„¹ï¸ Snowflake ì—°ê²° ì •ë³´ & ì¿¼ë¦¬ ê´€ë¦¬", expanded=False):
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                conn = get_snowflake_connection()
                if conn:
                    try:
                        # ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        account = conn.account
                        user = conn.user
                        database = conn.database
                        schema = conn.schema
                        warehouse = conn.warehouse
                        
                        st.success("âœ… Snowflake ì—°ê²°ë¨")
                        st.markdown(f"""
                        **ì—°ê²° ì •ë³´:**
                        - **Account**: {account}
                        - **User**: {user}
                        - **Database**: {database}
                        - **Schema**: {schema}
                        - **Warehouse**: {warehouse}
                        """)
                        
                        # í…Œì´ë¸” ì •ë³´ í™•ì¸
                        try:
                            cursor = conn.cursor()
                            cursor.execute("SHOW TABLES LIKE 'DB_srch_kwd_naver_w'")
                            tables = cursor.fetchall()
                            if tables:
                                st.info("âœ… PRCS.DB_srch_kwd_naver_w í…Œì´ë¸” í™•ì¸ë¨")
                            else:
                                st.warning("âš ï¸ PRCS.DB_srch_kwd_naver_w í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            cursor.close()
                        except Exception as e:
                            st.warning(f"âš ï¸ í…Œì´ë¸” ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
                        
                        # ì—°ê²°ì„ ë‹«ì§€ ì•Šê³  ìœ ì§€
                        # conn.close() ì œê±°
                        
                    except Exception as e:
                        st.error(f"âŒ ì—°ê²° ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                        if conn:
                            conn.close()
                else:
                    st.error("âŒ Snowflake ì—°ê²° ì‹¤íŒ¨")
                    st.markdown("""
                    **ì—°ê²° ì„¤ì • ë°©ë²•:**
                    1. `.streamlit/secrets.toml` íŒŒì¼ì— ë‹¤ìŒ ì •ë³´ë¥¼ ì„¤ì •í•˜ì„¸ìš”:
                    ```toml
                    [snowflake]
                    account = "your_account"
                    user = "your_username"
                    password = "your_password"
                    database = "your_database"
                    schema = "your_schema"
                    warehouse = "your_warehouse"
                    ```
                    2. í•„ìš”í•œ í…Œì´ë¸”: `PRCS.DB_srch_kwd_naver_w` (START_DT, END_DT, A-Z KWD, A-Z DVC, 123 SRCH_CNT ì»¬ëŸ¼ í¬í•¨)
                    """)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸ ë²„íŠ¼
                st.markdown("---")
                if st.button("ğŸ”— Snowflake ì—°ê²° í…ŒìŠ¤íŠ¸", use_container_width=True, key="search_snowflake_connection_test"):
                    conn = get_snowflake_connection()
                    if conn:
                        st.success("âœ… Snowflake ì—°ê²° ì„±ê³µ!")
                        conn.close()
                    else:
                        st.error("âŒ Snowflake ì—°ê²° ì‹¤íŒ¨")
                
                # ì¿¼ë¦¬ ê´€ë¦¬ ì„¹ì…˜
                st.markdown("---")
                st.markdown("#### ğŸ”§ ì¿¼ë¦¬ ê´€ë¦¬")
                
                col_query1, col_query2 = st.columns([1, 1])
                
                with col_query1:
                    if st.button("ğŸ“‹ í˜„ì¬ ì¿¼ë¦¬ í™•ì¸", use_container_width=True, key="search_current_query_check"):
                        st.markdown("**í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ Snowflake ì¿¼ë¦¬:**")
                        
                        # ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¿¼ë¦¬ í‘œì‹œ
                        if hasattr(st.session_state, 'custom_search_query') and st.session_state.custom_search_query:
                            st.code(st.session_state.custom_search_query, language='sql')
                            st.success("âœ… ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ê°€ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ë³¸ ì¿¼ë¦¬ í•¨ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                            current_query = get_default_search_query()
                            st.code(current_query, language='sql')
                            st.info("â„¹ï¸ ê¸°ë³¸ ì¿¼ë¦¬ê°€ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
                
                with col_query2:
                    if st.button("âœï¸ ì¿¼ë¦¬ ìˆ˜ì •", use_container_width=True, key="search_query_edit"):
                        st.session_state.show_search_query_editor = True
                
                # ì¿¼ë¦¬ ìˆ˜ì • ì—ë””í„°
                if st.session_state.get('show_search_query_editor', False):
                    st.markdown("**ì¿¼ë¦¬ ìˆ˜ì •:**")
                    st.warning("âš ï¸ ì¿¼ë¦¬ ìˆ˜ì •ì€ ê³ ê¸‰ ì‚¬ìš©ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ëª»ëœ ì¿¼ë¦¬ëŠ” ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ê¸°ë³¸ ì¿¼ë¦¬ í•¨ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    default_query = get_default_search_query()
                    
                    # ì¿¼ë¦¬ ì—ë””í„°
                    edited_query = st.text_area(
                        "SQL ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”:",
                        value=st.session_state.get('custom_search_query', default_query),
                        height=400,
                        help="ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•œ í›„ 'ì €ì¥' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
                    )
                    
                    # ì €ì¥/ì·¨ì†Œ ë²„íŠ¼
                    col_save, col_cancel = st.columns([1, 1])
                    
                    with col_save:
                        if st.button("ğŸ’¾ ì €ì¥", use_container_width=True, key="search_query_save"):
                            st.session_state.custom_search_query = edited_query
                            # ê¸°ë³¸ ì¿¼ë¦¬ë„ ì—…ë°ì´íŠ¸ (ë‹¤ìŒì— ê¸°ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œ ë°˜ì˜ë¨)
                            st.session_state.default_search_query = edited_query
                            # íŒŒì¼ì—ë„ ì €ì¥
                            if save_search_query(edited_query):
                                st.success("ì¿¼ë¦¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (íŒŒì¼ì— ì˜êµ¬ ì €ì¥ë¨)")
                            st.session_state.show_search_query_editor = False
                            st.rerun()
                    
                    with col_cancel:
                        if st.button("âŒ ì·¨ì†Œ", use_container_width=True, key="search_query_cancel"):
                            st.session_state.show_search_query_editor = False
                            st.rerun()
        
        with col2:
            # Snowflake ì‘ì—… ë²„íŠ¼
            if st.button("ğŸ”„ Snowflakeì—ì„œ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True, key="search_snowflake_load"):
                with st.spinner("Snowflakeì—ì„œ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                    if os.path.exists(SEARCH_FILE):
                        os.remove(SEARCH_FILE)
                        st.info("ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
                    
                    # ì „ì²´ ë°ì´í„° ìƒˆë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
                    start_date_str = '2024-09-02'
                    end_date_str = datetime.now().strftime('%Y-%m-%d')
                    
                    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¿¼ë¦¬ í™•ì¸ (ìš°ì„ ìˆœìœ„: custom > default > íŒŒì¼ > í•˜ë“œì½”ë”©)
                    current_query = None
                    if hasattr(st.session_state, 'custom_search_query') and st.session_state.custom_search_query:
                        current_query = st.session_state.custom_search_query
                        st.info("âœ… ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    elif hasattr(st.session_state, 'default_search_query') and st.session_state.default_search_query:
                        current_query = st.session_state.default_search_query
                        st.info("âœ… ì €ì¥ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    else:
                        # íŒŒì¼ì—ì„œ ì €ì¥ëœ ì¿¼ë¦¬ ë¡œë“œ ì‹œë„
                        saved_query = load_search_query()
                        if saved_query:
                            st.session_state.default_search_query = saved_query
                            current_query = saved_query
                            st.info(f"âœ… íŒŒì¼ì—ì„œ ì €ì¥ëœ ì¿¼ë¦¬ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ({SEARCH_QUERY_FILE})")
                        else:
                            # ìµœí›„ì˜ ìˆ˜ë‹¨: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì¿¼ë¦¬
                            default_query = get_default_search_query()
                            st.session_state.default_search_query = default_query
                            current_query = default_query
                            st.info("â„¹ï¸ ê¸°ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì¿¼ë¦¬ ìˆ˜ì •í•˜ê¸°ì—ì„œ ì €ì¥í•˜ë©´ íŒŒì¼ì— ì˜êµ¬ ì €ì¥ë©ë‹ˆë‹¤)")
                    
                    # ì¿¼ë¦¬ ë¯¸ë¦¬ë³´ê¸° (ë””ë²„ê¹…ìš©)
                    with st.expander("ğŸ” ì‚¬ìš© ì¤‘ì¸ ì¿¼ë¦¬ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                        st.code(current_query, language='sql')
                    
                    snowflake_search_df = load_snowflake_search_data(start_date_str, end_date_str)
                    if not snowflake_search_df.empty:
                        # ìƒˆ ë°ì´í„°ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
                        save_search_data(snowflake_search_df)
                        # session_stateì—ë„ ì €ì¥
                        st.session_state.search_data = snowflake_search_df
                        st.success(f"âœ… Snowflakeì—ì„œ {len(snowflake_search_df)}ê±´ì˜ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("âŒ Snowflakeì—ì„œ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê²€ìƒ‰ëŸ‰ ë°ì´í„° í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ“Š ê²€ìƒ‰ëŸ‰ ë°ì´í„°")
    
    # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¡œë“œ
    search_df = load_search_data()
    
    if not search_df.empty:
        st.success(f"ì´ {len(search_df)}ê±´ì˜ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„í„°
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ·ï¸ ë¸Œëœë“œ**")
            if 'BRAND_CODE' in search_df.columns:
                brand_col = 'BRAND_CODE'
                # ë¸Œëœë“œ ì½”ë“œë¥¼ ë¸Œëœë“œëª…ìœ¼ë¡œ ë§¤í•‘
                brand_mapping = {
                    'M': 'MLB',
                    'X': 'DX', 
                    'V': 'DV',
                    'ST': 'ST'
                }
                unique_brands = search_df[brand_col].unique()
                # M, X, V, STë§Œ í•„í„°ë§í•˜ê³  ë¸Œëœë“œëª…ìœ¼ë¡œ ë³€í™˜
                filtered_brands = [b for b in unique_brands if b in brand_mapping]
                brand_options = ['ì „ì²´'] + [brand_mapping[b] for b in sorted(filtered_brands)]
                selected_brand = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", brand_options, key="search_brand_filter", label_visibility="collapsed")
                # ì„ íƒëœ ë¸Œëœë“œëª…ì„ ë‹¤ì‹œ ì½”ë“œë¡œ ë³€í™˜
                if selected_brand != "ì „ì²´":
                    selected_brand = next(k for k, v in brand_mapping.items() if v == selected_brand)
            elif 'BRD_CD' in search_df.columns:
                brand_col = 'BRD_CD'
                brand_mapping = {
                    'M': 'MLB',
                    'X': 'DX', 
                    'V': 'DV',
                    'ST': 'ST'
                }
                unique_brands = search_df[brand_col].unique()
                filtered_brands = [b for b in unique_brands if b in brand_mapping]
                brand_options = ['ì „ì²´'] + [brand_mapping[b] for b in sorted(filtered_brands)]
                selected_brand = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", brand_options, key="search_brand_filter", label_visibility="collapsed")
                if selected_brand != "ì „ì²´":
                    selected_brand = next(k for k, v in brand_mapping.items() if v == selected_brand)
            elif 'brand_code' in search_df.columns:
                brand_col = 'brand_code'
                brand_mapping = {
                    'M': 'MLB',
                    'X': 'DX', 
                    'V': 'DV',
                    'ST': 'ST'
                }
                unique_brands = search_df[brand_col].unique()
                filtered_brands = [b for b in unique_brands if b in brand_mapping]
                brand_options = ['ì „ì²´'] + [brand_mapping[b] for b in sorted(filtered_brands)]
                selected_brand = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", brand_options, key="search_brand_filter", label_visibility="collapsed")
                if selected_brand != "ì „ì²´":
                    selected_brand = next(k for k, v in brand_mapping.items() if v == selected_brand)
            else:
                st.error("ë¸Œëœë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                selected_brand = "ì „ì²´"
        
        with col2:
            st.markdown("**ğŸ“… ì‹œì‘ë‚ ì§œ**")
            if 'START_DT' in search_df.columns:
                unique_dates = sorted(search_df['START_DT'].unique())
                date_options = ['ì „ì²´'] + [str(date) for date in unique_dates]
                selected_date = st.selectbox("ì‹œì‘ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”", date_options, key="search_date_filter", label_visibility="collapsed")
            else:
                selected_date = "ì „ì²´"
        
        # ë°ì´í„° í•„í„°ë§
        filtered_search_df = search_df.copy()
        
        # ë¸Œëœë“œ í•„í„°ë§
        if selected_brand != "ì „ì²´" and brand_col in filtered_search_df.columns:
            filtered_search_df = filtered_search_df[filtered_search_df[brand_col] == selected_brand]
        
        # ë‚ ì§œ í•„í„°ë§ (íƒ€ì… ë³€í™˜ ì²˜ë¦¬)
        if selected_date != "ì „ì²´" and 'START_DT' in filtered_search_df.columns:
            # ë‚ ì§œ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
            filtered_search_df['START_DT_str'] = filtered_search_df['START_DT'].astype(str)
            filtered_search_df = filtered_search_df[filtered_search_df['START_DT_str'] == selected_date]
            filtered_search_df = filtered_search_df.drop('START_DT_str', axis=1)  # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
        
        # í•„í„°ë§ëœ ë°ì´í„° í‘œì‹œ
        if not filtered_search_df.empty:
            st.markdown(f"**í•„í„°ë§ëœ ë°ì´í„°: {len(filtered_search_df)}ê±´**")
            
            # ì»¬ëŸ¼ëª… í•œêµ­ì–´ë¡œ ë³€ê²½
            display_df = filtered_search_df.copy()
            column_mapping = {
                'rank': 'ìˆœìœ„',
                'search_keyword': 'ê²€ìƒ‰ì–´',
                'yoy_change_pct': 'ì „ë…„ëŒ€ë¹„ ì¦ê°ë¥ (%)',
                'period_search_cnt': 'ê¸°ê°„ ê²€ìƒ‰ëŸ‰',
                'category': 'ì¹´í…Œê³ ë¦¬',
                'sub_category': 'í•˜ìœ„ ì¹´í…Œê³ ë¦¬',
                'keyword_type': 'í‚¤ì›Œë“œ ìœ í˜•',
                'brand_code': 'ë¸Œëœë“œ ì½”ë“œ',
                'BRD_CD': 'ë¸Œëœë“œ ì½”ë“œ',
                'CAT_NM': 'ì¹´í…Œê³ ë¦¬',
                'SUB_CAT_NM': 'í•˜ìœ„ ì¹´í…Œê³ ë¦¬',
                'KWD_TYPE': 'í‚¤ì›Œë“œ ìœ í˜•',
                'START_DT': 'ì‹œì‘ë‚ ì§œ',
                'END_DT': 'ì¢…ë£Œë‚ ì§œ'
            }
            
            # ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ë§¤í•‘
            for old_col, new_col in column_mapping.items():
                if old_col in display_df.columns:
                    display_df = display_df.rename(columns={old_col: new_col})
            
            st.dataframe(display_df, use_container_width=True)
            
            # ë‹¤ìš´ë¡œë“œ ë° ì‚­ì œ ë²„íŠ¼
            col_download, col_delete = st.columns([1, 1])
            
            with col_download:
                if st.button("ğŸ“¥ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", use_container_width=True):
                    # ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        display_df.to_excel(writer, sheet_name='ê²€ìƒ‰ëŸ‰ë°ì´í„°', index=False)
                    excel_buffer.seek(0)
                    
                    st.download_button(
                        label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=excel_buffer.getvalue(),
                        file_name=f"ê²€ìƒ‰ëŸ‰ë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
            
            with col_delete:
                if st.button("ğŸ—‘ï¸ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì‚­ì œ", use_container_width=True):
                    if os.path.exists(SEARCH_FILE):
                        os.remove(SEARCH_FILE)
                        st.success("âœ… ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.info("ì‚­ì œí•  ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì„ íƒëœ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ Snowflake ì—°ë™ì„ í†µí•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")

# =============================================================================
# ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

def render_sales_management_tab():
    """ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ’° ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬")
    
    # ë§¤ì¶œ ë°ì´í„° í‘œì‹œ
    sales_df = load_sales_data()
    if not sales_df.empty:
        st.markdown("## ğŸ“Š ë§¤ì¶œ ë°ì´í„°")
        st.success(f"ì´ {len(sales_df)}ê±´ì˜ ë§¤ì¶œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„í„°
        st.markdown("#### ğŸ” ë§¤ì¶œ ë°ì´í„° í•„í„°")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**ğŸ·ï¸ ë¸Œëœë“œ**")
            if 'BRD_CD' in sales_df.columns:
                valid_brands = ['M', 'X', 'V', 'ST']
                sales_df_filtered = sales_df[sales_df['BRD_CD'].isin(valid_brands)]
                brand_mapping = {'M': 'MLB', 'X': 'DX', 'V': 'DV', 'ST': 'ST'}
                unique_brands = sales_df_filtered['BRD_CD'].unique()
                brand_names = [brand_mapping.get(brand, brand) for brand in unique_brands]
                brand_order = ['MLB', 'DX', 'DV', 'ST']
                ordered_brands = [brand for brand in brand_order if brand in brand_names]
                selected_brd = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ordered_brands, key="sales_table_brand_filter", label_visibility="collapsed")
            else:
                selected_brd = "MLB"
        
        with col2:
            st.markdown("**ğŸ“… ì›”**")
            if 'DT' in sales_df.columns:
                sales_df['ì›”'] = pd.to_datetime(sales_df['DT']).dt.to_period('M')
                months = sorted(sales_df['ì›”'].unique())
                selected_month = st.selectbox("ì›”ì„ ì„ íƒí•˜ì„¸ìš”", months, key="sales_table_month_filter", label_visibility="collapsed")
            else:
                selected_month = None
        
        with col3:
            st.markdown("**ğŸ“¦ ì¹´í…Œê³ ë¦¬**")
            if 'ITEM_NM' in sales_df.columns:
                categories = sales_df['ITEM_NM'].unique()
                selected_item = st.selectbox("ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + list(categories), key="sales_table_item_filter", label_visibility="collapsed")
            else:
                selected_item = "ì „ì²´"
        
        # ë°ì´í„° í•„í„°ë§
        filtered_sales_df = sales_df.copy()
        if 'BRD_CD' in sales_df.columns:
            brand_reverse_mapping = {'MLB': 'M', 'DX': 'X', 'DV': 'V', 'ST': 'ST'}
            brand_code = brand_reverse_mapping.get(selected_brd, selected_brd)
            filtered_sales_df = filtered_sales_df[filtered_sales_df['BRD_CD'] == brand_code]
        
        if selected_month and 'ì›”' in sales_df.columns:
            filtered_sales_df = filtered_sales_df[filtered_sales_df['ì›”'] == selected_month]
        
        if selected_item != "ì „ì²´" and 'ITEM_NM' in sales_df.columns:
            filtered_sales_df = filtered_sales_df[filtered_sales_df['ITEM_NM'] == selected_item]
        
        # í‘œì‹œìš© ë°ì´í„° ì¤€ë¹„
        display_df = filtered_sales_df.copy()
        if 'DT' in display_df.columns:
            display_df['DT'] = pd.to_datetime(display_df['DT'], errors='coerce').dt.date
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        column_order = ['BRD_CD', 'DT', 'ITEM', 'ITEM_NM', 'SALE_AMT_TY', 'SALE_QTY_TY', 'SALE_AMT_LY', 'SALE_QTY_LY']
        available_columns = [col for col in column_order if col in display_df.columns]
        display_df = display_df[available_columns]
        
        st.dataframe(display_df, use_container_width=True)
        
        # ê´€ë¦¬ ì˜µì…˜
        st.markdown("## âš™ï¸ ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬")
        col1, col2 = st.columns(2)
        
        with col1:
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                display_df.to_excel(writer, index=False, sheet_name='ë§¤ì¶œë°ì´í„°')
            output.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"ë§¤ì¶œë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        
        with col2:
            if st.button("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ"):
                if os.path.exists(SALES_FILE):
                    os.remove(SALES_FILE)
                    st.success("ë§¤ì¶œ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
    

# =============================================================================
# Snowflake ì—°ê²° ê¸°ëŠ¥
# =============================================================================

def get_snowflake_connection():
    """Snowflake ì—°ê²° ì„¤ì • - ë§¤ë²ˆ ìƒˆë¡œìš´ ì—°ê²° ìƒì„±"""
    if not SNOWFLAKE_AVAILABLE:
        st.error("Snowflake íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # Streamlit secretsì—ì„œ Snowflake ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        conn = snowflake.connector.connect(
            user=st.secrets["snowflake"]["user"],
            password=st.secrets["snowflake"]["password"],
            account=st.secrets["snowflake"]["account"],
            warehouse=st.secrets["snowflake"]["warehouse"],
            database=st.secrets["snowflake"]["database"],
            schema=st.secrets["snowflake"]["schema"]
        )
        return conn
    except Exception as e:
        st.error(f"Snowflake ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        return None

def execute_snowflake_query(query):
    """Snowflake ì¿¼ë¦¬ ì‹¤í–‰"""
    if not SNOWFLAKE_AVAILABLE:
        st.error("Snowflake íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    conn = None
    cursor = None
    try:
        # ìƒˆë¡œìš´ ì—°ê²° ìƒì„±
        conn = snowflake.connector.connect(
            user=st.secrets["snowflake"]["user"],
            password=st.secrets["snowflake"]["password"],
            account=st.secrets["snowflake"]["account"],
            warehouse=st.secrets["snowflake"]["warehouse"],
            database=st.secrets["snowflake"]["database"],
            schema=st.secrets["snowflake"]["schema"]
        )
        
        cursor = conn.cursor()
        cursor.execute(query)
        results = cursor.fetchall()
        
        # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
        columns = [desc[0] for desc in cursor.description]
        df = pd.DataFrame(results, columns=columns)
        
        # ë‚ ì§œ ë°ì´í„° ê²€ì¦ ë° ìˆ˜ì •
        if 'DT' in df.columns and not df.empty:
            df['DT'] = pd.to_datetime(df['DT'])
            current_year = pd.Timestamp.now().year
            
            # ì˜ëª»ëœ ë‚ ì§œ í•„í„°ë§ (í˜„ì¬ ì—°ë„ + 1ë…„ê¹Œì§€ë§Œ í—ˆìš©)
            df = df[df['DT'].dt.year <= current_year + 1]
            df = df[df['DT'].dt.year >= 1900]
            
            # ì˜ëª»ëœ ë‚ ì§œ ë°ì´í„°ëŠ” ì¡°ìš©íˆ ì œê±° (ê²½ê³  ë©”ì‹œì§€ ì œê±°)
        
        return df
    except Exception as e:
        st.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame()
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def load_snowflake_influencer_data():
    """Snowflakeì—ì„œ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë¡œë“œ"""
    query = """
    SELECT 
        contract_id,
        contract_sesn,
        sns_id,
        name,
        gender,
        follower,
        agency,
        mlb_qty,
        dx_qty,
        dv_qty,
        st_qty,
        total_qty,
        total_amt_incl2nd,
        total_amt_exc2nd,
        sec_usage,
        sec_period,
        sec_commercial,
        sec_sns,
        sec_ads,
        unit_fee
    FROM influencer_data
    ORDER BY contract_id
    """
    return execute_snowflake_query(query)

def load_snowflake_execution_data():
    """Snowflakeì—ì„œ ì§‘í–‰ ë°ì´í„° ë¡œë“œ"""
    query = """
    SELECT 
        ë‚ ì§œ,
        ì¸í”Œë£¨ì–¸ì„œ,
        ë…¸ì¶œìˆ˜,
        ì¢‹ì•„ìš”,
        ëŒ“ê¸€ìˆ˜,
        ì¡°íšŒìˆ˜
    FROM execution_data
    ORDER BY ë‚ ì§œ DESC
    """
    return execute_snowflake_query(query)

def get_default_sales_query():
    """ê¸°ë³¸ ë§¤ì¶œ ì¿¼ë¦¬ ë°˜í™˜"""
    # session_stateì— ì €ì¥ëœ ê¸°ë³¸ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
    if hasattr(st.session_state, 'default_sales_query') and st.session_state.default_sales_query:
        return st.session_state.default_sales_query
    
    # í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì¿¼ë¦¬
    return """
    WITH TY AS (
        SELECT  
            b.brd_cd,
            a.dt,
            b.item,
            b.item_nm,
            SUM(a.sale_nml_sale_amt_cns + a.sale_ret_sale_amt_cns) AS sale_amt_ty,
            SUM(a.sale_nml_qty_cns + a.sale_ret_qty_cns) AS sale_qty_ty
        FROM prcs.dw_scs_d a
        JOIN prcs.db_prdt b ON a.prdt_cd = b.prdt_cd 
        WHERE 1=1
          AND a.dt >= DATE '2025-09-01'   -- 2025ë…„ 9ì›” ì´í›„ ìµœì‹  ë°ì´í„°
        GROUP BY b.brd_cd, a.dt, b.item, b.item_nm
    ),
    LY AS (
        SELECT  
            b.brd_cd,
            DATEADD(year, 1, a.dt) AS dt,   -- ì‘ë…„ â†’ ì˜¬í•´ ë‚ ì§œë¡œ ì´ë™
            b.item,
            b.item_nm,
            SUM(a.sale_nml_sale_amt_cns + a.sale_ret_sale_amt_cns) AS sale_amt_ly,
            SUM(a.sale_nml_qty_cns + a.sale_ret_qty_cns) AS sale_qty_ly
        FROM prcs.dw_scs_d a
        JOIN prcs.db_prdt b ON a.prdt_cd = b.prdt_cd 
        WHERE 1=1
          AND a.dt >= DATEADD(year, -1, DATE '2025-09-01')  -- 2024-09-01 ì´í›„
        GROUP BY b.brd_cd, a.dt, b.item, b.item_nm
    )
    SELECT 
        t.brd_cd,
        t.dt,
        t.item,
        t.item_nm,
        t.sale_amt_ty,
        t.sale_qty_ty,
        l.sale_amt_ly,
        l.sale_qty_ly
    FROM TY t
    LEFT JOIN LY l 
        ON t.dt = l.dt 
       AND t.item = l.item 
       AND t.brd_cd = l.brd_cd
    WHERE 1=1
      AND t.brd_cd IN ('M', 'X', 'V', 'ST')
    ORDER BY t.brd_cd, t.dt DESC, t.item
    """

def load_snowflake_sales_data():
    """Snowflakeì—ì„œ ë§¤ì¶œ ë°ì´í„° ë¡œë“œ"""
    # ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
    if hasattr(st.session_state, 'custom_query') and st.session_state.custom_query:
        query = st.session_state.custom_query
    else:
        # ê¸°ë³¸ ì¿¼ë¦¬ í•¨ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        query = get_default_sales_query()
    return execute_snowflake_query(query)

def load_snowflake_assignment_data():
    """Snowflakeì—ì„œ ë°°ì • ë°ì´í„° ë¡œë“œ"""
    query = """
    SELECT 
        contract_id,
        brand,
        month,
        assigned_qty,
        season,
        assignment_date
    FROM assignment_history
    ORDER BY assignment_date DESC
    """
    return execute_snowflake_query(query)

# =============================================================================
# ë°ì´í„° ë¬¸ì˜ ê¸°ëŠ¥
# =============================================================================

def analyze_data_question(question, execution_df, influencer_df):
    """AI ê¸°ë°˜ ë°ì´í„° ë¬¸ì˜ ë¶„ì„ - íŒë‹¤ìŠ¤ ê¸°ë°˜ ìì—°ì–´ ì²˜ë¦¬"""
    question_lower = question.lower()
    
    # ëª¨ë“  ë°ì´í„° ë¡œë“œ
    sales_df = load_sales_data()
    assignment_df = load_assignment_history()
    
    # ë°ì´í„° í†µí•© ë¶„ì„
    try:
        # 1. ë¸Œëœë“œë³„ ì„±ê³¼ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ì„±ê³¼", "ì‹¤ì ", "ê²°ê³¼", "íš¨ê³¼"]):
            return analyze_brand_performance(execution_df, sales_df, influencer_df, question_lower)
        
        # 2. ì¸í”Œë£¨ì–¸ì„œë³„ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ì¸í”Œë£¨ì–¸ì„œ", "í¬ë¦¬ì—ì´í„°", "ì¸í”Œ"]):
            return analyze_influencer_performance(execution_df, influencer_df, question_lower)
        
        # 3. ë§¤ì¶œ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ë§¤ì¶œ", "íŒë§¤", "ìˆ˜ìµ", "ë§¤ì¶œì•¡"]):
            return analyze_sales_data(sales_df, question_lower)
        
        # 4. ì§‘í–‰ ë°ì´í„° ë¶„ì„
        if any(keyword in question_lower for keyword in ["ì§‘í–‰", "ì‹¤í–‰", "ë…¸ì¶œ", "ì¢‹ì•„ìš”", "ëŒ“ê¸€", "ì¡°íšŒ"]):
            return analyze_execution_data(execution_df, question_lower)
        
        # 5. ë°°ì • ë¶„ì„
        if any(keyword in question_lower for keyword in ["ë°°ì •", "í• ë‹¹", "ê³„íš"]):
            return analyze_assignment_data(assignment_df, influencer_df, question_lower)
        
        # 6. íŠ¸ë Œë“œ ë¶„ì„
        if any(keyword in question_lower for keyword in ["íŠ¸ë Œë“œ", "ì¶”ì´", "ë³€í™”", "ì¦ê°€", "ê°ì†Œ"]):
            return analyze_trends(execution_df, sales_df, question_lower)
        
        # 7. ë¹„êµ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ë¹„êµ", "vs", "ëŒ€ë¹„", "ì°¨ì´"]):
            return analyze_comparison(execution_df, sales_df, influencer_df, question_lower)
        
        # 8. ê³ ê¸‰ ë¶„ì„ (ìƒˆë¡œ ì¶”ê°€)
        if any(keyword in question_lower for keyword in ["ìƒê´€ê´€ê³„", "ì—°ê´€ì„±", "íŒ¨í„´", "ë¶„í¬", "í†µê³„"]):
            return analyze_advanced_statistics(execution_df, sales_df, influencer_df, question_lower)
        
        # 9. ì˜ˆì¸¡ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ì˜ˆì¸¡", "ì „ë§", "í–¥í›„", "ë¯¸ë˜"]):
            return analyze_predictions(execution_df, sales_df, question_lower)
        
        # 10. ì¸ì‚¬ì´íŠ¸ ë¶„ì„
        if any(keyword in question_lower for keyword in ["ì¸ì‚¬ì´íŠ¸", "ì¸ì‚¬ì´íŠ¸", "ë°œê²¬", "íŠ¹ì§•"]):
            return analyze_insights(execution_df, sales_df, influencer_df, question_lower)
        
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # ê¸°ì¡´ ë‹¨ìˆœ ë§¤í•‘ ë°©ì‹ (fallback)
    return analyze_simple_questions(question, execution_df, influencer_df, sales_df)

def analyze_brand_performance(execution_df, sales_df, influencer_df, question_lower):
    """ë¸Œëœë“œë³„ ì„±ê³¼ ë¶„ì„"""
    results = []
    
    # ë¸Œëœë“œ ë§¤í•‘
    brand_mapping = {'mlb': 'M', 'dx': 'X', 'dv': 'V', 'st': 'ST'}
    
    for brand_name, brand_code in brand_mapping.items():
        if brand_name in question_lower:
            # ì§‘í–‰ ë°ì´í„° ë¶„ì„
            if not execution_df.empty and 'ë¸Œëœë“œ' in execution_df.columns:
                brand_execution = execution_df[execution_df['ë¸Œëœë“œ'] == brand_name.upper()]
                if not brand_execution.empty:
                    total_exposure = brand_execution['ë…¸ì¶œìˆ˜'].sum() if 'ë…¸ì¶œìˆ˜' in brand_execution.columns else 0
                    total_likes = brand_execution['ì¢‹ì•„ìš”'].sum() if 'ì¢‹ì•„ìš”' in brand_execution.columns else 0
                    total_comments = brand_execution['ëŒ“ê¸€ìˆ˜'].sum() if 'ëŒ“ê¸€ìˆ˜' in brand_execution.columns else 0
                    total_views = brand_execution['ì¡°íšŒìˆ˜'].sum() if 'ì¡°íšŒìˆ˜' in brand_execution.columns else 0
                    
                    results.append(f"**{brand_name.upper()} ë¸Œëœë“œ ì„±ê³¼:**")
                    results.append(f"â€¢ ì´ ë…¸ì¶œìˆ˜: {total_exposure:,}")
                    results.append(f"â€¢ ì´ ì¢‹ì•„ìš”: {total_likes:,}")
                    results.append(f"â€¢ ì´ ëŒ“ê¸€: {total_comments:,}")
                    results.append(f"â€¢ ì´ ì¡°íšŒìˆ˜: {total_views:,}")
            
            # ë§¤ì¶œ ë°ì´í„° ë¶„ì„
            if not sales_df.empty and 'BRD_CD' in sales_df.columns:
                brand_sales = sales_df[sales_df['BRD_CD'] == brand_code]
                if not brand_sales.empty:
                    total_sales = brand_sales['SALE_AMT_TY'].sum() if 'SALE_AMT_TY' in brand_sales.columns else 0
                    total_qty = brand_sales['SALE_QTY_TY'].sum() if 'SALE_QTY_TY' in brand_sales.columns else 0
                    results.append(f"â€¢ ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì›")
                    results.append(f"â€¢ ì´ íŒë§¤ëŸ‰: {total_qty:,}ê°œ")
            
            # ì¸í”Œë£¨ì–¸ì„œ ê³„ì•½ ë¶„ì„
            if not influencer_df.empty:
                brand_qty_col = f"{brand_name}_qty"
                if brand_qty_col in influencer_df.columns:
                    total_contracts = influencer_df[brand_qty_col].sum()
                    active_influencers = len(influencer_df[influencer_df[brand_qty_col] > 0])
                    results.append(f"â€¢ ì´ ê³„ì•½ìˆ˜: {total_contracts}ê±´")
                    results.append(f"â€¢ í™œì„± ì¸í”Œë£¨ì–¸ì„œ: {active_influencers}ëª…")
            
            return "\n".join(results) if results else f"{brand_name.upper()} ë¸Œëœë“œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return "ë¸Œëœë“œ ì„±ê³¼ ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ë¸Œëœë“œëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_influencer_performance(execution_df, influencer_df, question_lower):
    """ì¸í”Œë£¨ì–¸ì„œë³„ ì„±ê³¼ ë¶„ì„"""
    if execution_df.empty:
        return "ì§‘í–‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ìµœê³  ì„±ê³¼ ì¸í”Œë£¨ì–¸ì„œ ì°¾ê¸°
    if "ìµœê³ " in question_lower or "1ìœ„" in question_lower or "ìµœëŒ€" in question_lower:
        if "ë…¸ì¶œìˆ˜" in question_lower:
            top_influencer = execution_df.loc[execution_df['ë…¸ì¶œìˆ˜'].idxmax()]
            return f"ìµœê³  ë…¸ì¶œìˆ˜: {top_influencer['ì¸í”Œë£¨ì–¸ì„œ']} ({top_influencer['ë…¸ì¶œìˆ˜']:,})"
        elif "ì¢‹ì•„ìš”" in question_lower:
            top_influencer = execution_df.loc[execution_df['ì¢‹ì•„ìš”'].idxmax()]
            return f"ìµœê³  ì¢‹ì•„ìš”: {top_influencer['ì¸í”Œë£¨ì–¸ì„œ']} ({top_influencer['ì¢‹ì•„ìš”']:,})"
        elif "ëŒ“ê¸€" in question_lower:
            top_influencer = execution_df.loc[execution_df['ëŒ“ê¸€ìˆ˜'].idxmax()]
            return f"ìµœê³  ëŒ“ê¸€ìˆ˜: {top_influencer['ì¸í”Œë£¨ì–¸ì„œ']} ({top_influencer['ëŒ“ê¸€ìˆ˜']:,})"
        elif "ì¡°íšŒìˆ˜" in question_lower:
            top_influencer = execution_df.loc[execution_df['ì¡°íšŒìˆ˜'].idxmax()]
            return f"ìµœê³  ì¡°íšŒìˆ˜: {top_influencer['ì¸í”Œë£¨ì–¸ì„œ']} ({top_influencer['ì¡°íšŒìˆ˜']:,})"
    
    # ì¸í”Œë£¨ì–¸ì„œ ìˆ˜
    if "ëª‡ëª…" in question_lower or "ìˆ˜" in question_lower:
        unique_influencers = execution_df['ì¸í”Œë£¨ì–¸ì„œ'].nunique()
        return f"ì´ {unique_influencers}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œê°€ í™œë™í–ˆìŠµë‹ˆë‹¤."
    
    return "ì¸í”Œë£¨ì–¸ì„œ ì„±ê³¼ ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ì§€í‘œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_sales_data(sales_df, question_lower):
    """ë§¤ì¶œ ë°ì´í„° ë¶„ì„"""
    if sales_df.empty:
        return "ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë¸Œëœë“œë³„ ë§¤ì¶œ ë¶„ì„
    brand_mapping = {'mlb': 'M', 'dx': 'X', 'dv': 'V', 'st': 'ST'}
    
    for brand_name, brand_code in brand_mapping.items():
        if brand_name in question_lower:
            brand_sales = sales_df[sales_df['BRD_CD'] == brand_code]
            if not brand_sales.empty:
                # ì›”ë³„ í•„í„°ë§ ì²˜ë¦¬
                target_month = None
                month_mapping = {
                    '1ì›”': 1, '2ì›”': 2, '3ì›”': 3, '4ì›”': 4, '5ì›”': 5, '6ì›”': 6,
                    '7ì›”': 7, '8ì›”': 8, '9ì›”': 9, '10ì›”': 10, '11ì›”': 11, '12ì›”': 12
                }
                
                for month_name, month_num in month_mapping.items():
                    if month_name in question_lower:
                        target_month = month_num
                        break
                
                # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
                brand_sales['DT'] = pd.to_datetime(brand_sales['DT'])
                
                # ì˜ëª»ëœ ë‚ ì§œ í•„í„°ë§ (2025ë…„ ì´í›„ì˜ í˜„ì‹¤ì ì¸ ë‚ ì§œë§Œ)
                current_year = pd.Timestamp.now().year
                brand_sales = brand_sales[brand_sales['DT'].dt.year <= current_year + 1]  # ë‚´ë…„ê¹Œì§€ë§Œ í—ˆìš©
                
                # íŠ¹ì • ì›” í•„í„°ë§
                if target_month:
                    brand_sales = brand_sales[brand_sales['DT'].dt.month == target_month]
                
                if not brand_sales.empty:
                    # ë§ˆì§€ë§‰ ì¼ì ì²˜ë¦¬
                    if "ë§ˆì§€ë§‰" in question_lower or "ìµœì‹ " in question_lower or "ìµœê·¼" in question_lower:
                        latest_date = brand_sales['DT'].max()
                        latest_sales = brand_sales[brand_sales['DT'] == latest_date]
                    else:
                        # ì›”ë³„ ì „ì²´ ë°ì´í„° ë¶„ì„ (ë§ˆì§€ë§‰ ì¼ìê°€ ì•„ë‹Œ ê²½ìš°)
                        total_sales = brand_sales['SALE_AMT_TY'].sum()
                        total_qty = brand_sales['SALE_QTY_TY'].sum()
                        avg_sales = brand_sales['SALE_AMT_TY'].mean()
                        
                        month_name = f"{target_month}ì›”" if target_month else "ì „ì²´"
                        result = f"**{brand_name.upper()} {month_name} ë§¤ì¶œ ë¶„ì„:**\n"
                        result += f"â€¢ ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì›\n"
                        result += f"â€¢ ì´ íŒë§¤ëŸ‰: {total_qty:,}ê°œ\n"
                        result += f"â€¢ í‰ê·  ë§¤ì¶œì•¡: {avg_sales:,.0f}ì›\n"
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
                        if "ì¹´í…Œê³ ë¦¬" in question_lower or "ìƒí’ˆ" in question_lower:
                            category_sales = brand_sales.groupby('ITEM_NM').agg({
                                'SALE_AMT_TY': 'sum',
                                'SALE_QTY_TY': 'sum'
                            }).sort_values('SALE_AMT_TY', ascending=False)
                            
                            result += "\n**ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ:**\n"
                            for item, row in category_sales.head(5).iterrows():
                                result += f"â€¢ {item}: {row['SALE_AMT_TY']:,.0f}ì› ({row['SALE_QTY_TY']:,}ê°œ)\n"
                        
                        return result
                    
                    if not latest_sales.empty:
                        total_sales = latest_sales['SALE_AMT_TY'].sum()
                        total_qty = latest_sales['SALE_QTY_TY'].sum()
                        avg_sales = latest_sales['SALE_AMT_TY'].mean()
                        
                        result = f"**{brand_name.upper()} {latest_date.strftime('%Y-%m-%d')} ë§¤ì¶œ ë¶„ì„:**\n"
                        result += f"â€¢ ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì›\n"
                        result += f"â€¢ ì´ íŒë§¤ëŸ‰: {total_qty:,}ê°œ\n"
                        result += f"â€¢ í‰ê·  ë§¤ì¶œì•¡: {avg_sales:,.0f}ì›\n"
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
                        if "ì¹´í…Œê³ ë¦¬" in question_lower or "ìƒí’ˆ" in question_lower:
                            category_sales = latest_sales.groupby('ITEM_NM').agg({
                                'SALE_AMT_TY': 'sum',
                                'SALE_QTY_TY': 'sum'
                            }).sort_values('SALE_AMT_TY', ascending=False)
                            
                            result += "\n**ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ:**\n"
                            for item, row in category_sales.head(5).iterrows():
                                result += f"â€¢ {item}: {row['SALE_AMT_TY']:,.0f}ì› ({row['SALE_QTY_TY']:,}ê°œ)\n"
                        
                        return result
                    else:
                        return f"{brand_name.upper()}ì˜ ë§ˆì§€ë§‰ ì¼ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                else:
                    month_name = f"{target_month}ì›”" if target_month else "í•´ë‹¹ ê¸°ê°„"
                    return f"{brand_name.upper()}ì˜ {month_name} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                
                # ì¼ë°˜ì ì¸ ì „ì²´ ê¸°ê°„ ë¶„ì„
                total_sales = brand_sales['SALE_AMT_TY'].sum()
                total_qty = brand_sales['SALE_QTY_TY'].sum()
                avg_sales = brand_sales['SALE_AMT_TY'].mean()
                
                result = f"**{brand_name.upper()} ë§¤ì¶œ ë¶„ì„:**\n"
                result += f"â€¢ ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì›\n"
                result += f"â€¢ ì´ íŒë§¤ëŸ‰: {total_qty:,}ê°œ\n"
                result += f"â€¢ í‰ê·  ë§¤ì¶œì•¡: {avg_sales:,.0f}ì›\n"
                
                # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
                if "ì¹´í…Œê³ ë¦¬" in question_lower or "ìƒí’ˆ" in question_lower:
                    category_sales = brand_sales.groupby('ITEM_NM').agg({
                        'SALE_AMT_TY': 'sum',
                        'SALE_QTY_TY': 'sum'
                    }).sort_values('SALE_AMT_TY', ascending=False)
                    
                    result += "\n**ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ:**\n"
                    for item, row in category_sales.head(5).iterrows():
                        result += f"â€¢ {item}: {row['SALE_AMT_TY']:,.0f}ì› ({row['SALE_QTY_TY']:,}ê°œ)\n"
                
                return result
    
    # ì „ì²´ ë§¤ì¶œ ë¶„ì„
    if "ì „ì²´" in question_lower or "ì´" in question_lower:
        total_sales = sales_df['SALE_AMT_TY'].sum()
        total_qty = sales_df['SALE_QTY_TY'].sum()
        return f"ì „ì²´ ë§¤ì¶œ: {total_sales:,.0f}ì› ({total_qty:,}ê°œ)"
    
    return "ë§¤ì¶œ ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ë¸Œëœë“œëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_execution_data(execution_df, question_lower):
    """ì§‘í–‰ ë°ì´í„° ë¶„ì„"""
    if execution_df.empty:
        return "ì§‘í–‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë©”íŠ¸ë¦­ë³„ ë¶„ì„
    metrics = {
        'ë…¸ì¶œìˆ˜': 'ë…¸ì¶œìˆ˜',
        'ì¢‹ì•„ìš”': 'ì¢‹ì•„ìš”',
        'ëŒ“ê¸€': 'ëŒ“ê¸€ìˆ˜',
        'ì¡°íšŒìˆ˜': 'ì¡°íšŒìˆ˜'
    }
    
    for metric_name, column in metrics.items():
        if metric_name in question_lower and column in execution_df.columns:
            if "ìµœê³ " in question_lower or "ìµœëŒ€" in question_lower:
                max_value = execution_df[column].max()
                max_row = execution_df[execution_df[column] == max_value].iloc[0]
                return f"ìµœê³  {metric_name}: {max_row['ì¸í”Œë£¨ì–¸ì„œ']} ({max_value:,})"
            elif "í‰ê· " in question_lower:
                avg_value = execution_df[column].mean()
                return f"í‰ê·  {metric_name}: {avg_value:,.0f}"
            elif "ì´" in question_lower or "í•©ê³„" in question_lower:
                total_value = execution_df[column].sum()
                return f"ì´ {metric_name}: {total_value:,}"
    
    return "ì§‘í–‰ ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ì§€í‘œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_assignment_data(assignment_df, influencer_df, question_lower):
    """ë°°ì • ë°ì´í„° ë¶„ì„"""
    if assignment_df.empty:
        return "ë°°ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ë¸Œëœë“œë³„ ë°°ì • ë¶„ì„
    if "ë¸Œëœë“œ" in question_lower:
        brand_assignments = assignment_df.groupby('brand')['assigned_qty'].sum()
        result = "**ë¸Œëœë“œë³„ ë°°ì • í˜„í™©:**\n"
        for brand, qty in brand_assignments.items():
            result += f"â€¢ {brand}: {qty}ê±´\n"
        return result
    
    # ì›”ë³„ ë°°ì • ë¶„ì„
    if "ì›”ë³„" in question_lower or "ì›”" in question_lower:
        monthly_assignments = assignment_df.groupby('month')['assigned_qty'].sum()
        result = "**ì›”ë³„ ë°°ì • í˜„í™©:**\n"
        for month, qty in monthly_assignments.items():
            result += f"â€¢ {month}ì›”: {qty}ê±´\n"
        return result
    
    return "ë°°ì • ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ì¡°ê±´ì„ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_trends(execution_df, sales_df, question_lower):
    """íŠ¸ë Œë“œ ë¶„ì„"""
    results = []
    
    # ì§‘í–‰ ë°ì´í„° íŠ¸ë Œë“œ
    if not execution_df.empty and 'ë‚ ì§œ' in execution_df.columns:
        execution_df['ë‚ ì§œ'] = pd.to_datetime(execution_df['ë‚ ì§œ'])
        daily_metrics = execution_df.groupby(execution_df['ë‚ ì§œ'].dt.date).agg({
            'ë…¸ì¶œìˆ˜': 'sum',
            'ì¢‹ì•„ìš”': 'sum',
            'ëŒ“ê¸€ìˆ˜': 'sum',
            'ì¡°íšŒìˆ˜': 'sum'
        })
        
        # ìµœê·¼ 7ì¼ íŠ¸ë Œë“œ
        recent_7days = daily_metrics.tail(7)
        if len(recent_7days) >= 2:
            exposure_trend = (recent_7days['ë…¸ì¶œìˆ˜'].iloc[-1] - recent_7days['ë…¸ì¶œìˆ˜'].iloc[0]) / recent_7days['ë…¸ì¶œìˆ˜'].iloc[0] * 100
            results.append(f"ìµœê·¼ 7ì¼ ë…¸ì¶œìˆ˜ ë³€í™”: {exposure_trend:+.1f}%")
    
    # ë§¤ì¶œ ë°ì´í„° íŠ¸ë Œë“œ
    if not sales_df.empty and 'DT' in sales_df.columns:
        sales_df['DT'] = pd.to_datetime(sales_df['DT'])
        daily_sales = sales_df.groupby(sales_df['DT'].dt.date)['SALE_AMT_TY'].sum()
        
        if len(daily_sales) >= 2:
            sales_trend = (daily_sales.iloc[-1] - daily_sales.iloc[0]) / daily_sales.iloc[0] * 100
            results.append(f"ìµœê·¼ ë§¤ì¶œ ë³€í™”: {sales_trend:+.1f}%")
    
    return "\n".join(results) if results else "íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

def analyze_comparison(execution_df, sales_df, influencer_df, question_lower):
    """ë¹„êµ ë¶„ì„"""
    if "ë¸Œëœë“œ" in question_lower:
        # ë¸Œëœë“œë³„ ì„±ê³¼ ë¹„êµ
        brand_performance = {}
        
        if not execution_df.empty and 'ë¸Œëœë“œ' in execution_df.columns:
            for brand in execution_df['ë¸Œëœë“œ'].unique():
                brand_data = execution_df[execution_df['ë¸Œëœë“œ'] == brand]
                brand_performance[brand] = {
                    'ë…¸ì¶œìˆ˜': brand_data['ë…¸ì¶œìˆ˜'].sum(),
                    'ì¢‹ì•„ìš”': brand_data['ì¢‹ì•„ìš”'].sum(),
                    'ëŒ“ê¸€ìˆ˜': brand_data['ëŒ“ê¸€ìˆ˜'].sum(),
                    'ì¡°íšŒìˆ˜': brand_data['ì¡°íšŒìˆ˜'].sum()
                }
        
        result = "**ë¸Œëœë“œë³„ ì„±ê³¼ ë¹„êµ:**\n"
        for brand, metrics in brand_performance.items():
            result += f"**{brand}:**\n"
            for metric, value in metrics.items():
                result += f"  â€¢ {metric}: {value:,}\n"
        
        return result
    
    return "ë¹„êµ ë¶„ì„ì„ ìœ„í•´ êµ¬ì²´ì ì¸ ë¹„êµ ëŒ€ìƒì„ í¬í•¨í•´ì£¼ì„¸ìš”."

def analyze_simple_questions(question, execution_df, influencer_df, sales_df):
    """ê¸°ì¡´ ë‹¨ìˆœ ì§ˆë¬¸ ì²˜ë¦¬ (fallback)"""
    question_lower = question.lower()
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
    if not influencer_df.empty:
        # ë¸Œëœë“œë³„ ê³„ì•½ìˆ˜ ì§ˆë¬¸ (ë™ì  ì²˜ë¦¬)
        brand_mapping = {
            'dv': 'dv_qty',
            'mlb': 'mlb_qty', 
            'dx': 'dx_qty',
            'st': 'st_qty'
        }
        
        for brand, column in brand_mapping.items():
            if brand in question_lower and ("ê³„ì•½ìˆ˜" in question or "ê³„ì•½" in question):
                if "ì´" in question or "í•©ê³„" in question or "ëª‡ê°œ" in question:
                    total = int(influencer_df[column].sum())
                    return f"{brand.upper()} ì´ ê³„ì•½ìˆ˜: {total}ê±´"
                elif "ì¸í”Œë£¨ì–¸ì„œ" in question or "ëª…" in question:
                    count = len(influencer_df[influencer_df[column] > 0])
                    return f"{brand.upper()} ê³„ì•½ì´ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œ: {count}ëª…"
        
        # ì „ì²´ ê³„ì•½ìˆ˜ ê´€ë ¨ ì§ˆë¬¸
        if "ì „ì²´" in question and ("ê³„ì•½ìˆ˜" in question or "ê³„ì•½" in question):
            if "ì´" in question or "í•©ê³„" in question:
                total_contracts = int(influencer_df['total_qty'].sum())
                return f"ì „ì²´ ì´ ê³„ì•½ìˆ˜: {total_contracts}ê±´"
            elif "ì¸í”Œë£¨ì–¸ì„œ" in question or "ëª…" in question:
                total_count = len(influencer_df)
                return f"ì „ì²´ ì¸í”Œë£¨ì–¸ì„œ ìˆ˜: {total_count}ëª…"
    
    # execution ë°ì´í„° ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬ (ì¼ë°˜í™”)
    if not execution_df.empty:
        # ë©”íŠ¸ë¦­ ë§¤í•‘
        metric_mapping = {
            'ë…¸ì¶œìˆ˜': 'ë…¸ì¶œìˆ˜',
            'ì¢‹ì•„ìš”': 'ì¢‹ì•„ìš”', 
            'ëŒ“ê¸€': 'ëŒ“ê¸€ìˆ˜',
            'ì¡°íšŒìˆ˜': 'ì¡°íšŒìˆ˜'
        }
        
        for metric_name, column in metric_mapping.items():
            if metric_name in question_lower and column in execution_df.columns:
                if "ìµœê³ " in question_lower or "ìµœëŒ€" in question_lower or "ë†’ì€" in question_lower:
                    if "ì¼ì" in question_lower or "ë‚ ì§œ" in question_lower or "ì–¸ì œ" in question_lower:
                        max_value = execution_df[column].max()
                        max_date = execution_df[execution_df[column] == max_value]['ë‚ ì§œ'].iloc[0]
                        return f"{metric_name}ì´ ê°€ì¥ ë†’ì€ ë‚ ì§œ: {max_date} ({max_value:,}ê°œ)"
                    else:
                        max_value = execution_df[column].max()
                        max_influencer = execution_df[execution_df[column] == max_value]['ì¸í”Œë£¨ì–¸ì„œ'].iloc[0]
                        return f"ìµœê³  {metric_name}: {max_value:,} (ì¸í”Œë£¨ì–¸ì„œ: {max_influencer})"
                elif "í‰ê· " in question_lower:
                    avg_value = execution_df[column].mean()
                    return f"í‰ê·  {metric_name}: {avg_value:,.0f}"
                elif "ì´" in question_lower or "í•©ê³„" in question_lower:
                    total_value = execution_df[column].sum()
                    return f"ì´ {metric_name}: {total_value:,}"
    
    # ë§¤ì¶œ ê´€ë ¨ ì§ˆë¬¸ - ì¼ë°˜ì ì´ê³  ìœ ì—°í•œ ì²˜ë¦¬
    if "ë§¤ì¶œ" in question_lower or "íŒë§¤" in question_lower:
        if sales_df.empty:
            return "ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ğŸ“ˆ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬' â†’ 'ğŸ’° ë§¤ì¶œ ë°ì´í„° ê´€ë¦¬'ì—ì„œ Snowflakeì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”."
        
        # ë¸Œëœë“œ ë§¤í•‘
        brand_mapping = {
            'mlb': 'M',
            'dx': 'X', 
            'dv': 'V',
            'st': 'ST'
        }
        
        # ì§ˆë¬¸ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
        detected_brand = None
        brand_code = None
        for brand, code in brand_mapping.items():
            if brand in question_lower:
                detected_brand = brand.upper()
                brand_code = code
                break
        
        # ì›” ì¶”ì¶œ (1ì›”~12ì›”)
        month_mapping = {
            '1ì›”': 1, '2ì›”': 2, '3ì›”': 3, '4ì›”': 4, '5ì›”': 5, '6ì›”': 6,
            '7ì›”': 7, '8ì›”': 8, '9ì›”': 9, '10ì›”': 10, '11ì›”': 11, '12ì›”': 12
        }
        
        detected_month = None
        month_num = None
        for month, num in month_mapping.items():
            if month in question:
                detected_month = month
                month_num = num
                break
        
        # íŠ¹ì • ì›”ì˜ ë¸Œëœë“œ ë§¤ì¶œ ì²˜ë¦¬
        if detected_month and detected_brand and brand_code:
            if 'BRD_CD' in sales_df.columns:
                brand_sales = sales_df[sales_df['BRD_CD'] == brand_code]
                if not brand_sales.empty:
                    # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    brand_sales['DT'] = pd.to_datetime(brand_sales['DT'])
                    
                    # í•´ë‹¹ ì›” ë°ì´í„° í•„í„°ë§
                    month_sales = brand_sales[brand_sales['DT'].dt.month == month_num]
                    
                    if not month_sales.empty:
                        # ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ
                        if "ì¹´í…Œê³ ë¦¬" in question_lower or "ë³„" in question_lower:
                            result = f"{detected_brand} {detected_month} ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ:\n"
                            category_sales = month_sales.groupby('ITEM_NM').agg({
                                'SALE_AMT_TY': 'sum',
                                'SALE_QTY_TY': 'sum'
                            }).sort_values('SALE_AMT_TY', ascending=False)
                            
                            for item_nm, row in category_sales.iterrows():
                                sale_amt = row['SALE_AMT_TY']
                                sale_qty = row['SALE_QTY_TY']
                                result += f"â€¢ {item_nm}: {sale_amt:,.0f}ì› ({sale_qty:,}ê°œ)\n"
                            return result.strip()
                        else:
                            # ì´ ë§¤ì¶œ
                            total_amt = month_sales['SALE_AMT_TY'].sum()
                            total_qty = month_sales['SALE_QTY_TY'].sum()
                            return f"{detected_brand} {detected_month} ì´ë§¤ì¶œ: {total_amt:,.0f}ì› ({total_qty:,}ê°œ)"
                    else:
                        return f"{detected_brand} {detected_month} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                else:
                    return f"{detected_brand} ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            else:
                return "ë¸Œëœë“œ ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìµœì‹  ë‚ ì§œì˜ íŠ¹ì • ë¸Œëœë“œ ë§¤ì¶œ (ì¼ë°˜í™”)
        elif ("ìµœì‹ " in question_lower or "ìµœì‹ ë‚ ì§œ" in question_lower) and detected_brand and brand_code:
            if 'BRD_CD' in sales_df.columns:
                brand_sales = sales_df[sales_df['BRD_CD'] == brand_code]
                if not brand_sales.empty:
                    # ìµœì‹  ë‚ ì§œ ì°¾ê¸°
                    latest_date = brand_sales['DT'].max()
                    latest_data = brand_sales[brand_sales['DT'] == latest_date]
                    
                    if not latest_data.empty:
                        # ì´ë§¤ì¶œ vs ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ êµ¬ë¶„
                        if "ì´ë§¤ì¶œ" in question_lower or "ì´" in question_lower:
                            total_amt = latest_data['SALE_AMT_TY'].sum()
                            total_qty = latest_data['SALE_QTY_TY'].sum()
                            return f"{detected_brand} ìµœì‹  ë‚ ì§œ ({latest_date}) ì´ë§¤ì¶œ: {total_amt:,.0f}ì› ({total_qty:,}ê°œ)"
                        else:
                            result = f"{detected_brand} ìµœì‹  ë‚ ì§œ ({latest_date}) ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ:\n"
                            for _, row in latest_data.iterrows():
                                item_nm = row.get('ITEM_NM', 'ì•Œ ìˆ˜ ì—†ìŒ')
                                sale_amt = row.get('SALE_AMT_TY', 0)
                                sale_qty = row.get('SALE_QTY_TY', 0)
                                result += f"â€¢ {item_nm}: {sale_amt:,.0f}ì› ({sale_qty:,}ê°œ)\n"
                            return result.strip()
                    else:
                        return f"{detected_brand} ìµœì‹  ë‚ ì§œ ({latest_date}) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                else:
                    return f"{detected_brand} ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            else:
                return "ë¸Œëœë“œ ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        elif "ì´" in question_lower or "í•©ê³„" in question_lower:
            total_sales = sales_df['SALE_AMT_TY'].sum() if 'SALE_AMT_TY' in sales_df.columns else 0
            return f"ì´ ë§¤ì¶œì•¡: {total_sales:,.0f}ì›"
        elif "ì¹´í…Œê³ ë¦¬" in question_lower or "ìƒí’ˆ" in question_lower:
            if "ìˆœìœ„" in question_lower or "ë­í‚¹" in question_lower or "ìƒìœ„" in question_lower:
                if 'ITEM_NM' in sales_df.columns and 'SALE_AMT_TY' in sales_df.columns:
                    # ë¸Œëœë“œ í•„í„°ë§ (DX ë¸Œëœë“œë§Œ)
                    if "DX" in question:
                        if 'BRD_CD' in sales_df.columns:
                            sales_df = sales_df[sales_df['BRD_CD'] == 'X']
                    
                    category_sales = sales_df.groupby('ITEM_NM')['SALE_AMT_TY'].sum().sort_values(ascending=False)
                    if len(category_sales) > 0:
                        top_5 = category_sales.head(5)
                        result = "ìƒìœ„ ì¹´í…Œê³ ë¦¬ ìˆœìœ„:\n"
                        for i, (category, sales) in enumerate(top_5.items(), 1):
                            result += f"{i}. {category}: {sales:,.0f}ì›\n"
                        return result.strip()
                    else:
                        return "ì¹´í…Œê³ ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                else:
                    return "ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì¼ë°˜ì ì¸ ë°ì´í„° ë¶„ì„ ëŠ¥ë ¥
    if not execution_df.empty:
        # ë°ì´í„° ê¸°ë³¸ ì •ë³´
        if "ë°ì´í„°" in question_lower and ("ê°œìˆ˜" in question_lower or "ê±´ìˆ˜" in question_lower or "ëª‡ê°œ" in question_lower):
            return f"ì§‘í–‰ ë°ì´í„° ì´ {len(execution_df)}ê±´"
        
        # ë‚ ì§œ ë²”ìœ„
        if "ë‚ ì§œ" in question_lower and ("ë²”ìœ„" in question_lower or "ê¸°ê°„" in question_lower):
            if 'ë‚ ì§œ' in execution_df.columns:
                min_date = execution_df['ë‚ ì§œ'].min()
                max_date = execution_df['ë‚ ì§œ'].max()
                return f"ë°ì´í„° ê¸°ê°„: {min_date} ~ {max_date}"
        
        # ì¸í”Œë£¨ì–¸ì„œ ìˆ˜
        if "ì¸í”Œë£¨ì–¸ì„œ" in question_lower and ("ëª‡ëª…" in question_lower or "ìˆ˜" in question_lower):
            if 'ì¸í”Œë£¨ì–¸ì„œ' in execution_df.columns:
                unique_influencers = execution_df['ì¸í”Œë£¨ì–¸ì„œ'].nunique()
                return f"ì´ {unique_influencers}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œ"
    
    # ë§¤ì¶œ ë°ì´í„° ê¸°ë³¸ ì •ë³´
    if not sales_df.empty:
        if "ë§¤ì¶œ" in question_lower and ("ë°ì´í„°" in question_lower or "ê±´ìˆ˜" in question_lower):
            return f"ë§¤ì¶œ ë°ì´í„° ì´ {len(sales_df)}ê±´"
        
        if "ë¸Œëœë“œ" in question_lower and ("ëª‡ê°œ" in question_lower or "ìˆ˜" in question_lower):
            if 'BRD_CD' in sales_df.columns:
                unique_brands = sales_df['BRD_CD'].nunique()
                return f"ì´ {unique_brands}ê°œ ë¸Œëœë“œ"
    
    # ê¸°ë³¸ ì‘ë‹µ
    return "ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

# =============================================================================
# ê²€ìƒ‰ëŸ‰ë¶„ì„ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

def save_search_query(query):
    """ê²€ìƒ‰ëŸ‰ ì¿¼ë¦¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(SEARCH_QUERY_FILE, 'w', encoding='utf-8') as f:
            f.write(query)
        return True
    except Exception as e:
        st.error(f"ê²€ìƒ‰ëŸ‰ ì¿¼ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_search_query():
    """ì €ì¥ëœ ê²€ìƒ‰ëŸ‰ ì¿¼ë¦¬ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        if os.path.exists(SEARCH_QUERY_FILE):
            with open(SEARCH_QUERY_FILE, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        st.warning(f"ê²€ìƒ‰ëŸ‰ ì¿¼ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    return None

def save_sales_query(query):
    """ë§¤ì¶œ ì¿¼ë¦¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(SALES_QUERY_FILE, 'w', encoding='utf-8') as f:
            f.write(query)
        return True
    except Exception as e:
        st.error(f"ë§¤ì¶œ ì¿¼ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_sales_query():
    """ì €ì¥ëœ ë§¤ì¶œ ì¿¼ë¦¬ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        if os.path.exists(SALES_QUERY_FILE):
            with open(SALES_QUERY_FILE, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        st.warning(f"ë§¤ì¶œ ì¿¼ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    return None

def get_default_search_query():
    """ê¸°ë³¸ ê²€ìƒ‰ëŸ‰ ì¿¼ë¦¬ ë°˜í™˜"""
    # 1. ì„¸ì…˜ì— ì €ì¥ëœ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if hasattr(st.session_state, 'default_search_query') and st.session_state.default_search_query:
        return st.session_state.default_search_query
    
    # 2. íŒŒì¼ì—ì„œ ì €ì¥ëœ ì¿¼ë¦¬ ë¡œë“œ
    saved_query = load_search_query()
    if saved_query:
        st.session_state.default_search_query = saved_query
        return saved_query
    
    # í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì¿¼ë¦¬ (ì‚¬ìš©ì ì„¤ì • ì¿¼ë¦¬ë¡œ ì—…ë°ì´íŠ¸)
    return """
    WITH current_day AS (
        SELECT
            w.SRCH_DT::DATE AS START_DT,                 -- ë°ì¼ë¦¬ ì¶œë ¥(START=END=í•´ë‹¹ì¼)
            w.SRCH_DT::DATE AS END_DT,
            w.KWD_NM        AS search_keyword,
            SUM(w.SRCH_CNT) AS SRCH_CNT_TY,
            m.BRD_CD        AS brand_code,
            m.ADULT_KIDS,
            m.CAT_NM        AS category,
            m.SUB_CAT_NM    AS sub_category,
            m.KWD_TYPE      AS keyword_type,
            m.COMP_TYPE,
            m.COMP_BRD_NM   AS comp_brand_name,
            YEAR(w.SRCH_DT)             AS ty_year,
            WEEKOFYEAR(w.SRCH_DT)       AS ty_week,
            DAYOFWEEKISO(w.SRCH_DT)     AS ty_dow
        FROM PRCS.DB_SRCH_KWD_NAVER_D w
        JOIN PRCS.DB_SRCH_KWD_NAVER_MST m
          ON w.KWD_NM = m.KWD_NM
        WHERE m.COMP_TYPE = 'ìì‚¬'
          AND m.BRD_CD IN ('M','X','V','ST')
          AND w.SRCH_DT >= '2024-09-01'
        GROUP BY
            w.SRCH_DT, w.KWD_NM,
            m.BRD_CD, m.ADULT_KIDS, m.CAT_NM, m.SUB_CAT_NM,
            m.KWD_TYPE, m.COMP_TYPE, m.COMP_BRD_NM
    ),
    previous_year_day AS (
        SELECT
            w2.SRCH_DT::DATE AS ly_dt,
            w2.KWD_NM        AS search_keyword,
            SUM(w2.SRCH_CNT) AS SRCH_CNT_LY_RAW,
            m2.BRD_CD        AS brand_code,
            m2.ADULT_KIDS,
            m2.CAT_NM        AS category,
            m2.SUB_CAT_NM    AS sub_category,
            m2.KWD_TYPE      AS keyword_type,
            m2.COMP_TYPE,
            m2.COMP_BRD_NM   AS comp_brand_name,
            YEAR(w2.SRCH_DT)         AS ly_year,
            WEEKOFYEAR(w2.SRCH_DT)   AS ly_week,
            DAYOFWEEKISO(w2.SRCH_DT) AS ly_dow
        FROM PRCS.DB_SRCH_KWD_NAVER_D w2
        JOIN PRCS.DB_SRCH_KWD_NAVER_MST m2
          ON w2.KWD_NM = m2.KWD_NM
        WHERE m2.COMP_TYPE = 'ìì‚¬'
          AND m2.BRD_CD IN ('M','X','V','ST')
          AND w2.SRCH_DT >= '2023-09-01'
        GROUP BY
            w2.SRCH_DT, w2.KWD_NM,
            m2.BRD_CD, m2.ADULT_KIDS, m2.CAT_NM, m2.SUB_CAT_NM,
            m2.KWD_TYPE, m2.COMP_TYPE, m2.COMP_BRD_NM
    )
    SELECT
        c.START_DT,
        c.END_DT,
        c.search_keyword,
        c.SRCH_CNT_TY,
        COALESCE(p.SRCH_CNT_LY_RAW, 0) AS SRCH_CNT_LY,
        c.brand_code,
        c.ADULT_KIDS,
        c.category,
        c.sub_category,
        c.keyword_type,
        c.COMP_TYPE,
        c.comp_brand_name
    FROM current_day c
    LEFT JOIN previous_year_day p
      ON  c.search_keyword = p.search_keyword
      AND c.brand_code     = p.brand_code
      /* ê°™ì€ ì£¼ì°¨ + ê°™ì€ ìš”ì¼ ê¸°ì¤€ìœ¼ë¡œ ì „ë…„ ë§¤ì¹­ */
      AND p.ly_year = c.ty_year - 1
      AND p.ly_week = c.ty_week
      AND p.ly_dow  = c.ty_dow
    ORDER BY c.START_DT DESC, c.SRCH_CNT_TY DESC;
    """

def load_snowflake_search_data(start_date=None, end_date=None):
    """Snowflakeì—ì„œ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        # ë‚ ì§œ ê¸°ë³¸ê°’ ì„¤ì • (2024ë…„ 9ì›” 2ì¼ë¶€í„° ìµœì‹ ê¹Œì§€)
        if not start_date:
            start_date = '2024-09-02'  # 2024ë…„ 9ì›” 2ì¼ë¶€í„°
        if not end_date:
            end_date = datetime.now().strftime('%Y-%m-%d')  # ìµœì‹  ë‚ ì§œê¹Œì§€
        
        # ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
        if isinstance(start_date, datetime):
            start_date = start_date.strftime('%Y-%m-%d')
        if isinstance(end_date, datetime):
            end_date = end_date.strftime('%Y-%m-%d')
        
        # ë§¤ë²ˆ ìƒˆë¡œìš´ ì—°ê²° ìƒì„± (ìºì‹œ ì œê±°ë¨)
        conn = get_snowflake_connection()
        if not conn:
            return pd.DataFrame()
        
        # ì¿¼ë¦¬ ê´€ë¦¬ì— ì €ì¥ëœ ì¿¼ë¦¬ ì‚¬ìš© (ëŒ€ì‹œë³´ë“œëŠ” ì—…ë¡œë“œ ê´€ë¦¬ ì¿¼ë¦¬ë§Œ ì‚¬ìš©)
        query = None
        if hasattr(st.session_state, 'custom_search_query') and st.session_state.custom_search_query:
            query = st.session_state.custom_search_query
        elif hasattr(st.session_state, 'default_search_query') and st.session_state.default_search_query:
            query = st.session_state.default_search_query

        # ê´€ë¦¬ ì¿¼ë¦¬ê°€ ì—†ëŠ” ê²½ìš°: ì‹¤í–‰í•˜ì§€ ì•Šê³  ì•ˆë‚´
        if not query:
            st.info("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬'ì—ì„œ Snowflakeì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
            return pd.DataFrame()
        
        try:
            # ë§¤ë²ˆ ìƒˆë¡œìš´ ì—°ê²° ìƒì„± (ìºì‹œ ì œê±°ë¡œ ì¸í•´ í•­ìƒ ìƒˆ ì—°ê²°)
            cursor = conn.cursor()
            cursor.execute(query)
            data = cursor.fetchall()
            
            # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
            columns = [desc[0] for desc in cursor.description]
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            # ì—°ê²° ì •ë¦¬
            try:
                if conn and not conn.is_closed():
                    conn.close()
            except:
                pass
            
            st.error(f"Snowflake ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
        
        if data:
            df = pd.DataFrame(data, columns=columns)
            return df
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"Snowflake ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame()

def save_search_data(df):
    """ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    try:
        df.to_csv(SEARCH_FILE, index=False, encoding='utf-8-sig')
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_search_data():
    """ë¡œì»¬ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        if os.path.exists(SEARCH_FILE):
            df = pd.read_csv(SEARCH_FILE, encoding='utf-8-sig')
            return df
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame()

def render_sales_dashboard_tab():
    """ë§¤ì¶œëŒ€ì‹œë³´ë“œ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ’° ë§¤ì¶œëŒ€ì‹œë³´ë“œ")
    
    # ë°ì´í„° ë¡œë“œ
    sales_df = load_sales_data()
    
    if sales_df.empty:
        st.warning("ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("## ğŸ“Š ì¼ë³„ ë§¤ì¶œ ë¶„ì„")
    
    # ë¸Œëœë“œ, ì•„ì´í…œ, ì‹œì¦Œ, ê¸°ê°„ í•„í„° ì¶”ê°€ (ëŒ€ì‹œë³´ë“œì™€ ë™ì¼í•œ êµ¬ì¡°)
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("#### ğŸ·ï¸ ë¸Œëœë“œ")
        # ë¸Œëœë“œ ë§¤í•‘ ì„¤ì •
        brand_mapping = {
            'MLB': 'M',
            'DX': 'X', 
            'DV': 'V',
            'ST': 'ST'
        }
        
        # ë§¤ì¶œ ë°ì´í„°ì—ì„œ ë¸Œëœë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (MLB ìš°ì„ ìˆœìœ„)
        if 'BRD_CD' in sales_df.columns:
            available_brands = []
            for brand_code in sales_df['BRD_CD'].unique():
                for display_name, code in brand_mapping.items():
                    if code == brand_code:
                        available_brands.append(display_name)
                        break
            
            # MLBë¥¼ ì²« ë²ˆì§¸ë¡œ ì •ë ¬
            if 'MLB' in available_brands:
                available_brands.remove('MLB')
                available_brands = ['MLB'] + available_brands
        else:
            available_brands = ['ì „ì²´']
            
        selected_brand = st.selectbox(
            "ë¶„ì„í•  ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", 
            options=["ì „ì²´"] + available_brands,
            index=0,
            key="sales_brand_filter"
        )
    
    with col2:
        st.markdown("#### ğŸ“¦ ì•„ì´í…œ")
        # ë§¤ì¶œ ë°ì´í„°ì—ì„œ ì•„ì´í…œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        if 'ITEM' in sales_df.columns:
            available_items = sales_df['ITEM'].unique().tolist()
        else:
            available_items = []
            
        selected_item = st.selectbox(
            "ë¶„ì„í•  ì•„ì´í…œì„ ì„ íƒí•˜ì„¸ìš”", 
            options=["ì „ì²´"] + available_items,
            index=0,
            key="sales_item_filter"
        )
    
    with col3:
        st.markdown("#### ğŸŒŸ ì‹œì¦Œ")
        # ì‹œì¦Œ í•„í„° ì˜µì…˜
        season_options = ["ì „ì²´", "24FW", "25SS", "25FW"]
        selected_season = st.selectbox(
            "ë¶„ì„í•  ì‹œì¦Œì„ ì„ íƒí•˜ì„¸ìš”",
            options=season_options,
            index=0,
            key="sales_season_filter"
        )
    
    with col4:
        st.markdown("#### ğŸ“… ê¸°ê°„ ì„ íƒ")
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        if not sales_df.empty and 'DT' in sales_df.columns:
            try:
                sales_df['DT'] = pd.to_datetime(sales_df['DT'], errors='coerce')
                valid_dates = sales_df['DT'].dropna()
                
                if len(valid_dates) > 0:
                    # ì‹œì¦Œ ì„ íƒì— ë”°ë¥¸ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
                    if selected_season == "24FW":
                        season_min = pd.to_datetime('2024-09-01')
                        season_max = pd.to_datetime('2025-02-28')
                    elif selected_season == "25SS":
                        season_min = pd.to_datetime('2025-03-01')
                        season_max = pd.to_datetime('2025-08-31')
                    elif selected_season == "25FW":
                        season_min = pd.to_datetime('2025-09-01')
                        season_max = pd.to_datetime('2026-02-28')
                    else:
                        # ì „ì²´ ì„ íƒ ì‹œ ëª¨ë“  ë°ì´í„° ë²”ìœ„ ì‚¬ìš©
                        season_min = valid_dates.min()
                        season_max = valid_dates.max()
                    
                    # ì‹œì¦Œ ë²”ìœ„ì™€ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì˜ êµì§‘í•©
                    min_date = max(season_min, valid_dates.min())
                    max_date = min(season_max, valid_dates.max())
                    
                    # ë‚ ì§œ ìŠ¬ë¼ì´ë”
                    date_range = st.slider(
                        "ë¶„ì„í•  ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”",
                        min_value=min_date.date(),
                        max_value=max_date.date(),
                        value=(min_date.date(), max_date.date()),
                        format="YYYY-MM-DD",
                        key="sales_date_range_slider"
                    )
                else:
                    st.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    date_range = None
            except Exception as e:
                st.error(f"ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                date_range = None
        else:
            st.warning("ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            date_range = None
    
    # ë§¤ì¶œ ë°ì´í„° í•„í„°ë§ ë° ê·¸ë˜í”„ ìƒì„±
    if not sales_df.empty:
        # í•„í„°ë§ëœ ë§¤ì¶œ ë°ì´í„° ì¤€ë¹„
        filtered_sales_df = sales_df.copy()
        
        # ë¸Œëœë“œ í•„í„° ì ìš©
        if selected_brand != "ì „ì²´":
            brand_code = brand_mapping.get(selected_brand, selected_brand)
            if 'BRD_CD' in filtered_sales_df.columns:
                filtered_sales_df = filtered_sales_df[filtered_sales_df['BRD_CD'] == brand_code]
        
        # ì•„ì´í…œ í•„í„° ì ìš©
        if selected_item != "ì „ì²´":
            filtered_sales_df = filtered_sales_df[filtered_sales_df['ITEM'] == selected_item]
        
        # ì‹œì¦Œ í•„í„° ì ìš©
        if selected_season != "ì „ì²´":
            if 'ì‹œì¦Œ' in filtered_sales_df.columns:
                filtered_sales_df = filtered_sales_df[filtered_sales_df['ì‹œì¦Œ'] == selected_season]
        
        # ë‚ ì§œ í•„í„° ì ìš©
        if date_range:
            filtered_sales_df['DT'] = pd.to_datetime(filtered_sales_df['DT'])
            filtered_sales_df = filtered_sales_df[
                (filtered_sales_df['DT'] >= pd.to_datetime(date_range[0])) &
                (filtered_sales_df['DT'] <= pd.to_datetime(date_range[1]))
            ]
        
        # ì¼ë³„ ë§¤ì¶œ ë°ì´í„° ì§‘ê³„
        if not filtered_sales_df.empty:
            daily_sales = filtered_sales_df.groupby('DT').agg({
                'SALE_AMT_TY': 'sum',  # ë‹¹í•´ ë§¤ì¶œì•¡
                'SALE_AMT_LY': 'sum'   # ì „ë…„ ë§¤ì¶œì•¡
            }).reset_index()
            
            daily_sales['DT'] = pd.to_datetime(daily_sales['DT'])
            daily_sales = daily_sales.sort_values('DT')
            
            # ë§¤ì¶œì•¡ ê·¸ë˜í”„ ìƒì„±
            import plotly.graph_objects as go
            
            fig = go.Figure()
            
            # ë‹¹í•´ ë§¤ì¶œì•¡ ë¼ì¸
            fig.add_trace(go.Scatter(
                x=daily_sales['DT'],
                y=daily_sales['SALE_AMT_TY'],
                mode='lines+markers',
                name='ë‹¹í•´ ë§¤ì¶œì•¡',
                line=dict(color='#1f77b4', width=3),
                marker=dict(size=6)
            ))
            
            # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
            if 'SALE_AMT_LY' in daily_sales.columns and not daily_sales['SALE_AMT_LY'].isna().all():
                fig.add_trace(go.Scatter(
                    x=daily_sales['DT'],
                    y=daily_sales['SALE_AMT_LY'],
                    mode='lines+markers',
                    name='ì „ë…„ ë§¤ì¶œì•¡',
                    line=dict(color='#ff7f0e', width=2, dash='dash'),
                    marker=dict(size=5)
                ))
            
            # ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title="ì¼ë³„ ë§¤ì¶œì•¡ íŠ¸ë Œë“œ (ë‹¹í•´ vs ì „ë…„)",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ë§¤ì¶œì•¡ (ì›)",
                xaxis=dict(
                    type='date',
                    showgrid=True,
                    gridcolor='lightgray'
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    tickformat=',.0f'
                ),
                hovermode='x unified',
                                                    legend=dict(
                                                        orientation='h',
                                                        x=0,
                                                        y=1.1,
                                                        xanchor='left',
                                                        yanchor='bottom',
                                                        bgcolor='rgba(255,255,255,0.8)',
                                                        bordercolor='gray',
                                                        borderwidth=1
                                                    ),
                height=500,
                template='plotly_white'
            )
            
            # í˜¸ë²„ í…œí”Œë¦¿ ì„¤ì •
            fig.update_traces(
                hovertemplate='<b>%{fullData.name}</b><br>' +
                             'ë‚ ì§œ: %{x}<br>' +
                             'ë§¤ì¶œì•¡: %{y:,.0f}ì›<br>' +
                             '<extra></extra>'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ë§¤ì¶œ í†µê³„ ìš”ì•½
            st.markdown("### ğŸ“ˆ ë§¤ì¶œ í†µê³„ ìš”ì•½")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_current = daily_sales['SALE_AMT_TY'].sum()
                st.metric(
                    label="**ì„ íƒ ê¸°ê°„ ë§¤ì¶œì•¡**",
                    value=f"{total_current:,.0f}ì›"
                )
            
            with col2:
                if 'SALE_AMT_LY' in daily_sales.columns and not daily_sales['SALE_AMT_LY'].isna().all():
                    total_previous = daily_sales['SALE_AMT_LY'].sum()
                    st.metric(
                        label="**ì „ë…„ ë™ì¼ê¸°ê°„ ë§¤ì¶œì•¡**",
                        value=f"{total_previous:,.0f}ì›"
                    )
                else:
                    st.metric(
                        label="**ì „ë…„ ë™ì¼ê¸°ê°„ ë§¤ì¶œì•¡**",
                        value="ë°ì´í„° ì—†ìŒ"
                    )
            
            with col3:
                if 'SALE_AMT_LY' in daily_sales.columns and not daily_sales['SALE_AMT_LY'].isna().all():
                    total_previous = daily_sales['SALE_AMT_LY'].sum()
                    if total_previous > 0:
                        yoy_change = ((total_current - total_previous) / total_previous) * 100
                        st.metric(
                            label="**ì „ë…„ ë™ì¼ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ë¥ **",
                            value=f"{yoy_change:+.1f}%"
                        )
                    else:
                        st.metric(
                            label="**ì „ë…„ ë™ì¼ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ë¥ **",
                            value="ê³„ì‚° ë¶ˆê°€"
                        )
                else:
                    st.metric(
                        label="**ì „ë…„ ë™ì¼ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ë¥ **",
                        value="ë°ì´í„° ì—†ìŒ"
                    )
            
            with col4:
                avg_daily = daily_sales['SALE_AMT_TY'].mean()
                st.metric(
                    label="**ì¼í‰ê·  ë§¤ì¶œì•¡**",
                    value=f"{avg_daily:,.0f}ì›"
                )
        else:
            st.warning("ì„ íƒí•œ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def render_search_analysis_tab():
    """ê²€ìƒ‰ëŸ‰ë¶„ì„ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ” ê²€ìƒ‰ëŸ‰ë¶„ì„")
    st.markdown("""
    <style>
    div[data-testid="stMetricLabel"] {
        font-size: 0.7em; /* ë¼ë²¨ ê¸€ì í¬ê¸° ì¤„ì„ */
    }
    div[data-testid="stMetricValue"] {
        font-size: 0.9em; /* ê°’ ê¸€ì í¬ê¸° ì¤„ì„ */
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë¡œë“œ (ì €ì¥ëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©)
    search_df = pd.DataFrame()
    
    # 1. ë¨¼ì € ì„¸ì…˜ì— ì €ì¥ëœ ë°ì´í„° í™•ì¸
    if hasattr(st.session_state, 'search_data') and not st.session_state.search_data.empty:
        search_df = st.session_state.search_data
    # 2. ì„¸ì…˜ì— ì—†ìœ¼ë©´ ë¡œì»¬ CSVì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ìƒˆë¡œê³ ì¹¨ ì‹œ ì„¸ì…˜ ì´ˆê¸°í™” ëŒ€ì‘)
    elif os.path.exists(SEARCH_FILE):
        file_df = load_search_data()
        if not file_df.empty:
            st.session_state.search_data = file_df
            search_df = file_df
    # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ ë°ì´í„° ì—†ìŒ ì•ˆë‚´ (ì§ì ‘ Snowflake ë¡œë“œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    else:
        search_df = pd.DataFrame()
    
    if not search_df.empty:
        # ë°ì´í„° í•„í„°ë§ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        filtered_df = search_df
        
        if not filtered_df.empty:
            
            # ë¸Œëœë“œ ì˜µì…˜ ì •ì˜ (ì‹¤ì œ ë°ì´í„°ì—ì„œ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°)
            brand_columns = ['BRD_CD', 'brand_code', 'BRAND_CODE', 'brand_cd']
            brand_col = None
            for col in brand_columns:
                if col in filtered_df.columns:
                    brand_col = col
                    break
            
            if brand_col:
                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ê³ ìœ í•œ ë¸Œëœë“œ ì½”ë“œ ì¶”ì¶œ
                unique_brands = sorted(filtered_df[brand_col].dropna().unique())
                
                # ì§€ì •ëœ ë¸Œëœë“œë§Œ í•„í„°ë§ (M, X, V, ST)
                allowed_brands = ['M', 'X', 'V', 'ST']
                filtered_brands = [brand for brand in unique_brands if brand in allowed_brands]
                brand_options = ['ì „ì²´'] + filtered_brands
            else:
                # ë¸Œëœë“œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                brand_options = ['ì „ì²´', 'V']
            
            # ê°€ì¥ ìµœê·¼ ì£¼ì°¨ ë‚ ì§œ ê³„ì‚°
            if not filtered_df.empty and 'START_DT' in filtered_df.columns:
                # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì°¾ê¸°
                latest_date = pd.to_datetime(filtered_df['START_DT']).max()
                # í•´ë‹¹ ë‚ ì§œì˜ ì£¼ì°¨ ì‹œì‘ì¼ ê³„ì‚° (ì›”ìš”ì¼)
                latest_week_start = latest_date - pd.Timedelta(days=latest_date.weekday())
                default_date = latest_week_start.date()
            else:
                default_date = datetime(2024, 9, 2).date()
            
            dashboard_start_date = st.date_input(
                "ëŒ€ì‹œë³´ë“œ ì‹œì‘ ë‚ ì§œ (í•´ë‹¹ ì£¼ì˜ ì›”ìš”ì¼ ë°ì´í„° í‘œì‹œ)",
                value=default_date,  # ê°€ì¥ ìµœê·¼ ì£¼ì°¨ ì‹œì‘ì¼
                key="dashboard_start_date",
                help="ì„ íƒí•œ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
            )
            
            # ê²€ìƒ‰ì–´ ìˆœìœ„ ëŒ€ì‹œë³´ë“œ í‘œì‹œ
            col_title, col_download = st.columns([3, 1])
            with col_title:
                st.markdown("#### ğŸ“‹ ê²€ìƒ‰ì–´ ìˆœìœ„ ëŒ€ì‹œë³´ë“œ")
            with col_download:
                # ì£¼ì°¨ë³„ ê²€ìƒ‰ëŸ‰ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
                if st.button("ğŸ“¥ ì£¼ì°¨ë³„ ê²€ìƒ‰ëŸ‰ ë‹¤ìš´ë¡œë“œ", use_container_width=True, key="weekly_search_download"):
                    # í˜„ì¬ ì£¼ì°¨ê°€ ì†í•œ ì›”ì˜ ì£¼ì°¨ë³„ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ìƒì„±
                    selected_date = pd.to_datetime(dashboard_start_date)
                    current_month = selected_date.month
                    current_year = selected_date.year
                    
                    # í•´ë‹¹ ì›”ì˜ ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ê³„ì‚°
                    month_start = pd.Timestamp(current_year, current_month, 1)
                    if current_month == 12:
                        month_end = pd.Timestamp(current_year + 1, 1, 1) - pd.Timedelta(days=1)
                    else:
                        month_end = pd.Timestamp(current_year, current_month + 1, 1) - pd.Timedelta(days=1)
                    
                    # START_DTì™€ END_DT ê¸°ì¤€ìœ¼ë¡œ í•´ë‹¹ ì›”ì— í¬í•¨ë˜ëŠ” ë°ì´í„° í•„í„°ë§
                    filtered_df_copy = filtered_df.copy()
                    filtered_df_copy['START_DT_dt'] = pd.to_datetime(filtered_df_copy['START_DT'])
                    
                    # END_DT ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ START_DTë¥¼ END_DTë¡œ ì‚¬ìš©
                    if 'END_DT' in filtered_df_copy.columns:
                        filtered_df_copy['END_DT_dt'] = pd.to_datetime(filtered_df_copy['END_DT'])
                    else:
                        filtered_df_copy['END_DT_dt'] = filtered_df_copy['START_DT_dt']
                    
                    # START_DT ë˜ëŠ” END_DTê°€ í•´ë‹¹ ì›”ì— í¬í•¨ë˜ë©´ í¬í•¨
                    # ì¦‰, ì£¼ì°¨ì˜ ì¼ë¶€ë¼ë„ í•´ë‹¹ ì›”ì— í¬í•¨ë˜ë©´ ì£¼ì°¨ ì „ì²´ë¥¼ í¬í•¨
                    month_data = filtered_df_copy[
                        (
                            (filtered_df_copy['START_DT_dt'] >= month_start) & 
                            (filtered_df_copy['START_DT_dt'] <= month_end)
                        ) | (
                            (filtered_df_copy['END_DT_dt'] >= month_start) & 
                            (filtered_df_copy['END_DT_dt'] <= month_end)
                        )
                    ].copy()
                    
                    # ì£¼ì°¨ ë‹¨ìœ„ë¡œ í¬í•¨í•˜ê¸° ìœ„í•´, í•´ë‹¹ ì›”ê³¼ ê²¹ì¹˜ëŠ” ì£¼ì°¨ì˜ ëª¨ë“  ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•¨
                    # ì£¼ì°¨ ì‹œì‘ì¼(ì›”ìš”ì¼) ê³„ì‚° - ISO ê¸°ì¤€ (ì›”ìš”ì¼=0, ì¼ìš”ì¼=6)
                    filtered_df_copy['week_start'] = filtered_df_copy['START_DT_dt'].apply(
                        lambda x: x - pd.Timedelta(days=x.weekday())
                    )
                    
                    # í•´ë‹¹ ì›”ì— í¬í•¨ë˜ëŠ” ë°ì´í„°ë“¤ì˜ ì£¼ì°¨ ì°¾ê¸°
                    month_overlap_data = filtered_df_copy[
                        (
                            (filtered_df_copy['START_DT_dt'] >= month_start) & 
                            (filtered_df_copy['START_DT_dt'] <= month_end)
                        ) | (
                            (filtered_df_copy['END_DT_dt'] >= month_start) & 
                            (filtered_df_copy['END_DT_dt'] <= month_end)
                        )
                    ]
                    
                    # í•´ë‹¹ ì›”ê³¼ ê²¹ì¹˜ëŠ” ëª¨ë“  ì£¼ì°¨ ì°¾ê¸° (ì£¼ì°¨ ì‹œì‘ì¼ ê¸°ì¤€)
                    valid_weeks = month_overlap_data['week_start'].unique()
                    
                    # ì›ë³¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì£¼ì°¨ë“¤ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì£¼ì°¨ ì „ì²´ í¬í•¨)
                    month_data = filtered_df_copy[
                        filtered_df_copy['week_start'].isin(valid_weeks)
                    ].copy()
                    
                    # ì„ì‹œ ì»¬ëŸ¼ ì •ë¦¬ (week_startëŠ” ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ë¯€ë¡œ ìœ ì§€)
                    month_data = month_data.drop(columns=['START_DT_dt', 'END_DT_dt'], errors='ignore')
                    
                    if not month_data.empty:
                        # ì»¬ëŸ¼ëª… ë™ì  í™•ì¸
                        keyword_cols = ['SEARCH_KEYWORD', 'search_keyword', 'ê²€ìƒ‰ì–´']
                        keyword_col = None
                        for col in keyword_cols:
                            if col in month_data.columns:
                                keyword_col = col
                                break
                        
                        if keyword_col is None:
                            st.error("ê²€ìƒ‰ì–´ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ë¸Œëœë“œ ì»¬ëŸ¼ í™•ì¸
                            brand_cols = ['BRAND_CODE', 'brand_code', 'BRD_CD', 'brand_cd']
                            brand_col = None
                            for col in brand_cols:
                                if col in month_data.columns:
                                    brand_col = col
                                    break
                            
                            # ì£¼ì°¨ë³„ë¡œ ê·¸ë£¹í™” (ì›”ìš”ì¼ ê¸°ì¤€)
                            month_data['week_start'] = pd.to_datetime(month_data['START_DT']).apply(
                                lambda x: x - pd.Timedelta(days=x.weekday())
                            )
                            # ì£¼ì°¨ ëë‚ ì§œ (ì¼ìš”ì¼) ê³„ì‚°
                            month_data['week_end'] = month_data['week_start'] + pd.Timedelta(days=6)
                            
                            # ê·¸ë£¹í™”í•  ì»¬ëŸ¼ ëª©ë¡
                            groupby_cols = ['week_start', 'week_end', keyword_col]
                            if brand_col:
                                groupby_cols.append(brand_col)
                            
                            # ì£¼ì°¨ë³„, ê²€ìƒ‰ì–´ë³„, ë¸Œëœë“œë³„ ê²€ìƒ‰ëŸ‰ ì§‘ê³„
                            # ë¨¼ì € ì£¼ì°¨ë³„ë¡œ ì‹¤ì œ í¬í•¨ëœ ë‚ ì§œ í™•ì¸ (ë””ë²„ê¹…ìš©)
                            if len(month_data) > 0:
                                # ì£¼ì°¨ë³„ë¡œ í¬í•¨ëœ START_DT ëª©ë¡ í™•ì¸
                                week_dates_check = month_data.groupby('week_start')['START_DT'].unique().reset_index()
                                week_dates_check['week_end'] = week_dates_check['week_start'] + pd.Timedelta(days=6)
                            
                            weekly_summary = month_data.groupby(groupby_cols).agg({
                                'SRCH_CNT_TY': 'sum',
                                'SRCH_CNT_LY': 'sum'
                            }).reset_index()
                            
                            # ì£¼ì°¨ë³„ ì‹¤ì œ í¬í•¨ëœ ë‚ ì§œ ë²”ìœ„ í™•ì¸ (ë””ë²„ê¹… ë©”ì‹œì§€)
                            if len(weekly_summary) > 0:
                                check_df = month_data.groupby('week_start').agg({
                                    'START_DT': ['min', 'max']
                                }).reset_index()
                                check_df.columns = ['week_start', 'min_date', 'max_date']
                                # ì„ì‹œë¡œ í™•ì¸ ë©”ì‹œì§€ í‘œì‹œ (ë””ë²„ê¹…ìš©, í•„ìš”ì‹œ ì œê±°)
                                # st.info(f"ì£¼ì°¨ë³„ ë°ì´í„° ë²”ìœ„: {len(check_df)}ê°œ ì£¼ì°¨ í¬í•¨")
                            
                            # ì „ë…„ ë¹„êµ ê³„ì‚°
                            weekly_summary['ì „ë…„ë¹„êµ'] = weekly_summary.apply(
                                lambda row: f"{((row['SRCH_CNT_TY'] - row['SRCH_CNT_LY']) / row['SRCH_CNT_LY'] * 100):+.1f}%" 
                                if row['SRCH_CNT_LY'] > 0 else "ì‹ ê·œ", axis=1
                            )
                            
                            # ì»¬ëŸ¼ëª… ë³€ê²½
                            rename_dict = {
                                'week_start': 'START_DT',
                                'week_end': 'END_DT',
                                keyword_col: 'ê²€ìƒ‰ì–´',
                                'SRCH_CNT_TY': 'ê¸°ê°„ê²€ìƒ‰ëŸ‰',
                                'SRCH_CNT_LY': 'ì „ë…„ê²€ìƒ‰ëŸ‰'
                            }
                            
                            # ë¸Œëœë“œ ì»¬ëŸ¼ëª… ë§¤í•‘
                            brand_mapping = {'M': 'MLB', 'X': 'DX', 'V': 'DV', 'ST': 'ST'}
                            if brand_col:
                                rename_dict[brand_col] = 'ë¸Œëœë“œ'
                                # ë¸Œëœë“œ ì½”ë“œë¥¼ ë¸Œëœë“œëª…ìœ¼ë¡œ ë³€í™˜
                                weekly_summary[brand_col] = weekly_summary[brand_col].map(brand_mapping).fillna(weekly_summary[brand_col])
                            
                            export_df = weekly_summary.rename(columns=rename_dict)
                            
                            # ì „ë…„ê²€ìƒ‰ëŸ‰ì„ ì •ìˆ˜ë¡œ í¬ë§·íŒ… (ì—†ëŠ” ê²½ìš° 0)
                            export_df['ì „ë…„ê²€ìƒ‰ëŸ‰'] = export_df['ì „ë…„ê²€ìƒ‰ëŸ‰'].fillna(0).astype(int)
                            
                            # ì»¬ëŸ¼ ìˆœì„œ ì„¤ì •
                            if brand_col:
                                export_df = export_df[['START_DT', 'END_DT', 'ë¸Œëœë“œ', 'ê²€ìƒ‰ì–´', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰', 'ì „ë…„ê²€ìƒ‰ëŸ‰', 'ì „ë…„ë¹„êµ']]
                            else:
                                export_df = export_df[['START_DT', 'END_DT', 'ê²€ìƒ‰ì–´', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰', 'ì „ë…„ê²€ìƒ‰ëŸ‰', 'ì „ë…„ë¹„êµ']]
                            
                            # ì£¼ì°¨ ë‚ ì§œë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ìœ ì§€ (ì‹œê°„ì€ 00:00:00ìœ¼ë¡œ ì„¤ì •)
                            export_df['START_DT'] = pd.to_datetime(export_df['START_DT'])
                            export_df['END_DT'] = pd.to_datetime(export_df['END_DT'])
                            
                            # ì£¼ì°¨ ìˆœì„œëŒ€ë¡œ ì •ë ¬
                            export_df = export_df.sort_values(['START_DT', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰'], ascending=[True, False])
                            
                            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
                            from io import BytesIO
                            from datetime import datetime
                            
                            output = BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl', date_format='yyyy-mm-dd') as writer:
                                export_df.to_excel(writer, sheet_name='ì£¼ì°¨ë³„ê²€ìƒ‰ëŸ‰', index=False)
                                
                                # ë‚ ì§œ ì»¬ëŸ¼ í¬ë§· ì„¤ì • (ì‹œê°„ ì œê±°)
                                workbook = writer.book
                                worksheet = writer.sheets['ì£¼ì°¨ë³„ê²€ìƒ‰ëŸ‰']
                                
                                # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ì•„ì„œ í¬ë§· ì ìš©
                                for col_idx, col_name in enumerate(export_df.columns, start=1):
                                    if col_name in ['START_DT', 'END_DT']:
                                        # í—¤ë”ë¥¼ ì œì™¸í•œ ëª¨ë“  í–‰ì— ë‚ ì§œ í¬ë§· ì ìš©
                                        for row_idx in range(2, len(export_df) + 2):
                                            cell = worksheet.cell(row=row_idx, column=col_idx)
                                            if isinstance(cell.value, datetime):
                                                cell.number_format = 'YYYY-MM-DD'
                            
                            output.seek(0)
                            
                            st.download_button(
                                label="ğŸ’¾ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=output.getvalue(),
                                file_name=f"ì£¼ì°¨ë³„ê²€ìƒ‰ëŸ‰_{current_year}{current_month:02d}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="weekly_search_excel_download"
                            )
                            st.success(f"âœ… {current_year}ë…„ {current_month}ì›” ì£¼ì°¨ë³„ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.warning("í•´ë‹¹ ì›”ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë¡œë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
            display_df = filtered_df.copy()
            
            # 1. ê²€ìƒ‰ëŸ‰ í•©ê³„ ê³„ì‚° (í‚¤ì›Œë“œë³„ë¡œ ê·¸ë£¹í™”)
            if 'SRCH_CNT_TY' in display_df.columns and 'SEARCH_KEYWORD' in display_df.columns:
                # í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ í•©ê³„
                keyword_summary = display_df.groupby('SEARCH_KEYWORD').agg({
                    'SRCH_CNT_TY': 'sum',
                    'SRCH_CNT_LY': 'sum',
                    'BRAND_CODE': 'first',
                    'CATEGORY': 'first',
                    'SUB_CATEGORY': 'first',
                    'KEYWORD_TYPE': 'first'
                }).reset_index()
                
                # 2. YoY ì¦ê°ë¥  ê³„ì‚°
                keyword_summary['YOY_CHANGE_PCT'] = keyword_summary.apply(
                    lambda row: ((row['SRCH_CNT_TY'] - row['SRCH_CNT_LY']) / row['SRCH_CNT_LY'] * 100) 
                    if row['SRCH_CNT_LY'] > 0 else 0, axis=1
                )
                
                # 3. ìˆœìœ„ ê³„ì‚° (ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
                keyword_summary = keyword_summary.sort_values('SRCH_CNT_TY', ascending=False)
                keyword_summary['RANK'] = range(1, len(keyword_summary) + 1)
                
                # 4. ì»¬ëŸ¼ëª… ë§¤í•‘
                display_df = keyword_summary.rename(columns={
                    'RANK': 'ìˆœìœ„',
                    'SEARCH_KEYWORD': 'ê²€ìƒ‰ì–´',
                    'YOY_CHANGE_PCT': 'ì „ë…„ëŒ€ë¹„ ì¦ê°',
                    'SRCH_CNT_TY': 'ê¸°ê°„ê²€ìƒ‰ëŸ‰',
                    'BRAND_CODE': 'ë¸Œëœë“œì½”ë“œ',
                    'CATEGORY': 'ì¹´í…Œê³ ë¦¬',
                    'SUB_CATEGORY': 'ì„œë¸Œì¹´í…Œê³ ë¦¬',
                    'KEYWORD_TYPE': 'í‚¤ì›Œë“œíƒ€ì…'
                })
                
                # 5. ì „ë…„ëŒ€ë¹„ ì¦ê° í¬ë§·íŒ…
                display_df['ì „ë…„ëŒ€ë¹„ ì¦ê°'] = display_df['ì „ë…„ëŒ€ë¹„ ì¦ê°'].apply(
                    lambda x: f"{x:+.1f}%" if pd.notna(x) else "0.0%"
                )
            else:
                # ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                display_df = pd.DataFrame(columns=['ìˆœìœ„', 'ê²€ìƒ‰ì–´', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰'])
            
            # ì£¼ì°¨ë³„ ë°ì´í„° ì²˜ë¦¬
            if not display_df.empty:
                # ì„ íƒëœ ì‹œì‘ë‚ ì§œì˜ ì£¼ì°¨ ê³„ì‚°
                selected_date = pd.to_datetime(dashboard_start_date)
                selected_week_start = selected_date - pd.Timedelta(days=selected_date.weekday())
                selected_week_end = selected_week_start + pd.Timedelta(days=6)
                
                # ì „ì£¼ì°¨ ê³„ì‚°
                prev_week_start = selected_week_start - pd.Timedelta(days=7)
                prev_week_end = prev_week_start + pd.Timedelta(days=6)
                
                # ì „ë…„ë„ ë™ì¼ì£¼ì°¨ ê³„ì‚° (ì •í™•í•œ ì£¼ì°¨ ë§¤ì¹­)
                # í˜„ì¬ ì£¼ì°¨ì˜ ì—°ë„ì™€ ì£¼ì°¨ ë²ˆí˜¸ë¥¼ êµ¬í•´ì„œ ì „ë…„ë„ ë™ì¼ ì£¼ì°¨ ì°¾ê¸°
                current_year = selected_week_start.year
                current_week_num = selected_week_start.isocalendar()[1]  # ISO ì£¼ì°¨ ë²ˆí˜¸
                
                # ì „ë…„ë„ ë™ì¼ ì£¼ì°¨ì˜ ì›”ìš”ì¼ ê³„ì‚°
                prev_year = current_year - 1
                prev_year_week_start = pd.Timestamp.fromisocalendar(prev_year, current_week_num, 1)
                prev_year_week_end = prev_year_week_start + pd.Timedelta(days=6)
                
                # ë°ì´í„°ê°€ ì›”ìš”ì¼ ê¸°ì¤€ì´ë¯€ë¡œ, ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ì›”ìš”ì¼ë§Œ í•„í„°ë§
                current_week_monday = selected_week_start
                prev_week_monday = prev_week_start
                prev_year_week_monday = prev_year_week_start
                
                # ì›ë³¸ ë°ì´í„°ì—ì„œ ì£¼ì°¨ë³„ í•„í„°ë§ (ì£¼ì°¨ ì „ì²´ ë°ì´í„° ì§‘ê³„)
                current_week_end = current_week_monday + pd.Timedelta(days=6)
                prev_week_end = prev_week_monday + pd.Timedelta(days=6)
                prev_year_week_end = prev_year_week_monday + pd.Timedelta(days=6)
                
                current_week_data = filtered_df[
                    (pd.to_datetime(filtered_df['START_DT']) >= pd.Timestamp(current_week_monday)) &
                    (pd.to_datetime(filtered_df['START_DT']) <= pd.Timestamp(current_week_end))
                ].copy()
                
                prev_week_data = filtered_df[
                    (pd.to_datetime(filtered_df['START_DT']) >= pd.Timestamp(prev_week_monday)) &
                    (pd.to_datetime(filtered_df['START_DT']) <= pd.Timestamp(prev_week_end))
                ].copy()
                
                prev_year_week_data = filtered_df[
                    (pd.to_datetime(filtered_df['START_DT']) >= pd.Timestamp(prev_year_week_monday)) &
                    (pd.to_datetime(filtered_df['START_DT']) <= pd.Timestamp(prev_year_week_end))
                ].copy()
                
                
                # ë¸Œëœë“œë³„ë¡œ ì´ë¯¸ ë‚˜ëˆ„ì–´ì„œ í‘œì‹œí•˜ë¯€ë¡œ ì „ì²´ ë°ì´í„° ì‚¬ìš©
                
                # ì£¼ì°¨ë³„ ê²€ìƒ‰ì–´ ìˆœìœ„ ê³„ì‚°
                def calculate_weekly_ranking(week_data, brand_code=None, rising_keywords=None, falling_keywords=None):
                    if week_data.empty:
                        return pd.DataFrame(columns=['ìˆœìœ„', 'ê²€ìƒ‰ì–´', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰'])
                    
                    # ë¸Œëœë“œë³„ íŠ¹ì • ì¸ë¬¼ëª…ì´ í¬í•¨ëœ í‚¤ì›Œë“œ ì œì™¸
                    if brand_code:
                        excluded_keywords = []
                        if brand_code == 'V':  # DV ë¸Œëœë“œ
                            excluded_keywords = ['ê¹€ì§€ì›']
                        elif brand_code == 'ST':  # ST ë¸Œëœë“œ
                            excluded_keywords = ['ë°•ì§€í˜„']
                        elif brand_code == 'X':  # DX ë¸Œëœë“œ
                            excluded_keywords = ['ê³ ìœ¤ì •', 'ë³€ìš°ì„']
                        
                        # ì œì™¸í•  í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²€ìƒ‰ì–´ í•„í„°ë§
                        if excluded_keywords:
                            for excluded_name in excluded_keywords:
                                week_data = week_data[~week_data['SEARCH_KEYWORD'].str.contains(excluded_name, na=False)]
                    
                    # í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ í•©ê³„
                    keyword_summary = week_data.groupby('SEARCH_KEYWORD').agg({
                        'SRCH_CNT_TY': 'sum',
                        'SRCH_CNT_LY': 'sum'
                    }).reset_index()
                    
                    # YoY ì¦ê°ë¥  ê³„ì‚°
                    keyword_summary['YOY_CHANGE_PCT'] = keyword_summary.apply(
                        lambda row: ((row['SRCH_CNT_TY'] - row['SRCH_CNT_LY']) / row['SRCH_CNT_LY'] * 100) 
                        if row['SRCH_CNT_LY'] > 0 else 0, axis=1
                    )
                    
                    # ìˆœìœ„ ê³„ì‚°
                    keyword_summary = keyword_summary.sort_values('SRCH_CNT_TY', ascending=False)
                    keyword_summary['RANK'] = range(1, len(keyword_summary) + 1)
                    
                    # ê¸°ê°„ê²€ìƒ‰ëŸ‰ë§Œ í‘œì‹œ (ì „ë…„ëŒ€ë¹„ ì¦ê°ë¥  ì œê±°)
                    result_df = keyword_summary.copy()
                    result_df['ê¸°ê°„ê²€ìƒ‰ëŸ‰'] = result_df['SRCH_CNT_TY'].apply(lambda x: f"{x:,.0f}")
                    
                    # ìƒìŠ¹/í•˜ë½ í‚¤ì›Œë“œì— ì•„ì´ì½˜ ì¶”ê°€ (í‚¤ì›Œë“œëª… ì˜¤ë¥¸ìª½ì— í‘œì‹œ)
                    if rising_keywords:
                        # 4ë‹¨ê³„ ì´ìƒ ìƒìŠ¹ í‚¤ì›Œë“œ (ì´ˆë¡ ë™ê·¸ë¼ë¯¸ ë‘ ê°œ)
                        major_rising_keywords = [item['ê²€ìƒ‰ì–´'] for item in rising_keywords if item['ìˆœìœ„ë³€í™”'] >= 4]
                        # 2-3ë‹¨ê³„ ìƒìŠ¹ í‚¤ì›Œë“œ (ì´ˆë¡ ë™ê·¸ë¼ë¯¸ í•œ ê°œ)
                        minor_rising_keywords = [item['ê²€ìƒ‰ì–´'] for item in rising_keywords if 2 <= item['ìˆœìœ„ë³€í™”'] < 4]
                        
                        def add_rising_icon(x):
                            if x in major_rising_keywords:
                                return f"{x} ğŸŸ¢ğŸŸ¢"
                            elif x in minor_rising_keywords:
                                return f"{x} ğŸŸ¢"
                            else:
                                return x
                        
                        result_df['ê²€ìƒ‰ì–´'] = result_df['SEARCH_KEYWORD'].apply(add_rising_icon)
                    else:
                        result_df['ê²€ìƒ‰ì–´'] = result_df['SEARCH_KEYWORD']
                    
                    # í•˜ë½ í‚¤ì›Œë“œì— íšŒìƒ‰ ë™ê·¸ë¼ë¯¸ ì¶”ê°€ (4ë‹¨ê³„ ì´ìƒ í•˜ë½)
                    if falling_keywords:
                        falling_keyword_list = [item['ê²€ìƒ‰ì–´'] for item in falling_keywords]
                        result_df['ê²€ìƒ‰ì–´'] = result_df['ê²€ìƒ‰ì–´'].apply(
                            lambda x: f"{x} ğŸ”´" if any(keyword in x for keyword in falling_keyword_list) else x
                        )
                    
                    # ì»¬ëŸ¼ëª… ë§¤í•‘
                    result_df = result_df.rename(columns={
                        'RANK': 'ìˆœìœ„'
                    })
                    
                    # SRCH_CNT_LY ì»¬ëŸ¼ ìœ ì§€
                    result_df = result_df[['ìˆœìœ„', 'ê²€ìƒ‰ì–´', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰', 'SRCH_CNT_TY', 'SRCH_CNT_LY']]
                    
                    return result_df.head(20)
                
                
                # í˜„ì¬ ì£¼ì°¨, ì „ì£¼ì°¨, ì „ë…„ë„ ë™ì¼ì£¼ì°¨ ìˆœìœ„ ê³„ì‚°
                current_week_ranking = calculate_weekly_ranking(current_week_data)
                prev_week_ranking = calculate_weekly_ranking(prev_week_data)
                prev_year_week_ranking = calculate_weekly_ranking(prev_year_week_data)
                
                # ë¸Œëœë“œë³„ ëŒ€ì‹œë³´ë“œ í‘œì‹œ
                brands = ['M', 'X', 'V', 'ST']
                brand_names = ['MLB', 'DX', 'DV', 'ST']
                
                for i, (brand_code, brand_name) in enumerate(zip(brands, brand_names)):
                    st.markdown(f"### ğŸ·ï¸ {brand_name} ë¸Œëœë“œ ê²€ìƒ‰ì–´ ìˆœìœ„")
                    
                    # ë¸Œëœë“œë³„ ë°ì´í„° í•„í„°ë§
                    current_brand_data = current_week_data[current_week_data['BRAND_CODE'] == brand_code] if not current_week_data.empty else pd.DataFrame()
                    prev_brand_data = prev_week_data[prev_week_data['BRAND_CODE'] == brand_code] if not prev_week_data.empty else pd.DataFrame()
                    prev_year_brand_data = prev_year_week_data[prev_year_week_data['BRAND_CODE'] == brand_code] if not prev_year_week_data.empty else pd.DataFrame()
                    
                    # ì „ì „ì£¼ ë°ì´í„° ê³„ì‚°
                    prev_prev_week_start = selected_week_start - pd.Timedelta(days=14)
                    prev_prev_week_end = selected_week_start - pd.Timedelta(days=8)
                    
                    # START_DT ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    if not search_df.empty and 'START_DT' in search_df.columns:
                        search_df_copy = search_df.copy()
                        search_df_copy['START_DT'] = pd.to_datetime(search_df_copy['START_DT'])
                        prev_prev_week_data = search_df_copy[
                            (search_df_copy['START_DT'] >= prev_prev_week_start) & 
                            (search_df_copy['START_DT'] <= prev_prev_week_end)
                        ]
                    else:
                        prev_prev_week_data = pd.DataFrame()
                    prev_prev_brand_data = prev_prev_week_data[prev_prev_week_data['BRAND_CODE'] == brand_code] if not prev_prev_week_data.empty else pd.DataFrame()
                    
                    # ë¸Œëœë“œë³„ ìˆœìœ„ ê³„ì‚° (ë¸Œëœë“œ ì½”ë“œ ì „ë‹¬)
                    current_brand_ranking = calculate_weekly_ranking(current_brand_data, brand_code)
                    prev_brand_ranking = calculate_weekly_ranking(prev_brand_data, brand_code)
                    prev_prev_brand_ranking = calculate_weekly_ranking(prev_prev_brand_data, brand_code)
                    prev_year_brand_ranking = calculate_weekly_ranking(prev_year_brand_data, brand_code)

                    # ì „ì²´(ìƒìœ„ 20 ì œí•œ ì—†ì´) ë­í¬ ì‚¬ì „ ìƒì„± í•¨ìˆ˜
                    def build_full_rank_dicts(week_df):
                        if week_df.empty:
                            return {}, {}
                        base = week_df.copy()
                        # í‚¤ì›Œë“œë³„ ì§‘ê³„
                        aggregated = base.groupby('SEARCH_KEYWORD', as_index=False)['SRCH_CNT_TY'].sum()
                        aggregated = aggregated.sort_values('SRCH_CNT_TY', ascending=False).reset_index(drop=True)
                        aggregated['ìˆœìœ„'] = aggregated.index + 1
                        keyword_to_rank = dict(zip(aggregated['SEARCH_KEYWORD'], aggregated['ìˆœìœ„']))
                        rank_to_keyword = dict(zip(aggregated['ìˆœìœ„'], aggregated['SEARCH_KEYWORD']))
                        return keyword_to_rank, rank_to_keyword

                    # ì „ì „ì£¼/ì „ì£¼ ì‚¬ì „: í‚¤ì›Œë“œâ†’ìˆœìœ„, ìˆœìœ„â†’í‚¤ì›Œë“œ ëª¨ë‘ ì¤€ë¹„ (ì „ì²´ ë­í¬)
                    prev_prev_kw_to_rank, prev_prev_rank_to_kw = build_full_rank_dicts(prev_prev_brand_data)
                    prev_kw_to_rank, prev_rank_to_kw = build_full_rank_dicts(prev_brand_data)
                    
                    # ìƒìŠ¹ í‚¤ì›Œë“œ ê³„ì‚° (í˜„ì¬ ì£¼ì°¨ ê¸°ì¤€) - ì „ì²´ ìˆœìœ„ ì‚¬ì „ ì‚¬ìš©
                    ranking_changes = []
                    if not current_brand_ranking.empty:
                        current_dict = dict(zip(current_brand_ranking['ê²€ìƒ‰ì–´'], current_brand_ranking['ìˆœìœ„']))
                        
                        for keyword in current_dict:
                            current_rank = current_dict[keyword]
                            # ì „ì£¼ ì „ì²´ ìˆœìœ„ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œì˜ ìˆœìœ„ ì°¾ê¸°
                            prev_rank = prev_kw_to_rank.get(keyword)
                            
                            if prev_rank is not None:
                                rank_change = prev_rank - current_rank  # ì–‘ìˆ˜ë©´ ìƒìŠ¹, ìŒìˆ˜ë©´ í•˜ë½
                                ranking_changes.append({
                                    'ê²€ìƒ‰ì–´': keyword,
                                    'í˜„ì¬ìˆœìœ„': current_rank,
                                    'ì „ì£¼ì°¨ìˆœìœ„': prev_rank,
                                    'ìˆœìœ„ë³€í™”': rank_change
                                })
                    
                    # 2ë‹¨ê³„ ì´ìƒ ìƒìŠ¹ í‚¤ì›Œë“œë§Œ í•„í„°ë§
                    rising_keywords = [item for item in ranking_changes if item['ìˆœìœ„ë³€í™”'] >= 2]
                    rising_keywords.sort(key=lambda x: x['ìˆœìœ„ë³€í™”'], reverse=True)
                    
                    # 4ë‹¨ê³„ ì´ìƒ í•˜ë½ í‚¤ì›Œë“œ í•„í„°ë§
                    falling_keywords = [item for item in ranking_changes if item['ìˆœìœ„ë³€í™”'] <= -4]
                    falling_keywords.sort(key=lambda x: x['ìˆœìœ„ë³€í™”'])
                    
                    # ìƒìŠ¹/í•˜ë½ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° í˜„ì¬ ì£¼ì°¨ í…Œì´ë¸”ì— ì•„ì´ì½˜ í‘œì‹œ
                    current_brand_ranking_with_icons = calculate_weekly_ranking(current_brand_data, brand_code, rising_keywords, falling_keywords)
                    
                    # í˜„ì¬ ì£¼ì°¨ í…Œì´ë¸”ì— ì „ì£¼ëŒ€ë¹„ ì¦ê° ì»¬ëŸ¼ ì¶”ê°€
                    current_brand_total = current_brand_data['SRCH_CNT_TY'].sum() if not current_brand_data.empty else 0
                    st.markdown(f"#### ğŸ“Š {selected_week_start.strftime('%Y/%m/%d')}~{selected_week_end.strftime('%m/%d')} ì£¼ì°¨ (ì´ë²ˆì£¼ì°¨)")
                    st.markdown(f"<small>ì „ì²´ ê²€ìƒ‰ëŸ‰: {current_brand_total:,} (ğŸŸ¢ğŸŸ¢ 4ë‹¨ê³„ ì´ìƒ ìƒìŠ¹ | ğŸŸ¢ 2-3ë‹¨ê³„ ìƒìŠ¹ | ğŸ”´ 4ë‹¨ê³„ ì´ìƒ í•˜ë½)</small>", unsafe_allow_html=True)
                    
                    if not current_brand_ranking_with_icons.empty:
                        # 3ê°œ ì£¼ì°¨ ë°ì´í„° ë§¤ì¹­ ë° ê²€ìƒ‰ì–´ ì»¬ëŸ¼ í™•ì¥
                        current_ranking_with_three_weeks = current_brand_ranking_with_icons.copy()
                        
                        # ì „ì „ì£¼, ì „ì£¼ ë°ì´í„°ì—ì„œ ê²€ìƒ‰ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        # build_full_rank_dicts ê²°ê³¼ ì‚¬ìš©
                        prev_prev_dict = prev_prev_rank_to_kw  # ìˆœìœ„ â†’ ê²€ìƒ‰ì–´
                        prev_dict = prev_rank_to_kw            # ìˆœìœ„ â†’ ê²€ìƒ‰ì–´
                        
                        def get_keyword_by_rank(rank_dict, target_rank):
                            """ìˆœìœ„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸° (ì–‘ë°©í–¥ dict ì§€ì›)"""
                            if not rank_dict:
                                return "-"
                            # case 1: {keyword -> rank}
                            sample_key = next(iter(rank_dict.keys()))
                            if isinstance(rank_dict[sample_key], (int, float)):
                                for keyword, rank in rank_dict.items():
                                    if rank == target_rank:
                                        return keyword
                                return "-"
                            # case 2: {rank -> keyword}
                            if target_rank in rank_dict:
                                return rank_dict.get(target_rank, "-")
                            return "-"
                        
                        def get_rank_by_keyword(rank_dict, keyword):
                            """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ìˆœìœ„ ì°¾ê¸° (ì–‘ë°©í–¥ dict ì§€ì›)"""
                            if not rank_dict:
                                return None
                            sample_key = next(iter(rank_dict.keys()))
                            # case 1: {keyword -> rank}
                            if isinstance(rank_dict[sample_key], (int, float)):
                                return rank_dict.get(keyword)
                            # case 2: {rank -> keyword}
                            for r, k in rank_dict.items():
                                if k == keyword:
                                    return r
                            return None
                        
                        def get_rank_display(rank_dict, keyword):
                            """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ìˆœìœ„ í‘œì‹œ. ì—†ìœ¼ë©´ X ë°˜í™˜ (ì–‘ë°©í–¥ dict ì§€ì›)"""
                            actual_rank = get_rank_by_keyword(rank_dict, keyword)
                            if actual_rank is None:
                                return "X"
                            return f"{actual_rank}ìœ„"
                        
                        def get_clean_keyword(keyword_with_icons):
                            """ì•„ì´ì½˜ì´ í¬í•¨ëœ í‚¤ì›Œë“œì—ì„œ ì›ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ"""
                            if 'ğŸŸ¢ğŸŸ¢' in keyword_with_icons:
                                return keyword_with_icons.replace('ğŸŸ¢ğŸŸ¢', '').strip()
                            elif 'ğŸŸ¢' in keyword_with_icons:
                                return keyword_with_icons.replace('ğŸŸ¢', '').strip()
                            elif 'ğŸ”´' in keyword_with_icons:
                                return keyword_with_icons.replace('ğŸ”´', '').strip()
                            else:
                                return keyword_with_icons
                        
                        # 3ê°œ ì£¼ì°¨ ê²€ìƒ‰ì–´ë¥¼ ê°ê° ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ìƒì„±
                        def create_prev_prev_keyword(row):
                            current_rank = row['ìˆœìœ„']
                            return get_keyword_by_rank(prev_prev_dict, current_rank)
                        
                        def create_prev_keyword(row):
                            current_rank = row['ìˆœìœ„']
                            return get_keyword_by_rank(prev_dict, current_rank)
                        
                        def create_current_keyword(row):
                            # ì›ë³¸ ê²€ìƒ‰ì–´ì— ì•„ì´ì½˜ì´ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
                            return row['ê²€ìƒ‰ì–´']
                        
                        # 3ê°œ ì£¼ì°¨ ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ìƒì„±
                        current_ranking_with_three_weeks['ê²€ìƒ‰ì–´(ì „ì „ì£¼)'] = current_ranking_with_three_weeks.apply(create_prev_prev_keyword, axis=1)
                        current_ranking_with_three_weeks['ê²€ìƒ‰ì–´(ì „ì£¼)'] = current_ranking_with_three_weeks.apply(create_prev_keyword, axis=1)
                        current_ranking_with_three_weeks['â­ ê²€ìƒ‰ì–´(ì´ë²ˆì£¼)'] = current_ranking_with_three_weeks.apply(create_current_keyword, axis=1)
                        
                        # 3ì£¼ê°„ ìˆœìœ„ ë³€ë™ ê³„ì‚°
                        def calculate_three_week_rank_change(row):
                            current_rank = row['ìˆœìœ„']
                            current_keyword = get_clean_keyword(row['ê²€ìƒ‰ì–´'])
                            
                            # ì „ì „ì£¼ ìˆœìœ„ í‘œì‹œ (í‚¤ì›Œë“œâ†’ìˆœìœ„ ì‚¬ì „ìœ¼ë¡œ ì •í™•í•œ ì‹¤ì œ ìˆœìœ„ í‘œì‹œ)
                            prev_prev_rank_display = get_rank_display(prev_prev_kw_to_rank, current_keyword)
                            
                            # ì „ì£¼ ìˆœìœ„ í‘œì‹œ
                            prev_rank_display = get_rank_display(prev_kw_to_rank, current_keyword)
                            
                            # í˜„ì¬ ì£¼ì°¨ ìˆœìœ„
                            current_rank_str = f"{current_rank}ìœ„"
                            
                            # ìˆœìœ„ ë³€ë™ ë¬¸ìì—´ ìƒì„±
                            return f"{prev_prev_rank_display}->{prev_rank_display}->{current_rank_str}"
                        
                        current_ranking_with_three_weeks['ìˆœìœ„ ë³€ë™'] = current_ranking_with_three_weeks.apply(calculate_three_week_rank_change, axis=1)
                        
                        # ì „ë…„ë™ì¼ì£¼ì°¨ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                        def calculate_yoy_change(row):
                            current_volume = row['SRCH_CNT_TY']
                            current_keyword = get_clean_keyword(row['ê²€ìƒ‰ì–´'])
                            
                            # í˜„ì¬ ë°ì´í„°ì—ì„œ SRCH_CNT_LY ì»¬ëŸ¼ ì‚¬ìš©
                            if 'SRCH_CNT_LY' in row and pd.notna(row['SRCH_CNT_LY']) and row['SRCH_CNT_LY'] > 0:
                                prev_year_volume = row['SRCH_CNT_LY']
                                yoy_change_pct = ((current_volume - prev_year_volume) / prev_year_volume) * 100
                                
                                # í™”ì‚´í‘œ ì•„ì´ì½˜ ì¶”ê°€
                                if yoy_change_pct > 0:
                                    arrow = "â–²"
                                elif yoy_change_pct < 0:
                                    arrow = "â–¼"
                                else:
                                    arrow = "â†’"
                                
                                return f"{current_volume:,.0f} ({arrow}{yoy_change_pct:+.1f}%)"
                            else:
                                return f"{current_volume:,.0f} (ì‹ ê·œ)"
                        
                        current_ranking_with_three_weeks['ê¸°ê°„ê²€ìƒ‰ëŸ‰'] = current_ranking_with_three_weeks.apply(calculate_yoy_change, axis=1)
                        
                        # í…Œì´ë¸”ê³¼ ê·¸ë˜í”„ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
                        col_table, col_chart = st.columns([1.3, 0.7])
                        
                        with col_table:
                            # í…Œì´ë¸” í‘œì‹œ (3ê°œ ì£¼ì°¨ ê²€ìƒ‰ì–´ ì»¬ëŸ¼ í¬í•¨)
                            # 20ê°œ í–‰ ëª¨ë‘ í‘œì‹œ (í™•ì‹¤íˆ 20ê°œë§Œ í‘œì‹œ)
                            display_df = current_ranking_with_three_weeks[['ìˆœìœ„', 'ê²€ìƒ‰ì–´(ì „ì „ì£¼)', 'ê²€ìƒ‰ì–´(ì „ì£¼)', 'â­ ê²€ìƒ‰ì–´(ì´ë²ˆì£¼)', 'ê¸°ê°„ê²€ìƒ‰ëŸ‰', 'ìˆœìœ„ ë³€ë™']].head(20)
                            
                            # Streamlitì˜ dataframeì€ height íŒŒë¼ë¯¸í„°ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì˜ì—­ ìƒì„±
                            # 20ê°œ í–‰ì„ ëª¨ë‘ ë³´ê¸° ìœ„í•´ ì¶©ë¶„í•œ ë†’ì´ ì„¤ì • (ê° í–‰ ì•½ 50px, 20í–‰ = 1000px + í—¤ë”)
                            st.dataframe(
                                display_df,
                                width='stretch',
                                hide_index=True,
                                height=1100  # 20ê°œ í–‰ ëª¨ë‘ í‘œì‹œ ê°€ëŠ¥í•œ ë†’ì´
                            )
                        
                        with col_chart:
                            # 3ì£¼ì¹˜ ì¼ë³„ ë§¤ì¶œ ê·¸ë˜í”„ ìƒì„±
                            
                            # ë§¤ì¶œ ë°ì´í„° ë¡œë“œ (Snowflake ë°ì´í„° ì‚¬ìš©)
                            sales_df = load_snowflake_sales_data()
                            
                            if not sales_df.empty and 'BRD_CD' in sales_df.columns:
                                # ë¸Œëœë“œë³„ ë§¤ì¶œ ë°ì´í„° í•„í„°ë§
                                brand_sales = sales_df[sales_df['BRD_CD'] == brand_code].copy()
                                
                                # í•„í„° ì˜ì—­ (ì•„ì´í…œê³¼ ê²€ìƒ‰ì¹´í…Œê³ ë¦¬ ë‚˜ë€íˆ ë°°ì¹˜)
                                if not brand_sales.empty:
                                    col_item, col_category = st.columns(2)
                                    
                                    with col_item:
                                        # ì‚¬ìš© ê°€ëŠ¥í•œ ì•„ì´í…œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ITEM ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©)
                                        available_items = ['ì „ì²´']
                                        if 'ITEM' in brand_sales.columns:
                                            items = brand_sales['ITEM'].dropna().unique().tolist()
                                            available_items.extend(sorted(items))
                                        elif 'item' in brand_sales.columns:
                                            items = brand_sales['item'].dropna().unique().tolist()
                                            available_items.extend(sorted(items))
                                        elif 'ITEM_CD' in brand_sales.columns:
                                            items = brand_sales['ITEM_CD'].dropna().unique().tolist()
                                            available_items.extend(sorted(items))
                                        elif 'ITEM_NM' in brand_sales.columns:
                                            items = brand_sales['ITEM_NM'].dropna().unique().tolist()
                                            available_items.extend(sorted(items))
                                        
                                        # ì•„ì´í…œ ë‹¤ì¤‘ì„ íƒ í•„í„°
                                        selected_items = st.multiselect(
                                            "ğŸ“¦ ì•„ì´í…œ",
                                            options=available_items,
                                            default=['ì „ì²´'] if 'ì „ì²´' in available_items else available_items[:1],
                                            help="ë¶„ì„í•  ì•„ì´í…œì„ ì„ íƒí•˜ì„¸ìš”"
                                        )
                                    
                                    with col_category:
                                        # ê²€ìƒ‰ì–´ ë°ì´í„°ì—ì„œ SUB_CATEGORY ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                                        if hasattr(st.session_state, 'search_data') and not st.session_state.search_data.empty:
                                            search_df = st.session_state.search_data
                                        else:
                                            search_df = load_snowflake_search_data()
                                        available_categories = ['ì „ì²´']
                                        
                                        if not search_df.empty and 'SUB_CATEGORY' in search_df.columns:
                                            # í˜„ì¬ ë¸Œëœë“œì˜ ì„œë¸Œì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
                                            brand_search_data = search_df[search_df['BRAND_CODE'] == brand_code]
                                            if not brand_search_data.empty:
                                                categories = brand_search_data['SUB_CATEGORY'].dropna().unique().tolist()
                                                available_categories.extend(sorted(categories))
                                        
                                        # ê²€ìƒ‰ì¹´í…Œê³ ë¦¬ ë‹¤ì¤‘ì„ íƒ í•„í„°
                                        selected_categories = st.multiselect(
                                            "ğŸ” ê²€ìƒ‰ì¹´í…Œê³ ë¦¬",
                                            options=available_categories,
                                            default=['ì „ì²´'] if 'ì „ì²´' in available_categories else available_categories[:1],
                                            help="ë¶„ì„í•  ê²€ìƒ‰ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                                        )
                                    
                                    # ì•„ì´í…œ í•„í„°ë§ ì ìš© (ITEM ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©)
                                    if selected_items and 'ì „ì²´' not in selected_items:
                                        if 'ITEM' in brand_sales.columns:
                                            brand_sales = brand_sales[brand_sales['ITEM'].isin(selected_items)]
                                        elif 'item' in brand_sales.columns:
                                            brand_sales = brand_sales[brand_sales['item'].isin(selected_items)]
                                        elif 'ITEM_CD' in brand_sales.columns:
                                            brand_sales = brand_sales[brand_sales['ITEM_CD'].isin(selected_items)]
                                        elif 'ITEM_NM' in brand_sales.columns:
                                            brand_sales = brand_sales[brand_sales['ITEM_NM'].isin(selected_items)]
                                    
                                    # ê²€ìƒ‰ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì ìš© ë° ê²€ìƒ‰ëŸ‰ í‘œì‹œ
                                    if selected_categories and 'ì „ì²´' not in selected_categories:
                                        # ê²€ìƒ‰ì–´ ë°ì´í„°ì—ì„œ ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œë“¤ ê°€ì ¸ì˜¤ê¸°
                                        if not search_df.empty and 'SUB_CATEGORY' in search_df.columns:
                                            brand_search_data = search_df[search_df['BRAND_CODE'] == brand_code]
                                            if not brand_search_data.empty:
                                                # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë“¤ í•„í„°ë§
                                                filtered_keywords = brand_search_data[
                                                    brand_search_data['SUB_CATEGORY'].isin(selected_categories)
                                                ]['SEARCH_KEYWORD'].unique().tolist()
                                                
                                                # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ê²€ìƒ‰ëŸ‰ ê³„ì‚°
                                                category_search_data = brand_search_data[
                                                    brand_search_data['SUB_CATEGORY'].isin(selected_categories)
                                                ]
                                                
                                                # ì´ë²ˆì£¼ ê²€ìƒ‰ëŸ‰ ê³„ì‚° (ë‚ ì§œ íƒ€ì… ë³€í™˜)
                                                category_search_data_copy = category_search_data.copy()
                                                category_search_data_copy['START_DT'] = pd.to_datetime(category_search_data_copy['START_DT'])
                                                
                                                current_week_search = category_search_data_copy[
                                                    (category_search_data_copy['START_DT'] >= pd.Timestamp(selected_week_start)) & 
                                                    (category_search_data_copy['START_DT'] <= pd.Timestamp(selected_week_end))
                                                ]
                                                
                                                if not current_week_search.empty:
                                                    current_week_search_volume = current_week_search['SRCH_CNT_TY'].sum()
                                                    
                                                    # ì „ë…„ ë™ì¼ì£¼ ê²€ìƒ‰ëŸ‰ ê³„ì‚° (SRCH_CNT_LY ì‚¬ìš©)
                                                    prev_year_week_search_volume = current_week_search['SRCH_CNT_LY'].sum()
                                                    
                                                    # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                                                    if prev_year_week_search_volume > 0:
                                                        search_yoy_change = ((current_week_search_volume - prev_year_week_search_volume) / prev_year_week_search_volume) * 100
                                                        search_yoy_display = f" (ì „ë…„ ëŒ€ë¹„ {search_yoy_change:+.1f}%)"
                                                    else:
                                                        search_yoy_display = " (ì „ë…„ ë°ì´í„° ì—†ìŒ)"
                                                    
                                                    # ê²€ìƒ‰ëŸ‰ì€ ë§¤ì¶œì•¡ê³¼ í•¨ê»˜ í‘œì‹œí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°
                                                else:
                                                    st.info(f"ì„ íƒëœ ê²€ìƒ‰ì¹´í…Œê³ ë¦¬ ({', '.join(selected_categories)})ì˜ ì´ë²ˆì£¼ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                
                                if not brand_sales.empty and 'DT' in brand_sales.columns:
                                    # ë‚ ì§œ ë³€í™˜
                                    brand_sales['DT'] = pd.to_datetime(brand_sales['DT'])
                                    
                                    # 3ì£¼ì¹˜ ë°ì´í„° í•„í„°ë§ (ì „ì „ì£¼, ì „ì£¼, ì´ë²ˆì£¼)
                                    three_weeks_start = prev_prev_week_start
                                    three_weeks_end = selected_week_end
                                    
                                    three_weeks_sales = brand_sales[
                                        (brand_sales['DT'] >= three_weeks_start) & 
                                        (brand_sales['DT'] <= three_weeks_end)
                                    ]
                                    
                                    if not three_weeks_sales.empty:
                                        import plotly.graph_objects as go
                                        
                                        # ì—¬ëŸ¬ ì•„ì´í…œ ì„ íƒ ì‹œ ê°ê° ê°œë³„ ê·¸ë˜í”„ í‘œì‹œ
                                        if selected_items and 'ì „ì²´' not in selected_items and len(selected_items) > 1:
                                            # ê° ì•„ì´í…œë³„ë¡œ ê°œë³„ ê·¸ë˜í”„ ìƒì„±
                                            for i, item in enumerate(selected_items):
                                                # í•´ë‹¹ ì•„ì´í…œì˜ ë°ì´í„°ë§Œ í•„í„°ë§
                                                item_data = three_weeks_sales.copy()
                                                if 'ITEM' in item_data.columns:
                                                    item_data = item_data[item_data['ITEM'] == item]
                                                elif 'item' in item_data.columns:
                                                    item_data = item_data[item_data['item'] == item]
                                                elif 'ITEM_CD' in item_data.columns:
                                                    item_data = item_data[item_data['ITEM_CD'] == item]
                                                elif 'ITEM_NM' in item_data.columns:
                                                    item_data = item_data[item_data['ITEM_NM'] == item]
                                                
                                                if not item_data.empty:
                                                    # ì¼ë³„ ë§¤ì¶œ ì§‘ê³„
                                                    daily_sales = item_data.groupby('DT').agg({
                                                        'SALE_AMT_TY': 'sum',
                                                        'SALE_AMT_LY': 'sum'
                                                    }).reset_index()
                                                    
                                                    daily_sales = daily_sales.sort_values('DT')
                                                    
                                                    # ê·¸ë˜í”„ ìƒì„±
                                                    fig = go.Figure()
                                                    
                                                    # ë‹¹í•´ ë§¤ì¶œì•¡ ë¼ì¸
                                                    fig.add_trace(go.Scatter(
                                                        x=daily_sales['DT'],
                                                        y=daily_sales['SALE_AMT_TY'],
                                                        mode='lines+markers',
                                                        name='ë‹¹í•´ ë§¤ì¶œì•¡',
                                                        line=dict(color='#1f77b4', width=2),
                                                        marker=dict(size=4)
                                                    ))
                                                    
                                                    # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
                                                    if 'SALE_AMT_LY' in daily_sales.columns and not daily_sales['SALE_AMT_LY'].isna().all():
                                                        fig.add_trace(go.Scatter(
                                                            x=daily_sales['DT'],
                                                            y=daily_sales['SALE_AMT_LY'],
                                                            mode='lines+markers',
                                                            name='ì „ë…„ ë§¤ì¶œì•¡',
                                                            line=dict(color='#ff7f0e', width=2, dash='dash'),
                                                            marker=dict(size=4)
                                                        ))
                                                    
                                                    # ì¼ë³„ ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ ì¶”ê°€
                                                    # í•´ë‹¹ ì•„ì´í…œì˜ ê²€ìƒ‰ëŸ‰ ë°ì´í„° í•„í„°ë§
                                                    item_search_data = brand_search_data.copy()
                                                    if 'ITEM' in item_search_data.columns:
                                                        item_search_data = item_search_data[item_search_data['ITEM'] == item]
                                                    elif 'item' in item_search_data.columns:
                                                        item_search_data = item_search_data[item_search_data['item'] == item]
                                                    elif 'ITEM_CD' in item_search_data.columns:
                                                        item_search_data = item_search_data[item_search_data['ITEM_CD'] == item]
                                                    elif 'ITEM_NM' in item_search_data.columns:
                                                        item_search_data = item_search_data[item_search_data['ITEM_NM'] == item]
                                                    
                                                    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                                                    if selected_categories and 'ì „ì²´' not in selected_categories:
                                                        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
                                                        category_search_data = item_search_data[
                                                            item_search_data['SUB_CATEGORY'].isin(selected_categories)
                                                        ]
                                                        search_label = f'ê²€ìƒ‰ëŸ‰ ({",".join(selected_categories)})'
                                                    else:
                                                        # ì „ì²´ ê²€ìƒ‰ëŸ‰
                                                        category_search_data = item_search_data
                                                        search_label = 'ì „ì²´ ê²€ìƒ‰ëŸ‰'
                                                    
                                                    if not category_search_data.empty:
                                                        # ì¼ë³„ ê²€ìƒ‰ëŸ‰ ì§‘ê³„
                                                        daily_search = category_search_data.groupby('START_DT').agg({
                                                            'SRCH_CNT_TY': 'sum'
                                                        }).reset_index()
                                                        
                                                        # ë§¤ì¶œ ê·¸ë˜í”„ì™€ ê°™ì€ ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§
                                                        daily_search = daily_search[
                                                            (pd.to_datetime(daily_search['START_DT']) >= pd.Timestamp(three_weeks_start)) &
                                                            (pd.to_datetime(daily_search['START_DT']) <= pd.Timestamp(three_weeks_end))
                                                        ]
                                                        
                                                        if not daily_search.empty:
                                                            # ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ ì¶”ê°€
                                                            fig.add_trace(go.Bar(
                                                                x=pd.to_datetime(daily_search['START_DT']),
                                                                y=daily_search['SRCH_CNT_TY'],
                                                                name=search_label,
                                                                marker_color='rgba(128, 128, 128, 0.3)',
                                                                opacity=0.6,
                                                                yaxis='y2'
                                                            ))
                                                    
                                                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                                    fig.update_layout(
                                                        title=f"{brand_name} ì¼ë³„ ë§¤ì¶œ/ê²€ìƒ‰ëŸ‰",
                                                        xaxis_title="ë‚ ì§œ",
                                                        yaxis_title="ë§¤ì¶œì•¡ (ì›)",
                                                        xaxis=dict(
                                                            type='date',
                                                            showgrid=True,
                                                            gridcolor='lightgray'
                                                        ),
                                                        yaxis=dict(
                                                            showgrid=True,
                                                            gridcolor='lightgray',
                                                            tickformat=',.0f'
                                                        ),
                                                        yaxis2=dict(
                                                            title="ê²€ìƒ‰ëŸ‰ (íšŒ)",
                                                            overlaying="y",
                                                            side="right",
                                                            showgrid=False,
                                                            tickformat=',.0f'
                                                        ),
                                                        hovermode='x unified',
                                                        legend=dict(
                                                            orientation='h',
                                                            x=1,
                                                            y=1.1,
                                                            xanchor='right',
                                                            yanchor='bottom',
                                                            bgcolor='rgba(255,255,255,0.8)',
                                                            bordercolor='rgba(255,255,255,0)',
                                                            borderwidth=0
                                                        ),
                                                        height=300,
                                                        margin=dict(t=100),
                                                        template='plotly_white'
                                                    )
                                                    
                                                    # í˜¸ë²„ í…œí”Œë¦¿ ì„¤ì •
                                                    fig.update_traces(
                                                        hovertemplate='<b>%{fullData.name}</b><br>' +
                                                                     'ë‚ ì§œ: %{x}<br>' +
                                                                     'ë§¤ì¶œì•¡: %{y:,.0f}ì›<br>' +
                                                                     '<extra></extra>'
                                                    )
                                                    
                                                    # ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ í˜¸ë²„ í…œí”Œë¦¿ ë³„ë„ ì„¤ì •
                                                    fig.update_traces(
                                                        selector=dict(type='bar'),
                                                        hovertemplate='<b>%{fullData.name}</b><br>' +
                                                                     'ë‚ ì§œ: %{x}<br>' +
                                                                     'ê²€ìƒ‰ëŸ‰: %{y:,.0f}íšŒ<br>' +
                                                                     '<extra></extra>'
                                                    )
                                                    
                                                    st.plotly_chart(fig, use_container_width=True)
                                                    
                                                    # ê°œë³„ ì•„ì´í…œ ë§¤ì¶œ í†µê³„
                                                    total_current = daily_sales['SALE_AMT_TY'].sum()
                                                    
                                                    # ì´ë²ˆì£¼(10/20~10/26) ë§¤ì¶œì•¡ ê³„ì‚°
                                                    current_week_start = selected_week_start
                                                    current_week_end = selected_week_end
                                                    current_week_sales = item_data[
                                                        (item_data['DT'] >= current_week_start) & 
                                                        (item_data['DT'] <= current_week_end)
                                                    ]
                                                    
                                                    if not current_week_sales.empty:
                                                        current_week_total = current_week_sales['SALE_AMT_TY'].sum()
                                                        current_week_prev_year = current_week_sales['SALE_AMT_LY'].sum() if 'SALE_AMT_LY' in current_week_sales.columns else 0
                                                        
                                                        # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                                                        if current_week_prev_year > 0:
                                                            yoy_change = ((current_week_total - current_week_prev_year) / current_week_prev_year) * 100
                                                            yoy_display = f" (ì „ë…„ ëŒ€ë¹„ {yoy_change:+.1f}%)"
                                                        else:
                                                            yoy_display = " (ì „ë…„ ë°ì´í„° ì—†ìŒ)"
                                                        
                                                    # ì´ë²ˆì£¼ ë§¤ì¶œì•¡ê³¼ ê²€ìƒ‰ëŸ‰ì„ ë‚˜ë€íˆ í‘œì‹œ
                                                    col_sales, col_search = st.columns(2)
                                                    
                                                    with col_sales:
                                                        # ë‚ ì§œ ë²”ìœ„ í¬ë§·íŒ…
                                                        date_range = f"{selected_week_start.strftime('%m/%d')}~{selected_week_end.strftime('%m/%d')}"
                                                        st.metric(
                                                            label=f"**{date_range} ë§¤ì¶œì•¡ ({item})**",
                                                            value=f"{current_week_total:,.0f}ì›{yoy_display}"
                                                        )
                                                    
                                                    with col_search:
                                                        if selected_categories and 'ì „ì²´' not in selected_categories:
                                                            # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ëŸ‰ í‘œì‹œ
                                                            st.metric(
                                                                label=f"**{date_range} ê²€ìƒ‰ëŸ‰ ({','.join(selected_categories)})**",
                                                                value=f"{current_week_search_volume:,.0f}íšŒ{search_yoy_display}"
                                                            )
                                                        else:
                                                            # ì „ì²´ ê²€ìƒ‰ëŸ‰ ê³„ì‚°
                                                            total_current_week_search = brand_search_data[
                                                                (pd.to_datetime(brand_search_data['START_DT']) >= pd.Timestamp(current_week_start)) &
                                                                (pd.to_datetime(brand_search_data['START_DT']) <= pd.Timestamp(current_week_end))
                                                            ]
                                                            total_current_week_search_volume = total_current_week_search['SRCH_CNT_TY'].sum() if not total_current_week_search.empty else 0
                                                            
                                                            # ì „ë…„ ë™ì¼ì£¼ ì „ì²´ ê²€ìƒ‰ëŸ‰ ê³„ì‚° (SRCH_CNT_LY ì‚¬ìš©)
                                                            total_prev_year_week_search_volume = brand_search_data['SRCH_CNT_LY'].sum() if not brand_search_data.empty else 0
                                                            
                                                            # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                                                            total_search_yoy_display = ""
                                                            if total_prev_year_week_search_volume > 0:
                                                                total_search_yoy_change = ((total_current_week_search_volume - total_prev_year_week_search_volume) / total_prev_year_week_search_volume) * 100
                                                                total_search_yoy_display = f" (ì „ë…„ ëŒ€ë¹„ {total_search_yoy_change:+.1f}%)"
                                                            elif total_current_week_search_volume > 0:
                                                                total_search_yoy_display = " (ì‹ ê·œ)"
                                                            else:
                                                                total_search_yoy_display = " (-)"
                                                            
                                                            st.metric(
                                                                label=f"**{date_range} ì „ì²´ ê²€ìƒ‰ëŸ‰**",
                                                                value=f"{total_current_week_search_volume:,.0f}íšŒ{total_search_yoy_display}"
                                                            )
                                                    
                                                    # ì•„ì´í…œ ê°„ êµ¬ë¶„ì„ 
                                                    if i < len(selected_items) - 1:
                                                        st.markdown("---")
                                        else:
                                            # ë‹¨ì¼ ì•„ì´í…œ ë˜ëŠ” ì „ì²´ ì„ íƒ ì‹œ ê¸°ì¡´ ë¡œì§
                                            # ì¼ë³„ ë§¤ì¶œ ì§‘ê³„
                                            daily_sales = three_weeks_sales.groupby('DT').agg({
                                                'SALE_AMT_TY': 'sum',
                                                'SALE_AMT_LY': 'sum'
                                            }).reset_index()
                                            
                                            daily_sales = daily_sales.sort_values('DT')
                                            
                                            # ê·¸ë˜í”„ ìƒì„±
                                            fig = go.Figure()
                                            
                                            # ë‹¹í•´ ë§¤ì¶œì•¡ ë¼ì¸
                                            fig.add_trace(go.Scatter(
                                                x=daily_sales['DT'],
                                                y=daily_sales['SALE_AMT_TY'],
                                                mode='lines+markers',
                                                name='ë‹¹í•´ ë§¤ì¶œì•¡',
                                                line=dict(color='#1f77b4', width=2),
                                                marker=dict(size=4)
                                            ))
                                            
                                            # ì „ë…„ ë§¤ì¶œì•¡ ë¼ì¸ (YoY ë¹„êµìš©)
                                            if 'SALE_AMT_LY' in daily_sales.columns and not daily_sales['SALE_AMT_LY'].isna().all():
                                                fig.add_trace(go.Scatter(
                                                    x=daily_sales['DT'],
                                                    y=daily_sales['SALE_AMT_LY'],
                                                    mode='lines+markers',
                                                    name='ì „ë…„ ë§¤ì¶œì•¡',
                                                    line=dict(color='#ff7f0e', width=2, dash='dash'),
                                                    marker=dict(size=4)
                                                ))
                                            
                                            # ì¼ë³„ ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ ì¶”ê°€
                                            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                                            if selected_categories and 'ì „ì²´' not in selected_categories:
                                                # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
                                                category_search_data = brand_search_data[
                                                    brand_search_data['SUB_CATEGORY'].isin(selected_categories)
                                                ]
                                                search_label = f'ê²€ìƒ‰ëŸ‰ ({",".join(selected_categories)})'
                                            else:
                                                # ì „ì²´ ê²€ìƒ‰ëŸ‰
                                                category_search_data = brand_search_data
                                                search_label = 'ì „ì²´ ê²€ìƒ‰ëŸ‰'
                                            
                                            if not category_search_data.empty:
                                                # ì¼ë³„ ê²€ìƒ‰ëŸ‰ ì§‘ê³„
                                                daily_search = category_search_data.groupby('START_DT').agg({
                                                    'SRCH_CNT_TY': 'sum'
                                                }).reset_index()
                                                
                                                # ë§¤ì¶œ ê·¸ë˜í”„ì™€ ê°™ì€ ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§
                                                daily_search = daily_search[
                                                    (pd.to_datetime(daily_search['START_DT']) >= pd.Timestamp(three_weeks_start)) &
                                                    (pd.to_datetime(daily_search['START_DT']) <= pd.Timestamp(three_weeks_end))
                                                ]
                                                
                                                if not daily_search.empty:
                                                    # ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ ì¶”ê°€
                                                    fig.add_trace(go.Bar(
                                                        x=pd.to_datetime(daily_search['START_DT']),
                                                        y=daily_search['SRCH_CNT_TY'],
                                                        name=search_label,
                                                        marker_color='rgba(128, 128, 128, 0.3)',
                                                        opacity=0.6,
                                                        yaxis='y2'
                                                    ))
                                            
                                            # ê·¸ë˜í”„ ì œëª© ì„¤ì •
                                            title = f"{brand_name} ì¼ë³„ ë§¤ì¶œ/ê²€ìƒ‰ëŸ‰"
                                            
                                            # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                            fig.update_layout(
                                                title=title,
                                                xaxis_title="ë‚ ì§œ",
                                                yaxis_title="ë§¤ì¶œì•¡ (ì›)",
                                                xaxis=dict(
                                                    type='date',
                                                    showgrid=True,
                                                    gridcolor='lightgray'
                                                ),
                                                yaxis=dict(
                                                    showgrid=True,
                                                    gridcolor='lightgray',
                                                    tickformat=',.0f'
                                                ),
                                                yaxis2=dict(
                                                    title="ê²€ìƒ‰ëŸ‰ (íšŒ)",
                                                    overlaying="y",
                                                    side="right",
                                                    showgrid=False,
                                                    tickformat=',.0f'
                                                ),
                                                hovermode='x unified',
                                                legend=dict(
                                                    orientation='h',
                                                    x=1,
                                                    y=1.1,
                                                    xanchor='right',
                                                    yanchor='bottom',
                                                    bgcolor='rgba(255,255,255,0.8)',
                                                    bordercolor='rgba(255,255,255,0)',
                                                    borderwidth=0
                                                ),
                                                height=400,
                                                margin=dict(t=100),
                                                template='plotly_white'
                                            )
                                            
                                            # í˜¸ë²„ í…œí”Œë¦¿ ì„¤ì •
                                            fig.update_traces(
                                                hovertemplate='<b>%{fullData.name}</b><br>' +
                                                             'ë‚ ì§œ: %{x}<br>' +
                                                             'ë§¤ì¶œì•¡: %{y:,.0f}ì›<br>' +
                                                             '<extra></extra>'
                                            )
                                            
                                            # ê²€ìƒ‰ëŸ‰ ë§‰ëŒ€ê·¸ë˜í”„ í˜¸ë²„ í…œí”Œë¦¿ ë³„ë„ ì„¤ì •
                                            fig.update_traces(
                                                selector=dict(type='bar'),
                                                hovertemplate='<b>%{fullData.name}</b><br>' +
                                                             'ë‚ ì§œ: %{x}<br>' +
                                                             'ê²€ìƒ‰ëŸ‰: %{y:,.0f}íšŒ<br>' +
                                                             '<extra></extra>'
                                            )
                                            
                                            st.plotly_chart(fig, use_container_width=True)
                                            
                                            # ë§¤ì¶œ í†µê³„ ìš”ì•½ (ì„ íƒëœ ì•„ì´í…œ ë°˜ì˜)
                                            total_current = daily_sales['SALE_AMT_TY'].sum()
                                            
                                            # ì´ë²ˆì£¼(10/20~10/26) ë§¤ì¶œì•¡ ê³„ì‚°
                                            current_week_start = selected_week_start
                                            current_week_end = selected_week_end
                                            current_week_sales = three_weeks_sales[
                                                (three_weeks_sales['DT'] >= current_week_start) & 
                                                (three_weeks_sales['DT'] <= current_week_end)
                                            ]
                                            
                                            if not current_week_sales.empty:
                                                current_week_total = current_week_sales['SALE_AMT_TY'].sum()
                                                current_week_prev_year = current_week_sales['SALE_AMT_LY'].sum() if 'SALE_AMT_LY' in current_week_sales.columns else 0
                                                
                                                # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                                                if current_week_prev_year > 0:
                                                    yoy_change = ((current_week_total - current_week_prev_year) / current_week_prev_year) * 100
                                                    yoy_display = f" (ì „ë…„ ëŒ€ë¹„ {yoy_change:+.1f}%)"
                                                else:
                                                    yoy_display = " (ì „ë…„ ë°ì´í„° ì—†ìŒ)"
                                                
                                                # ì´ë²ˆì£¼ ë§¤ì¶œì•¡ê³¼ ê²€ìƒ‰ëŸ‰ì„ ë‚˜ë€íˆ í‘œì‹œ
                                                col_sales, col_search = st.columns(2)
                                                
                                                with col_sales:
                                                    # ë‚ ì§œ ë²”ìœ„ í¬ë§·íŒ…
                                                    date_range = f"{selected_week_start.strftime('%m/%d')}~{selected_week_end.strftime('%m/%d')}"
                                                    
                                                    # ì´ë²ˆì£¼ ë§¤ì¶œì•¡ í‘œì‹œ
                                                    if selected_items and 'ì „ì²´' not in selected_items:
                                                        if len(selected_items) == 1:
                                                            label = f"{date_range} ë§¤ì¶œì•¡ ({selected_items[0]})"
                                                        else:
                                                            label = f"{date_range} ë§¤ì¶œì•¡ (ì„ íƒ ì•„ì´í…œ)"
                                                    else:
                                                        label = f"{date_range} ë§¤ì¶œì•¡"
                                                    
                                                    st.metric(
                                                        label=f"**{label}**",
                                                        value=f"{current_week_total:,.0f}ì›{yoy_display}"
                                                    )
                                                
                                                with col_search:
                                                    if selected_categories and 'ì „ì²´' not in selected_categories:
                                                        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ëŸ‰ í‘œì‹œ
                                                        st.metric(
                                                            label=f"**{date_range} ê²€ìƒ‰ëŸ‰ ({','.join(selected_categories)})**",
                                                            value=f"{current_week_search_volume:,.0f}íšŒ{search_yoy_display}"
                                                        )
                                                    else:
                                                        # ì „ì²´ ê²€ìƒ‰ëŸ‰ ê³„ì‚°
                                                        total_current_week_search = brand_search_data[
                                                            (pd.to_datetime(brand_search_data['START_DT']) >= pd.Timestamp(selected_week_start)) &
                                                            (pd.to_datetime(brand_search_data['START_DT']) <= pd.Timestamp(selected_week_end))
                                                        ]
                                                        total_current_week_search_volume = total_current_week_search['SRCH_CNT_TY'].sum() if not total_current_week_search.empty else 0
                                                        
                                                        # ì „ë…„ ë™ì¼ì£¼ ì „ì²´ ê²€ìƒ‰ëŸ‰ ê³„ì‚° (SRCH_CNT_LY ì‚¬ìš©)
                                                        total_prev_year_week_search_volume = brand_search_data['SRCH_CNT_LY'].sum() if not brand_search_data.empty else 0
                                                        
                                                        # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°
                                                        total_search_yoy_display = ""
                                                        if total_prev_year_week_search_volume > 0:
                                                            total_search_yoy_change = ((total_current_week_search_volume - total_prev_year_week_search_volume) / total_prev_year_week_search_volume) * 100
                                                            total_search_yoy_display = f" (ì „ë…„ ëŒ€ë¹„ {total_search_yoy_change:+.1f}%)"
                                                        elif total_current_week_search_volume > 0:
                                                            total_search_yoy_display = " (ì‹ ê·œ)"
                                                        else:
                                                            total_search_yoy_display = " (-)"
                                                        
                                                        st.metric(
                                                            label=f"**{date_range} ì „ì²´ ê²€ìƒ‰ëŸ‰**",
                                                            value=f"{total_current_week_search_volume:,.0f}íšŒ{total_search_yoy_display}"
                                                        )
                                    else:
                                        st.info("í•´ë‹¹ ê¸°ê°„ì˜ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    st.info("ë§¤ì¶œ ë°ì´í„°ì— ë‚ ì§œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.info("ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("í•´ë‹¹ ì£¼ì°¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ì „ì£¼ì°¨ ëŒ€ë¹„ ë­í‚¹ ìƒìŠ¹ í‚¤ì›Œë“œ ë¶„ì„
                    if not current_brand_ranking.empty and not prev_brand_ranking.empty:
                        st.markdown("#### ğŸ” ì „ì£¼ì°¨ ëŒ€ë¹„ ë­í‚¹ ìƒìŠ¹ í‚¤ì›Œë“œ ë¶„ì„")
                        
                        # í˜„ì¬ ì£¼ì°¨ì™€ ì „ì£¼ì°¨ ë°ì´í„°ë¥¼ í‚¤ì›Œë“œë¡œ ë§¤ì¹­
                        current_dict = dict(zip(current_brand_ranking['ê²€ìƒ‰ì–´'], current_brand_ranking['ìˆœìœ„']))
                        prev_dict = dict(zip(prev_brand_ranking['ê²€ìƒ‰ì–´'], prev_brand_ranking['ìˆœìœ„']))
                        
                        ranking_changes = []
                        for keyword in current_dict.keys():
                            if keyword in prev_dict:
                                current_rank = current_dict[keyword]
                                prev_rank = prev_dict[keyword]
                                rank_change = prev_rank - current_rank  # ì–‘ìˆ˜ë©´ ìƒìŠ¹, ìŒìˆ˜ë©´ í•˜ë½
                                ranking_changes.append({
                                    'ê²€ìƒ‰ì–´': keyword,
                                    'í˜„ì¬ìˆœìœ„': current_rank,
                                    'ì „ì£¼ì°¨ìˆœìœ„': prev_rank,
                                    'ìˆœìœ„ë³€í™”': rank_change,
                                    'í˜„ì¬ê²€ìƒ‰ëŸ‰': current_brand_ranking[current_brand_ranking['ê²€ìƒ‰ì–´'] == keyword]['SRCH_CNT_TY'].iloc[0] if not current_brand_ranking[current_brand_ranking['ê²€ìƒ‰ì–´'] == keyword].empty else 0
                                })
                        
                        # ìˆœìœ„ ìƒìŠ¹ í‚¤ì›Œë“œë§Œ í•„í„°ë§ (2ë‹¨ê³„ ì´ìƒ ìƒìŠ¹, ìƒìŠ¹í­ì´ í° ìˆœìœ¼ë¡œ ì •ë ¬)
                        rising_keywords = [item for item in ranking_changes if item['ìˆœìœ„ë³€í™”'] >= 2]
                        rising_keywords.sort(key=lambda x: x['ìˆœìœ„ë³€í™”'], reverse=True)
                        
                        if rising_keywords:
                            # ìƒìœ„ 5ê°œ ìƒìŠ¹ í‚¤ì›Œë“œ í‘œì‹œ
                            st.markdown("**ğŸ“ˆ ì£¼ìš” ìƒìŠ¹ í‚¤ì›Œë“œ (ìƒìœ„ 5ê°œ)**")
                            for idx, item in enumerate(rising_keywords[:5], 1):
                                st.markdown(f"**{idx}.** {item['ê²€ìƒ‰ì–´']} - {item['ì „ì£¼ì°¨ìˆœìœ„']}ìœ„ â†’ {item['í˜„ì¬ìˆœìœ„']}ìœ„ (â–²{item['ìˆœìœ„ë³€í™”']}ë‹¨ê³„ ìƒìŠ¹)")
                            
                        else:
                            st.info("ì „ì£¼ì°¨ ëŒ€ë¹„ ìˆœìœ„ ìƒìŠ¹ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ë¸Œëœë“œ ê°„ êµ¬ë¶„ì„ 
                    if i < len(brands) - 1:
                        st.markdown("---")
    else:
        st.info("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬' ë©”ë‰´ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# =============================================================================
# ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ë§ˆì¼€íŒ… ë¶„ì„ ì‹œìŠ¤í…œ",
        page_icon="ğŸ‘¥",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.markdown("## ğŸ“Š ë§ˆì¼€íŒ… ë¶„ì„ ì‹œìŠ¤í…œ")
    
    # ë©”ë‰´ ì„¹ì…˜
    st.sidebar.markdown("### â˜… ë©”ë‰´")
    
    # ë©”ë‰´ ë²„íŠ¼ë“¤
    if st.sidebar.button("ğŸ‘¥ F&F CREW LIST", use_container_width=True):
        st.session_state.selected_menu = "ğŸ‘¥ F&F CREW LIST"
    
    
    if st.sidebar.button("ğŸ“ˆ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬", use_container_width=True):
        st.session_state.selected_menu = "ğŸ“ˆ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬"
    
    if st.sidebar.button("ğŸ“Š ëŒ€ì‹œë³´ë“œ", use_container_width=True):
        st.session_state.selected_menu = "ğŸ“Š ëŒ€ì‹œë³´ë“œ"
    
    if st.sidebar.button("ğŸ’° ë§¤ì¶œëŒ€ì‹œë³´ë“œ", use_container_width=True):
        st.session_state.selected_menu = "ğŸ’° ë§¤ì¶œëŒ€ì‹œë³´ë“œ"
    
    if st.sidebar.button("ğŸ” ê²€ìƒ‰ëŸ‰ë¶„ì„", use_container_width=True):
        st.session_state.selected_menu = "ğŸ” ê²€ìƒ‰ëŸ‰ë¶„ì„"
    
    # ë°ì´í„° ë¬¸ì˜ ê¸°ëŠ¥ (ì‚¬ì´ë“œë°” í•˜ë‹¨)
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ’¬ ë°ì´í„° ë¬¸ì˜")
    question = st.sidebar.text_area("ë°ì´í„°ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”:", height=100)
    if st.sidebar.button("ğŸ” ë¶„ì„"):
        if question:
            execution_df = load_execution_data()
            influencer_df = load_influencer_data()
            answer = analyze_data_question(question, execution_df, influencer_df)
            st.sidebar.success("ë¶„ì„ ì™„ë£Œ!")
            st.sidebar.markdown(f"**ë‹µë³€:** {answer}")
    
    # ê¸°ë³¸ ë©”ë‰´ ì„¤ì •
    if 'selected_menu' not in st.session_state:
        st.session_state.selected_menu = "ğŸ‘¥ F&F CREW LIST"
    
    selected_menu = st.session_state.selected_menu
    
    # ë°ì´í„° ë¡œë“œ
    df = load_influencer_data()
    
    # ë©”ë‰´ë³„ ë Œë”ë§
    if selected_menu == "ğŸ‘¥ F&F CREW LIST":
        render_influencer_tab(df)
    elif selected_menu == "ğŸ“ˆ ë°ì´í„° ì—…ë¡œë“œ ê´€ë¦¬":
        render_execution_data_management_tab()
    elif selected_menu == "ğŸ“Š ëŒ€ì‹œë³´ë“œ":
        render_dashboard_tab()
    elif selected_menu == "ğŸ’° ë§¤ì¶œëŒ€ì‹œë³´ë“œ":
        render_sales_dashboard_tab()
    elif selected_menu == "ğŸ” ê²€ìƒ‰ëŸ‰ë¶„ì„":
        render_search_analysis_tab()

def get_season_options(df):
    """ì‹œì¦Œ ì˜µì…˜ ìƒì„±"""
    return ["25FW", "26SS"]

def filter_by_season(influencer_summary, df, months):
    """ì‹œì¦Œë³„ í•„í„°ë§"""
    # ì›”ë³„ ë°°ì • ë°ì´í„°ì—ì„œ í•´ë‹¹ ì›”ë“¤ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
    return influencer_summary

def add_brand_details(influencer_summary, df, selected_brand_filter):
    """ë¸Œëœë“œë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€"""
    if selected_brand_filter == "ì „ì²´":
        # ì „ì²´ ë¸Œëœë“œ ì •ë³´ ì¶”ê°€
        for brand in BRANDS:
            qty_col = f"{brand.lower()}_qty"
            if qty_col in df.columns:
                influencer_summary[f"{brand}_ê³„ì•½ìˆ˜"] = df[qty_col]
    else:
        # ì„ íƒëœ ë¸Œëœë“œ ì •ë³´ë§Œ ì¶”ê°€
        qty_col = f"{selected_brand_filter.lower()}_qty"
        if qty_col in df.columns:
            influencer_summary[f"{selected_brand_filter}_ê³„ì•½ìˆ˜"] = df[qty_col]


def reorder_columns(influencer_summary):
    """ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •: ë¸Œëœë“œë³„ ê³„ì•½ìˆ˜ ì»¬ëŸ¼ë“¤ì„ ì›”ë³„ ì»¬ëŸ¼ë“¤ ì•ìœ¼ë¡œ ì´ë™"""
    # ê¸°ë³¸ ì»¬ëŸ¼ë“¤ (ìˆœì„œ ìœ ì§€)
    basic_columns = ["contract_id", "sns_id", "name", "follower", "unit_fee", "sec_usage", "sec_period", "ì „ì²´_ê³„ì•½ìˆ˜"]
    
    # ë¸Œëœë“œë³„ ê³„ì•½ìˆ˜ ì»¬ëŸ¼ë“¤
    brand_contract_columns = [col for col in influencer_summary.columns if col.endswith("_ê³„ì•½ìˆ˜")]
    
    
    # ì›”ë³„ ì»¬ëŸ¼ë“¤ (1ì›”~12ì›”)
    monthly_columns = [col for col in influencer_summary.columns if col in ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"]]
    
    # ê¸°íƒ€ ì»¬ëŸ¼ë“¤
    other_columns = [col for col in influencer_summary.columns if col not in basic_columns + brand_contract_columns + monthly_columns]
    
    # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ (ì¤‘ë³µ ì œê±°)
    final_columns = []
    for col in basic_columns + brand_contract_columns + monthly_columns + other_columns:
        if col in influencer_summary.columns and col not in final_columns:
            final_columns.append(col)
    
    return influencer_summary[final_columns]

def add_monthly_columns(influencer_summary, df, selected_brand_filter, selected_season_filter=None):
    """ì›”ë³„ ì»¬ëŸ¼ ì¶”ê°€ - CREW ë°°ì •ê´€ë¦¬ì˜ ë°°ì • ë°ì´í„° ë°˜ì˜"""
    # ì‹œì¦Œì— ë”°ë¥¸ ì›”ë³„ ì»¬ëŸ¼ ì„¤ì •
    if selected_season_filter == "25FW":
        months = ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"]
    elif selected_season_filter == "26SS":
        months = ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"]
    else:
        # ê¸°ë³¸ê°’: 25FW ì‹œì¦Œ
        months = ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"]
    
    for month in months:
        influencer_summary[month] = ""
    
    # CREW ë°°ì •ê´€ë¦¬ì˜ ë°°ì • ë°ì´í„° ë¡œë“œ ë° ë°˜ì˜
    try:
        if os.path.exists(ASSIGNMENT_FILE):
            assignment_data = pd.read_csv(ASSIGNMENT_FILE, encoding="utf-8")
            if not assignment_data.empty and 'contract_id' in assignment_data.columns:
                # ë°°ì • ë°ì´í„°ë¥¼ ì¸í”Œë£¨ì–¸ì„œë³„, ì›”ë³„ë¡œ ê·¸ë£¹í™”
                assignment_pivot = assignment_data.groupby(['contract_id', 'ë°°ì •ì›”'])['ë¸Œëœë“œ'].apply(lambda x: ', '.join(sorted(x.unique(), key=lambda b: ["MLB", "DX", "DV", "ST"].index(b) if b in ["MLB", "DX", "DV", "ST"] else 999))).reset_index()
                
                # ì¸í”Œë£¨ì–¸ì„œë³„ë¡œ ì›”ë³„ ë°°ì • ì •ë³´ ë§¤í•‘
                for _, row in influencer_summary.iterrows():
                    influencer_id = row["contract_id"]
                    influencer_assignments = assignment_pivot[assignment_pivot['contract_id'] == influencer_id]
                    
                    for _, assignment in influencer_assignments.iterrows():
                        month = assignment['ë°°ì •ì›”']
                        brands = assignment['ë¸Œëœë“œ']
                        if month in months:
                            influencer_summary.loc[influencer_summary['contract_id'] == influencer_id, month] = brands
    except Exception as e:
        print(f"ì›”ë³„ ì»¬ëŸ¼ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")

def render_influencer_table(influencer_summary, selected_brand_filter, selected_season_filter, influencer_count=None):
    """ì¸í”Œë£¨ì–¸ì„œ í…Œì´ë¸” ë Œë”ë§"""
    if influencer_count:
        st.markdown(f"**ì´ {influencer_count}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œ**")
    
    # ì»¬ëŸ¼ ì„¤ì •
    column_config = {
        "contract_id": st.column_config.NumberColumn("contract_id", width="small"),
        "SNS ID": st.column_config.TextColumn("SNS ID", width="medium"),
        "ì´ë¦„": st.column_config.TextColumn("ì´ë¦„", width="medium"),
        "FLW": st.column_config.NumberColumn("íŒ”ë¡œì›Œ", format="%d", width="medium"),
        "1íšŒê³„ì•½ë‹¨ê°€": st.column_config.NumberColumn("1íšŒê³„ì•½ë‹¨ê°€", format="%dì›", width="medium"),
        "2ì°¨í™œìš©": st.column_config.TextColumn("2ì°¨í™œìš©", width="small"),
        "2ì°¨ê¸°ê°„": st.column_config.TextColumn("2ì°¨ê¸°ê°„", width="small"),
        "ìµœì¢…ìƒíƒœ": st.column_config.TextColumn("ìµœì¢…ìƒíƒœ", width="small")
    }
    
    # ì›”ë³„ ì»¬ëŸ¼ ì„¤ì •
    for month in MONTHS:
        column_config[month] = st.column_config.TextColumn(month, width="small")
    
    st.dataframe(
        influencer_summary,
        use_container_width=True,
        column_config=column_config,
        hide_index=True,
        height=600  # í…Œì´ë¸” ë†’ì´ë¥¼ 600pxë¡œ ì„¤ì •
    )

def render_influencer_tab(df):
    """F&F CREW LIST íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ‘¥ F&F CREW LIST")
    
    if df.empty:
        st.warning("ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•„í„° ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ·ï¸ ë¸Œëœë“œ**")
        selected_brand_filter = st.selectbox("ë¸Œëœë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", BRAND_OPTIONS, key="crew_brand_filter", label_visibility="collapsed")
    
    with col2:
        st.markdown("**ğŸ“… ì‹œì¦Œ**")
        season_options = get_season_options(df)
        selected_season_filter = st.selectbox("ì‹œì¦Œì„ ì„ íƒí•˜ì„¸ìš”", season_options, key="crew_season_filter", label_visibility="collapsed", index=0)
    
    # ì‹œì¦Œ í•„í„° ì ìš© (í•­ìƒ ì„ íƒëœ ì‹œì¦Œìœ¼ë¡œ í•„í„°ë§)
    if 'contract_sesn' in df.columns:
        filtered_df = df[df['contract_sesn'] == selected_season_filter]
    else:
        filtered_df = df  # ì‹œì¦Œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©
    
    # ë¸Œëœë“œ í•„í„° ì ìš©
    if selected_brand_filter != 'ì „ì²´':
        qty_col = f"{selected_brand_filter.lower()}_qty"
        if qty_col in filtered_df.columns:
            filtered_df = filtered_df[filtered_df[qty_col] > 0]
        else:
            filtered_df = pd.DataFrame()  # í•´ë‹¹ ë¸Œëœë“œ ê³„ì•½ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„
    
    # í†µê³„ ê³„ì‚°
    total_influencers = len(filtered_df)
    
    # ì´ ê³„ì•½ìˆ˜ ê³„ì‚°
    total_contracts = 0
    if not filtered_df.empty:
        if selected_brand_filter != 'ì „ì²´':
            # íŠ¹ì • ë¸Œëœë“œ ì„ íƒ ì‹œ í•´ë‹¹ ë¸Œëœë“œ ê³„ì•½ìˆ˜ë§Œ ê³„ì‚°
            qty_col = f"{selected_brand_filter.lower()}_qty"
            if qty_col in filtered_df.columns:
                total_contracts = int(filtered_df[qty_col].sum())
        else:
            # ì „ì²´ ì„ íƒ ì‹œ ëª¨ë“  ë¸Œëœë“œ ê³„ì•½ìˆ˜ í•©ì‚°
            qty_cols = [f"{brand.lower()}_qty" for brand in BRANDS]
            available_qty_cols = [col for col in qty_cols if col in filtered_df.columns]
            if available_qty_cols:
                total_contracts = int(filtered_df[available_qty_cols].sum().sum())
    
    # NaN ê°’ ì²˜ë¦¬
    if 'follower' in filtered_df.columns and not filtered_df['follower'].isna().all():
        avg_followers = int(filtered_df['follower'].mean()) if not pd.isna(filtered_df['follower'].mean()) else 0
    else:
        avg_followers = 0
        
    if 'unit_fee' in filtered_df.columns and not filtered_df['unit_fee'].isna().all():
        avg_contract_fee = int(filtered_df['unit_fee'].mean()) if not pd.isna(filtered_df['unit_fee'].mean()) else 0
    else:
        avg_contract_fee = 0
    
    # í†µê³„ í‘œì‹œ (ì œëª© ì—†ì´)
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì¸í”Œë£¨ì–¸ì„œ ìˆ˜", f"{total_influencers:,}ëª…")
    with col2:
        st.metric("ì´ ê³„ì•½ìˆ˜", f"{total_contracts:,}ê±´")
    with col3:
        st.metric("í‰ê·  íŒ”ë¡œì›Œ ìˆ˜", f"{avg_followers:,}")
    with col4:
        st.metric("í‰ê·  ê³„ì•½ë‹¨ê°€", f"{avg_contract_fee:,}ì›")
    
    st.markdown("---")
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì¤€ë¹„ (í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©)
    influencer_summary = prepare_influencer_summary(filtered_df, selected_brand_filter, selected_season_filter)
    
    if influencer_summary.empty:
        st.warning("ì„ íƒëœ ì¡°ê±´ì— ë§ëŠ” ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° í‘œì‹œ
    render_influencer_table(influencer_summary, selected_brand_filter, selected_season_filter, influencer_count=len(influencer_summary))
    
    # CREW ë°°ì • ê´€ë¦¬ ì„¹ì…˜ ì¶”ê°€
    st.markdown("---")
    st.markdown("## ğŸ“‹ CREW ë°°ì • ê´€ë¦¬")
    
    # ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ í‘œ ìƒì„±
    st.markdown("### ğŸ“Š ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ ê´€ë¦¬")
    
    # ì‹œì¦Œ ì„ íƒ
    season_options = ["25FW", "26SS"]
    selected_season = st.selectbox("ì‹œì¦Œ", season_options, key="assignment_season")
    
    # ì‹œì¦Œì— ë”°ë¥¸ ì›” ì„¤ì •
    if selected_season == "25FW":
        months = ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"]
    else:  # 26SS
        months = ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"]
    
    # ê¸°ì¡´ ëª©í‘œ ë°ì´í„° ë¡œë“œ
    targets_df = load_monthly_targets()
    
    # ë¸Œëœë“œë³„ ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ í‘œ ìƒì„±
    brands = ["MLB", "DX", "DV", "ST"]
    
    # ì‹œì¦Œë³„ ì›” ê°€ì ¸ì˜¤ê¸°
    months = SEASON_MONTHS.get(selected_season, ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"])
    
    # í˜„ì¬ ì‹œì¦Œ/ì›”ì— ë§ëŠ” ë°ì´í„° í•„í„°ë§ ë˜ëŠ” ì´ˆê¸°í™”
    if not targets_df.empty:
        targets_df_filtered = targets_df[targets_df['season'] == selected_season]
        
        # í˜„ì¬ ì‹œì¦Œì˜ ëª¨ë“  ì›”ì´ í¬í•¨ë˜ë„ë¡ ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
        current_targets_data = []
        for month in months:
            for brand in brands:
                # ì›”ì„ ìˆ«ìë¡œ ë³€í™˜ (9ì›” -> 9, 10ì›” -> 10, ...)
                month_num = int(month.replace('ì›”', ''))
                
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì›”ê³¼ ë¸Œëœë“œì˜ ëª©í‘œ ìˆ˜ëŸ‰ ì°¾ê¸°
                existing_target = targets_df_filtered[
                    (targets_df_filtered['month'] == month_num) & 
                    (targets_df_filtered['brand'] == brand)
                ]
                if not existing_target.empty:
                    current_targets_data.append({
                        'month': month,
                        'ë¸Œëœë“œ': brand,
                        'ëª©í‘œìˆ˜ëŸ‰': int(existing_target['target_quantity'].iloc[0])
                    })
                else:
                    current_targets_data.append({
                        'month': month,
                        'ë¸Œëœë“œ': brand,
                        'ëª©í‘œìˆ˜ëŸ‰': 0
                    })
        
        current_targets_df = pd.DataFrame(current_targets_data)
        
        # í”¼ë²— í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜
        pivot_df = current_targets_df.pivot_table(
            index='month', columns='ë¸Œëœë“œ', values='ëª©í‘œìˆ˜ëŸ‰'
        ).reindex(months, axis=0).reindex(brands, axis=1).fillna(0).astype(int)
    else:
        # ì´ˆê¸° ë°ì´í„°í”„ë ˆì„ ìƒì„±
        pivot_data = []
        for month in months:
            row = {"ì›”": month}
            for brand in brands:
                row[brand] = 0
            pivot_data.append(row)
        
        pivot_df = pd.DataFrame(pivot_data)
        pivot_df = pivot_df.set_index("ì›”")
    
    # í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„
    st.markdown("#### ë°°ì •ìˆ˜ëŸ‰ ì…ë ¥")
    edited_df = st.data_editor(
        pivot_df,
        use_container_width=True,
        key="monthly_targets_editor",
        hide_index=False,
        column_config={
            col: st.column_config.NumberColumn(col, min_value=0) 
            for col in pivot_df.columns
        }
    )
    
    # ë²„íŠ¼ë“¤
    col1, col2, col3, col_spacer, col4 = st.columns([0.2, 0.2, 0.1, 0.1, 0.4])
    
    with col1:
        if st.button("ğŸ’¾ ë°°ì •ìˆ˜ëŸ‰ ì €ì¥", type="secondary", use_container_width=True):
            # edited_dfë¥¼ ì›ë˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            saved_targets = edited_df.stack().reset_index()
            saved_targets.columns = ['month', 'brand', 'target_quantity']
            
            # ì›”ì„ ìˆ«ìë¡œ ë³€í™˜ (9ì›” -> 9, 10ì›” -> 10, ...)
            saved_targets['month'] = saved_targets['month'].str.replace('ì›”', '').astype(int)
            saved_targets['season'] = selected_season  # ì‹œì¦Œ ì •ë³´ ì¶”ê°€
            
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í˜„ì¬ ì‹œì¦Œ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
            if not targets_df.empty:
                other_season_targets = targets_df[targets_df['season'] != selected_season]
                updated_targets_df = pd.concat([other_season_targets, saved_targets], ignore_index=True)
            else:
                updated_targets_df = saved_targets
            
            save_monthly_targets(updated_targets_df)
            st.success("âœ… ë°°ì •ìˆ˜ëŸ‰ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    with col2:
        if st.button("ğŸš€ ìë™ë°°ì •ì‹¤í–‰", type="secondary", use_container_width=True):
            # ìë™ë°°ì • ì‹¤í–‰
            execute_monthly_automatic_assignment_from_table(edited_df, df)
    
    with col3:
        pass  # ë¹ˆ ê³µê°„
    
    with col4:
        pass  # ë¹ˆ ê³µê°„
    
    # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ (ë©”ì¸ ì„¹ì…˜)
    st.markdown("---")
    st.subheader("ğŸ‘¥ ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­")
    
    # ë°°ì • ì´ë ¥ì´ ìˆëŠ” ê²½ìš° ë¶„ì„
    if os.path.exists('data/assignment_history.csv'):
        try:
            assignment_df = pd.read_csv('data/assignment_history.csv', encoding="utf-8")
            
            if not assignment_df.empty:
                # ì‹œì¦Œ í•„í„°ë§ ì ìš© (ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ì‚¬ìš©)
                selected_season = st.session_state.get('assignment_season', '25FW')
                
                if 'ì‹œì¦Œ' in assignment_df.columns:
                    original_count = len(assignment_df)
                    assignment_df = assignment_df[assignment_df['ì‹œì¦Œ'] == selected_season]
                    filtered_count = len(assignment_df)
                    st.info(f"ğŸ“Š ì´ {filtered_count}ê±´ì˜ ë°°ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                    
                    # ì‹œì¦Œì— ë°°ì • ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ í…Œì´ë¸” í‘œì‹œ
                    if assignment_df.empty:
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return
                else:
                    # ì‹œì¦Œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ëŠ” 25FWë¡œ ê°„ì£¼
                    if selected_season != '25FW':
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return
                
                # ìƒíƒœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°°ì •ì™„ë£Œ ìƒíƒœë§Œ í•„í„°ë§, ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
                if 'ìƒíƒœ' in assignment_df.columns:
                    completed_assignments = assignment_df[assignment_df['ìƒíƒœ'] == 'ğŸ“‹ ë°°ì •ì™„ë£Œ']
                else:
                    completed_assignments = assignment_df
                
                # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ í‘œì‹œ
                if not completed_assignments.empty:
                    # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ ìƒì„±
                    assignment_summary = create_assignment_summary(completed_assignments, selected_season, df)
                    if not assignment_summary.empty:
                        st.dataframe(assignment_summary, use_container_width=True, height=400, hide_index=True)
                        
                        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë° ë°°ì •ì´ˆê¸°í™” ë²„íŠ¼
                        col1, col2, col3, col_spacer, col4 = st.columns([0.2, 0.2, 0.1, 0.1, 0.4])
                        
                        with col1:
                            excel_buffer = create_excel_with_two_sheets(assignment_summary, completed_assignments)
                            
                            st.download_button(
                                label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                                data=excel_buffer,
                                file_name=f"assignment_summary_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                type="secondary",
                                use_container_width=True
                            )
                        
                        with col2:
                            if st.button("ğŸ—‘ï¸ ë°°ì •ì´ˆê¸°í™”", type="secondary", use_container_width=True):
                                # ë°°ì • ì´ë ¥ë§Œ ì´ˆê¸°í™” (ë°°ì •ìˆ˜ëŸ‰ ì…ë ¥ ë°ì´í„°ëŠ” ë³´ì¡´)
                                if os.path.exists("data/assignment_history.csv"):
                                    os.remove("data/assignment_history.csv")
                                
                                st.success("âœ… ë°°ì • ì´ë ¥ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.rerun()
                    else:
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                else:
                    st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                
            else:
                st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            st.warning(f"ë°°ì • ì´ë ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # ë°°ì •í˜„í™©ëª¨ë‹ˆí„°ë§
    st.markdown("---")
    st.subheader("ğŸ“Š ë°°ì •í˜„í™©ëª¨ë‹ˆí„°ë§")
    
    # ê·¸ë˜í”„ í†µê³„ ì„¹ì…˜
    st.markdown("#### ğŸ“ˆ ê·¸ë˜í”„ í†µê³„")
    
    # ë°°ì • ì´ë ¥ì´ ìˆëŠ” ê²½ìš° ê·¸ë˜í”„ í‘œì‹œ
    if os.path.exists('data/assignment_history.csv'):
        try:
            assignment_df = pd.read_csv('data/assignment_history.csv', encoding="utf-8")
            
            if not assignment_df.empty:
                # ì‹œì¦Œ í•„í„°ë§ ì ìš©
                selected_season = st.session_state.get('assignment_season', '25FW')
                
                if 'ì‹œì¦Œ' in assignment_df.columns:
                    assignment_df = assignment_df[assignment_df['ì‹œì¦Œ'] == selected_season]
                
                # ìƒíƒœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°°ì •ì™„ë£Œ ìƒíƒœë§Œ í•„í„°ë§
                if 'ìƒíƒœ' in assignment_df.columns:
                    assignment_df = assignment_df[assignment_df['ìƒíƒœ'] == 'ğŸ“‹ ë°°ì •ì™„ë£Œ']
                
                if not assignment_df.empty:
                    # ë¸Œëœë“œë³„ ë°°ì • í˜„í™©
                    brand_counts = assignment_df['ë¸Œëœë“œ'].value_counts()
                    
                    # ê·¸ë˜í”„ ìƒì„±
                    fig = px.pie(
                        values=brand_counts.values,
                        names=brand_counts.index,
                        title="ë¸Œëœë“œë³„ ë°°ì • í˜„í™©"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ì›”ë³„ ë°°ì • í˜„í™©
                    if 'ë°°ì •ì›”' in assignment_df.columns:
                        month_counts = assignment_df['ë°°ì •ì›”'].value_counts()
                        
                        # ì›” ìˆœì„œ ì •ë ¬
                        month_order = ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"] if selected_season == "25FW" else ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"]
                        month_counts = month_counts.reindex([m for m in month_order if m in month_counts.index])
                        
                        fig2 = px.bar(
                            x=month_counts.index,
                            y=month_counts.values,
                            title="ì›”ë³„ ë°°ì • í˜„í™©"
                        )
                        st.plotly_chart(fig2, use_container_width=True)
                else:
                    st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            st.warning(f"ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
    

def prepare_influencer_summary(df, selected_brand_filter, selected_season_filter):
    """ì¸í”Œë£¨ì–¸ì„œ ìš”ì•½ ë°ì´í„° ì¤€ë¹„"""
    if df.empty:
        return pd.DataFrame()
    
    # ê¸°ë³¸ ì»¬ëŸ¼ ì„ íƒ
    required_columns = ["contract_id", "sns_id", "name", "follower", "unit_fee", "sec_usage", "sec_period"]
    available_columns = [col for col in required_columns if col in df.columns]
    
    if not available_columns:
        st.error("í•„ìš”í•œ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    influencer_summary = df[available_columns].copy()
    
    # ì „ì²´ ê³„ì•½ìˆ˜ ê³„ì‚°
    qty_cols = [f"{brand.lower()}_qty" for brand in BRANDS]
    available_qty_cols = [col for col in qty_cols if col in df.columns]
    if available_qty_cols:
        influencer_summary["ì „ì²´_ê³„ì•½ìˆ˜"] = df[available_qty_cols].sum(axis=1)
    
    # ì‹œì¦Œ í•„í„° ì ìš© (ì´ë¯¸ filtered_dfë¡œ í•„í„°ë§ë¨)
    if selected_season_filter != "ì „ì²´":
        # ì‹œì¦Œë³„ ì›” ì»¬ëŸ¼ ì¶”ê°€
        months = SEASON_MONTHS.get(selected_season_filter, ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"])
        for month in months:
            influencer_summary[month] = ""
    
    # ë¸Œëœë“œ í•„í„° ì ìš©
    if selected_brand_filter != "ì „ì²´":
        qty_col = f"{selected_brand_filter.lower()}_qty"
        if qty_col in df.columns:
            brand_filter_mask = df[qty_col] > 0
            influencer_summary = influencer_summary[brand_filter_mask]
    
    # ë¸Œëœë“œë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
    add_brand_details(influencer_summary, df, selected_brand_filter)
    
    
    # ì›”ë³„ ì»¬ëŸ¼ ì¶”ê°€ (ì»¬ëŸ¼ëª… ë³€ê²½ ì „ì—) - ì‹œì¦Œ í•„í„°ì— ë”°ë¼ ì¶”ê°€
    add_monthly_columns(influencer_summary, df, selected_brand_filter, selected_season_filter)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •: ë¸Œëœë“œë³„ ê³„ì•½ìˆ˜ ì»¬ëŸ¼ë“¤ì„ ì›”ë³„ ì»¬ëŸ¼ë“¤ ì•ìœ¼ë¡œ ì´ë™
    influencer_summary = reorder_columns(influencer_summary)
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    influencer_summary = influencer_summary.rename(columns={
        "contract_id": "contract_id", "sns_id": "SNS ID", "name": "ì´ë¦„", "follower": "FLW", "unit_fee": "1íšŒê³„ì•½ë‹¨ê°€", 
        "sec_usage": "2ì°¨í™œìš©", "sec_period": "2ì°¨ê¸°ê°„"
    })
    
    return influencer_summary

def render_assignment_tab():
    """CREW ë°°ì • ê´€ë¦¬ íƒ­ ë Œë”ë§"""
    st.markdown("# ğŸ“‹ CREW ë°°ì • ê´€ë¦¬")
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë¡œë“œ
    df = load_influencer_data()
    if df.empty:
        st.warning("ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ í‘œ ìƒì„±
    st.markdown("## ğŸ“Š ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ ê´€ë¦¬")
    
    # ì‹œì¦Œ ì„ íƒ
    season_options = ["25FW", "26SS"]
    selected_season = st.selectbox("ì‹œì¦Œ", season_options, key="assignment_season")
    
    # ì‹œì¦Œì— ë”°ë¥¸ ì›” ì„¤ì •
    if selected_season == "25FW":
        months = ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"]
    else:  # 26SS
        months = ["3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”"]
    
    # ê¸°ì¡´ ëª©í‘œ ë°ì´í„° ë¡œë“œ
    targets_df = load_monthly_targets()
    
    # ë¸Œëœë“œë³„ ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ í‘œ ìƒì„±
    brands = ["MLB", "DX", "DV", "ST"]
    
    # ì‹œì¦Œë³„ ì›” ê°€ì ¸ì˜¤ê¸°
    months = SEASON_MONTHS.get(selected_season, ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"])
    
    # í˜„ì¬ ì‹œì¦Œ/ì›”ì— ë§ëŠ” ë°ì´í„° í•„í„°ë§ ë˜ëŠ” ì´ˆê¸°í™”
    if not targets_df.empty:
        targets_df_filtered = targets_df[targets_df['season'] == selected_season]
        
        # í˜„ì¬ ì‹œì¦Œì˜ ëª¨ë“  ì›”ì´ í¬í•¨ë˜ë„ë¡ ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
        current_targets_data = []
        for month in months:
            for brand in brands:
                # ì›”ì„ ìˆ«ìë¡œ ë³€í™˜ (9ì›” -> 9, 10ì›” -> 10, ...)
                month_num = int(month.replace('ì›”', ''))
                
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì›”ê³¼ ë¸Œëœë“œì˜ ëª©í‘œ ìˆ˜ëŸ‰ ì°¾ê¸°
                existing_target = targets_df_filtered[
                    (targets_df_filtered['month'] == month_num) & 
                    (targets_df_filtered['brand'] == brand)
                ]
                if not existing_target.empty:
                    current_targets_data.append({
                        'month': month,
                        'ë¸Œëœë“œ': brand,
                        'ëª©í‘œìˆ˜ëŸ‰': int(existing_target['target_quantity'].iloc[0])
                    })
                else:
                    current_targets_data.append({
                        'month': month,
                        'ë¸Œëœë“œ': brand,
                        'ëª©í‘œìˆ˜ëŸ‰': 0
                    })
        
        current_targets_df = pd.DataFrame(current_targets_data)
        
        # í”¼ë²— í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜
        pivot_df = current_targets_df.pivot_table(
            index='month', columns='ë¸Œëœë“œ', values='ëª©í‘œìˆ˜ëŸ‰'
        ).reindex(months, axis=0).reindex(brands, axis=1).fillna(0).astype(int)
    else:
        # ì´ˆê¸° ë°ì´í„°í”„ë ˆì„ ìƒì„±
        pivot_data = []
        for month in months:
            row = {"ì›”": month}
            for brand in brands:
                row[brand] = 0
            pivot_data.append(row)
        
        pivot_df = pd.DataFrame(pivot_data)
        pivot_df = pivot_df.set_index("ì›”")
    
    # í¸ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„
    st.markdown("### ë°°ì •ìˆ˜ëŸ‰ ì…ë ¥")
    edited_df = st.data_editor(
        pivot_df,
        use_container_width=True,
        key="monthly_targets_editor",
        hide_index=False,
        column_config={
            col: st.column_config.NumberColumn(col, min_value=0) 
            for col in pivot_df.columns
        }
    )
    
    # ë²„íŠ¼ë“¤
    col1, col2, col3, col_spacer, col4 = st.columns([0.2, 0.2, 0.1, 0.1, 0.4])
    
    with col1:
        if st.button("ğŸ’¾ ë°°ì •ìˆ˜ëŸ‰ ì €ì¥", type="secondary", use_container_width=True):
            # edited_dfë¥¼ ì›ë˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            saved_targets = edited_df.stack().reset_index()
            saved_targets.columns = ['month', 'brand', 'target_quantity']
            
            # ì›”ì„ ìˆ«ìë¡œ ë³€í™˜ (9ì›” -> 9, 10ì›” -> 10, ...)
            saved_targets['month'] = saved_targets['month'].str.replace('ì›”', '').astype(int)
            saved_targets['season'] = selected_season  # ì‹œì¦Œ ì •ë³´ ì¶”ê°€
            
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í˜„ì¬ ì‹œì¦Œ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
            if not targets_df.empty:
                other_season_targets = targets_df[targets_df['season'] != selected_season]
                updated_targets_df = pd.concat([other_season_targets, saved_targets], ignore_index=True)
            else:
                updated_targets_df = saved_targets
            
            save_monthly_targets(updated_targets_df)
            st.success("âœ… ë°°ì •ìˆ˜ëŸ‰ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    with col2:
        if st.button("ğŸš€ ìë™ë°°ì •ì‹¤í–‰", type="secondary", use_container_width=True):
            # ìë™ë°°ì • ì‹¤í–‰
            execute_monthly_automatic_assignment_from_table(edited_df, df)
    
    with col3:
        pass  # ë¹ˆ ê³µê°„
    
    with col4:
        pass  # ë¹ˆ ê³µê°„
    
    # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ (ë©”ì¸ ì„¹ì…˜)
    st.markdown("---")
    st.subheader("ğŸ‘¥ ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­")
    
    # ë°°ì • ì´ë ¥ì´ ìˆëŠ” ê²½ìš° ë¶„ì„
    if os.path.exists('data/assignment_history.csv'):
        try:
            assignment_df = pd.read_csv('data/assignment_history.csv', encoding="utf-8")
            
            if not assignment_df.empty:
                # ì‹œì¦Œ í•„í„°ë§ ì ìš© (ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ì‚¬ìš©)
                selected_season = st.session_state.get('assignment_season', '25FW')
                
                if 'ì‹œì¦Œ' in assignment_df.columns:
                    original_count = len(assignment_df)
                    assignment_df = assignment_df[assignment_df['ì‹œì¦Œ'] == selected_season]
                    filtered_count = len(assignment_df)
                    st.info(f"ğŸ“Š ì´ {filtered_count}ê±´ì˜ ë°°ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                    
                    # ì‹œì¦Œì— ë°°ì • ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ í…Œì´ë¸” í‘œì‹œ
                    if assignment_df.empty:
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return
                else:
                    # ì‹œì¦Œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ëŠ” 25FWë¡œ ê°„ì£¼
                    if selected_season != '25FW':
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return
                
                # ìƒíƒœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°°ì •ì™„ë£Œ ìƒíƒœë§Œ í•„í„°ë§, ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
                if 'ìƒíƒœ' in assignment_df.columns:
                    completed_assignments = assignment_df[assignment_df['ìƒíƒœ'] == 'ğŸ“‹ ë°°ì •ì™„ë£Œ']
                else:
                    completed_assignments = assignment_df
                
                # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ í‘œì‹œ
                if not completed_assignments.empty:
                    # ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ ìƒì„±
                    assignment_summary = create_assignment_summary(completed_assignments, selected_season, df)
                    if not assignment_summary.empty:
                        st.dataframe(assignment_summary, use_container_width=True, height=400, hide_index=True)
                        
                        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë° ë°°ì •ì´ˆê¸°í™” ë²„íŠ¼
                        col1, col2, col3, col_spacer, col4 = st.columns([0.2, 0.2, 0.1, 0.1, 0.4])
                        
                        with col1:
                            excel_buffer = create_excel_with_two_sheets(assignment_summary, completed_assignments)
                            
                            st.download_button(
                                label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                                data=excel_buffer,
                                file_name=f"assignment_summary_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                type="secondary",
                                use_container_width=True
                            )
                        
                        with col2:
                            if st.button("ğŸ—‘ï¸ ë°°ì •ì´ˆê¸°í™”", type="secondary", use_container_width=True):
                                # ë°°ì • ì´ë ¥ë§Œ ì´ˆê¸°í™” (ë°°ì •ìˆ˜ëŸ‰ ì…ë ¥ ë°ì´í„°ëŠ” ë³´ì¡´)
                                if os.path.exists("data/assignment_history.csv"):
                                    os.remove("data/assignment_history.csv")
                                
                                st.success("âœ… ë°°ì • ì´ë ¥ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.rerun()
                    else:
                        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                else:
                    st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                
            else:
                st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            st.warning(f"ë°°ì • ì´ë ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.info("ğŸ“Š ì•„ì§ ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # ë°°ì •í˜„í™©ëª¨ë‹ˆí„°ë§
    st.markdown("---")
    st.subheader("ğŸ“Š ë°°ì •í˜„í™©ëª¨ë‹ˆí„°ë§")
    
    # ê·¸ë˜í”„ í†µê³„ ì„¹ì…˜
    st.markdown("#### ğŸ“ˆ ê·¸ë˜í”„ í†µê³„")
    
    # ë°°ì • ì´ë ¥ì´ ìˆëŠ” ê²½ìš° ê·¸ë˜í”„ í‘œì‹œ
    if os.path.exists('data/assignment_history.csv'):
        try:
            assignment_df = pd.read_csv('data/assignment_history.csv', encoding="utf-8")
            
            if not assignment_df.empty and 'ë°°ì •ì›”' in assignment_df.columns and 'ë¸Œëœë“œ' in assignment_df.columns:
                # ì‹œì¦Œ í•„í„°ë§ ì ìš© (ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ì‚¬ìš©)
                if 'ì‹œì¦Œ' in assignment_df.columns:
                    # ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ê°’ ê°€ì ¸ì˜¤ê¸°
                    selected_season = st.session_state.get('assignment_season', '25FW')
                    assignment_df = assignment_df[assignment_df['ì‹œì¦Œ'] == selected_season]
                    
                    # ì‹œì¦Œì— ë°°ì • ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê·¸ë˜í”„ í‘œì‹œ
                    if assignment_df.empty:
                        return
                
                # ìƒíƒœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°°ì •ì™„ë£Œ ìƒíƒœë§Œ í•„í„°ë§, ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
                if 'ìƒíƒœ' in assignment_df.columns:
                    completed_assignments = assignment_df[assignment_df['ìƒíƒœ'] == 'ğŸ“‹ ë°°ì •ì™„ë£Œ']
                else:
                    completed_assignments = assignment_df
                
                if not completed_assignments.empty:
                    # 2ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë˜í”„ ë‚˜ë€íˆ ë°°ì¹˜
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ë¸Œëœë“œë³„ ë°°ì • í˜„í™© ê·¸ë˜í”„
                        brand_counts = completed_assignments['ë¸Œëœë“œ'].value_counts()
                        
                        # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
                        import plotly.express as px
                        fig = px.bar(
                            x=brand_counts.index, 
                            y=brand_counts.values,
                            title="ë¸Œëœë“œë³„ ë°°ì • í˜„í™©",
                            labels={'x': 'ë¸Œëœë“œ', 'y': 'ë°°ì • ìˆ˜ëŸ‰'},
                            color_discrete_sequence=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
                        )
                        fig.update_layout(
                            showlegend=False,
                            height=400,
                            title_x=0.5,
                            margin=dict(t=50, b=50, l=50, r=50)  # ìƒë‹¨ ì—¬ë°± ì¦ê°€
                        )
                        # ë§‰ëŒ€ ìœ„ì— ìˆ«ì ë ˆì´ë¸” ì¶”ê°€
                        fig.update_traces(
                            text=brand_counts.values,
                            textposition='outside'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # ì›”ë³„ ë°°ì • í˜„í™© ê·¸ë˜í”„
                        month_counts = completed_assignments['ë°°ì •ì›”'].value_counts()
                        month_order = ['9ì›”', '10ì›”', '11ì›”', '12ì›”', '1ì›”', '2ì›”']
                        month_counts = month_counts.reindex(month_order, fill_value=0)
                        
                        fig2 = px.bar(
                            x=month_counts.index, 
                            y=month_counts.values,
                            title="ì›”ë³„ ë°°ì • í˜„í™©",
                            labels={'x': 'ì›”', 'y': 'ë°°ì • ìˆ˜ëŸ‰'},
                            color_discrete_sequence=['#2ca02c', '#ff7f0e', '#1f77b4', '#d62728', '#9467bd', '#8c564b']
                        )
                        fig2.update_layout(
                            showlegend=False,
                            height=400,
                            title_x=0.5,
                            margin=dict(t=50, b=50, l=50, r=50)  # ìƒë‹¨ ì—¬ë°± ì¦ê°€
                        )
                        # ë§‰ëŒ€ ìœ„ì— ìˆ«ì ë ˆì´ë¸” ì¶”ê°€
                        fig2.update_traces(
                            text=month_counts.values,
                            textposition='outside'
                        )
                        st.plotly_chart(fig2, use_container_width=True)
                else:
                    st.info("ë°°ì •ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ë°°ì • ì´ë ¥ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.info("ì•„ì§ ë°°ì • ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë°°ì •ìš”ì²­ìˆ˜ëŸ‰ vs ë°°ì •ìˆ˜ëŸ‰ ë¹„êµ í…Œì´ë¸” (ë§¨ ì•„ë˜ì— í‘œì‹œ)
    st.markdown("#### ğŸ“ˆ ë°°ì •ìš”ì²­ìˆ˜ëŸ‰ vs ë°°ì •ìˆ˜ëŸ‰ ë¹„êµ")
    
    # ë°°ì • ì´ë ¥ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¹„êµ í…Œì´ë¸” í‘œì‹œ
    if os.path.exists('data/assignment_history.csv'):
        try:
            assignment_df = pd.read_csv('data/assignment_history.csv', encoding="utf-8")
            
            if not assignment_df.empty and 'ë°°ì •ì›”' in assignment_df.columns and 'ë¸Œëœë“œ' in assignment_df.columns:
                # ì‹œì¦Œ í•„í„°ë§ ì ìš© (ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ì‚¬ìš©)
                if 'ì‹œì¦Œ' in assignment_df.columns:
                    # ë§¨ ìœ„ì˜ ì‹œì¦Œ í•„í„° ê°’ ê°€ì ¸ì˜¤ê¸°
                    selected_season = st.session_state.get('assignment_season', '25FW')
                    assignment_df = assignment_df[assignment_df['ì‹œì¦Œ'] == selected_season]
                    
                    # ì‹œì¦Œì— ë°°ì • ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¹„êµ í…Œì´ë¸” í‘œì‹œ
                    if assignment_df.empty:
                        st.info(f"ğŸ“Š {selected_season} ì‹œì¦Œì—ëŠ” ì•„ì§ ë°°ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return
                
                # ìš”ì²­ìˆ˜ëŸ‰ (edited_dfì—ì„œ)
                request_data = []
                for brand in brands:
                    for month in months:
                        target = int(edited_df.loc[month, brand])
                        request_data.append({
                            'ë¸Œëœë“œ': brand,
                            'ì›”': month,
                            'ìš”ì²­ìˆ˜ëŸ‰': target
                        })
                
                request_df = pd.DataFrame(request_data)
                
                # ìƒíƒœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°°ì •ì™„ë£Œ ìƒíƒœë§Œ í•„í„°ë§, ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
                if 'ìƒíƒœ' in assignment_df.columns:
                    completed_assignments = assignment_df[assignment_df['ìƒíƒœ'] == 'ğŸ“‹ ë°°ì •ì™„ë£Œ']
                else:
                    completed_assignments = assignment_df
                
                # ë¸Œëœë“œë³„, ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ ì§‘ê³„
                actual_data = []
                for brand in brands:
                    for month in months:
                        brand_month_assignments = completed_assignments[
                            (completed_assignments['ë¸Œëœë“œ'] == brand) & 
                            (completed_assignments['ë°°ì •ì›”'] == month)
                        ]
                        actual_count = len(brand_month_assignments)
                        actual_data.append({
                            'ë¸Œëœë“œ': brand,
                            'ì›”': month,
                            'ë°°ì •ìˆ˜ëŸ‰': actual_count
                        })
                
                actual_df = pd.DataFrame(actual_data)
                
                # ìš”ì²­ìˆ˜ëŸ‰ê³¼ ë°°ì •ìˆ˜ëŸ‰ ë³‘í•©
                comparison_df = request_df.merge(actual_df, on=['ë¸Œëœë“œ', 'ì›”'], how='left')
                comparison_df['ë°°ì •ìˆ˜ëŸ‰'] = comparison_df['ë°°ì •ìˆ˜ëŸ‰'].fillna(0).astype(int)
                
                # ë‹¬ì„±ë¥  ê³„ì‚°
                comparison_df['ë‹¬ì„±ë¥ '] = (comparison_df['ë°°ì •ìˆ˜ëŸ‰'] / comparison_df['ìš”ì²­ìˆ˜ëŸ‰'] * 100).round(1)
                comparison_df['ë‹¬ì„±ë¥ '] = comparison_df['ë‹¬ì„±ë¥ '].replace([float('inf'), -float('inf')], 0)
                comparison_df['ë‹¬ì„±ë¥ '] = comparison_df['ë‹¬ì„±ë¥ '].fillna(0)
                
                # ìƒíƒœ í‘œì‹œ
                comparison_df['ìƒíƒœ'] = comparison_df.apply(
                    lambda row: "âœ… ì™„ë£Œ" if row['ë°°ì •ìˆ˜ëŸ‰'] >= row['ìš”ì²­ìˆ˜ëŸ‰'] else "âŒ ë¯¸ë‹¬ì„±", 
                    axis=1
                )
                
                # í‘œì‹œ
                st.dataframe(comparison_df, use_container_width=True)
            else:
                st.info("ë°°ì • ì´ë ¥ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ë°°ì • ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.info("ì•„ì§ ë°°ì • ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

def create_excel_with_two_sheets(assignment_summary, completed_assignments):
    """ì—‘ì…€ íŒŒì¼ì„ ë‘ ê°œì˜ ì‹œíŠ¸ë¡œ ìƒì„±"""
    import io
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    
    # ì›Œí¬ë¶ ìƒì„±
    wb = Workbook()
    
    # ì‹œíŠ¸1: ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ (í…Œì´ë¸” í˜•íƒœ)
    ws1 = wb.active
    ws1.title = "ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì •ë‚´ì—­"
    
    # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •
    header_font = Font(bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
    header_alignment = Alignment(horizontal="center", vertical="center")
    
    # ì‹œíŠ¸1 ë°ì´í„° ì‘ì„±
    if not assignment_summary.empty:
        # í—¤ë” ì‘ì„±
        headers = assignment_summary.columns.tolist()
        for col_idx, header in enumerate(headers, 1):
            cell = ws1.cell(row=1, column=col_idx, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # ë°ì´í„° ì‘ì„±
        for row_idx, row in assignment_summary.iterrows():
            for col_idx, value in enumerate(row, 1):
                ws1.cell(row=row_idx+2, column=col_idx, value=value)
        
        # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
        for column in ws1.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws1.column_dimensions[column_letter].width = adjusted_width
    
    # ì‹œíŠ¸2: ê°œë³„ ë°°ì • ë‚´ì—­ (ë¡œìš° í˜•íƒœ)
    ws2 = wb.create_sheet("ê°œë³„ ë°°ì •ë‚´ì—­")
    
    # ì‹œíŠ¸2 ë°ì´í„° ì‘ì„±
    if not completed_assignments.empty:
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        display_columns = ['contract_id', 'SNS ID', 'ì´ë¦„', 'ë¸Œëœë“œ', 'ë°°ì •ì›”', 'ë°°ì •ì¼']
        available_columns = [col for col in display_columns if col in completed_assignments.columns]
        
        if available_columns:
            row_data = completed_assignments[available_columns].copy()
            
            # í—¤ë” ì‘ì„±
            for col_idx, header in enumerate(available_columns, 1):
                cell = ws2.cell(row=1, column=col_idx, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
            
            # ë°ì´í„° ì‘ì„±
            for row_idx, row in row_data.iterrows():
                for col_idx, value in enumerate(row, 1):
                    ws2.cell(row=row_idx+2, column=col_idx, value=value)
            
            # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws2.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws2.column_dimensions[column_letter].width = adjusted_width
    
    # ë©”ëª¨ë¦¬ì— ì—‘ì…€ íŒŒì¼ ì €ì¥
    excel_buffer = io.BytesIO()
    wb.save(excel_buffer)
    excel_buffer.seek(0)
    
    return excel_buffer.getvalue()

def create_assignment_summary(completed_assignments, selected_season=None, df=None):
    """ì¸í”Œë£¨ì–¸ì„œë³„ ì›”ë³„ ë°°ì • ë‚´ì—­ ìƒì„±"""
    if completed_assignments.empty:
        return pd.DataFrame()
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['ì´ë¦„', 'ë¸Œëœë“œ', 'ë°°ì •ì›”']
    if not all(col in completed_assignments.columns for col in required_columns):
        return pd.DataFrame()
    
    # ì‹œì¦Œë³„ ì›” ê°€ì ¸ì˜¤ê¸°
    months = SEASON_MONTHS.get(selected_season, ["9ì›”", "10ì›”", "11ì›”", "12ì›”", "1ì›”", "2ì›”"])
    
    # ì¸í”Œë£¨ì–¸ì„œë³„ë¡œ ê·¸ë£¹í™”
    summary_data = []
    
    for name in completed_assignments['ì´ë¦„'].unique():
        influencer_data = completed_assignments[completed_assignments['ì´ë¦„'] == name]
        
        # ì¸í”Œë£¨ì–¸ì„œ ê¸°ë³¸ ì •ë³´ (ì²« ë²ˆì§¸ í–‰ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        first_row = influencer_data.iloc[0]
        contract_id = first_row.get('contract_id', '')
        sns_id = first_row.get('SNS ID', '')
        
        # ì›”ë³„ ë°°ì • ë¸Œëœë“œ ì •ë¦¬ (ì¤‘ë³µ ì œê±°)
        monthly_assignments = {}
        for month in months:
            month_data = influencer_data[influencer_data['ë°°ì •ì›”'] == month]
            if not month_data.empty:
                brands = month_data['ë¸Œëœë“œ'].tolist()
                # ì¤‘ë³µ ì œê±°í•˜ê³  ë¸Œëœë“œ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬ (MLB, DX, DV, ST)
                unique_brands = list(set(brands))
                brand_order = ['MLB', 'DX', 'DV', 'ST']
                sorted_brands = [brand for brand in brand_order if brand in unique_brands]
                monthly_assignments[month] = ','.join(sorted_brands)
            else:
                monthly_assignments[month] = ''
        
        # ì´ê³„ì•½ìˆ˜ ê³„ì‚° (influencer.csvì˜ ì‹¤ì œ ê³„ì•½ìˆ˜)
        total_contracts = 0
        if df is not None and not df.empty:
            # contract_idë¡œ í•´ë‹¹ ì¸í”Œë£¨ì–¸ì„œ ì°¾ê¸°
            if 'contract_id' in df.columns and contract_id:
                influencer_row = df[df['contract_id'] == contract_id]
                if not influencer_row.empty:
                    # ëª¨ë“  ë¸Œëœë“œ ê³„ì•½ìˆ˜ í•©ê³„
                    qty_cols = [f"{brand.lower()}_qty" for brand in BRANDS]
                    available_qty_cols = [col for col in qty_cols if col in influencer_row.columns]
                    if available_qty_cols:
                        total_contracts = int(influencer_row[available_qty_cols].sum().sum())
        
        # ìš”ì•½ ë°ì´í„° ìƒì„±
        summary_row = {
            'contract_id': contract_id,
            'SNS ID': sns_id,
            'ì´ë¦„': name,
            'ì´ê³„ì•½ìˆ˜': total_contracts
        }
        
        # ì‹œì¦Œë³„ ì›” ì»¬ëŸ¼ ì¶”ê°€
        for month in months:
            summary_row[month] = monthly_assignments[month]
        
        summary_data.append(summary_row)
    
    return pd.DataFrame(summary_data)

def execute_monthly_automatic_assignment_from_table(edited_df, df):
    """ì›”ë³„ ë°°ì •ìˆ˜ëŸ‰ í‘œì—ì„œ ìë™ë°°ì • ì‹¤í–‰ (ìµœì ë°°ì •ì•Œê³ ë¦¬ì¦˜ ì ìš©)"""
    try:
        import pulp
    except ImportError:
        st.error("âŒ PuLP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install pulp' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return
    
    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° í™•ì¸
    if df.empty:
        st.error("âŒ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í˜„ì¬ ì„ íƒëœ ì‹œì¦Œ ê°€ì ¸ì˜¤ê¸°
    selected_season = st.session_state.get('assignment_season', '25FW')
    
    # ë¸Œëœë“œë³„ ì»¬ëŸ¼ ë§¤í•‘
    brand_columns = {
        'MLB': 'mlb_qty',
        'DX': 'dx_qty', 
        'DV': 'dv_qty',
        'ST': 'st_qty'
    }
    
    # ê° ë¸Œëœë“œë³„ë¡œ ìµœì ë°°ì • ì‹¤í–‰
    assignment_data = []
    
    for brand in edited_df.columns:
        # í•´ë‹¹ ë¸Œëœë“œì˜ ì›”ë³„ ëª©í‘œ ìˆ˜ëŸ‰ í™•ì¸
        brand_targets = edited_df[brand]
        if brand_targets.sum() <= 0:
            continue  # ìš”ì²­ì´ ì•ˆëœ ë¸Œëœë“œ
        
        # í•´ë‹¹ ë¸Œëœë“œì˜ ì¸í”Œë£¨ì–¸ì„œ í•„í„°ë§
        brand_column = brand_columns.get(brand)
        if not brand_column or brand_column not in df.columns:
            st.warning(f"âš ï¸ {brand} ë¸Œëœë“œì˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        brand_influencers = df[df[brand_column] > 0].copy()
        if brand_influencers.empty:
            st.warning(f"âš ï¸ {brand} ë¸Œëœë“œì— ê³„ì•½ìˆ˜ëŸ‰ì´ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ìµœì ë°°ì •ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
        brand_assignments = execute_optimal_assignment_for_brand(
            brand, brand_influencers, brand_targets, brand_column, selected_season
        )
        assignment_data.extend(brand_assignments)
    
    # ë°°ì • ê²°ê³¼ ì €ì¥
    if assignment_data:
        # DataFrameìœ¼ë¡œ ë³€í™˜
        assignment_df = pd.DataFrame(assignment_data)
        
        # ê¸°ì¡´ ë°°ì • ì´ë ¥ ë¡œë“œ
        existing_assignments = load_assignment_history()
        
        # ìƒˆë¡œìš´ ë°°ì • ì´ë ¥ì„ ê¸°ì¡´ ì´ë ¥ì— ì¶”ê°€
        updated_assignments = pd.concat([existing_assignments, assignment_df], ignore_index=True)
        
        # ì¤‘ë³µ ì œê±° (ë™ì¼ ì¸í”Œë£¨ì–¸ì„œ-ë¸Œëœë“œ-ì›” ì¤‘ë³µ ë°°ì • ë°©ì§€)
        updated_assignments.drop_duplicates(
            subset=['contract_id', 'ë¸Œëœë“œ', 'ë°°ì •ì›”'], 
            keep='last', 
            inplace=True
        )
        
        # CSVë¡œ ì €ì¥
        save_assignment_history(updated_assignments)
    else:
        st.warning("ë°°ì •í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def execute_optimal_assignment_for_brand(brand, influencers_df, monthly_targets, brand_column, selected_season):
    """íŠ¹ì • ë¸Œëœë“œì— ëŒ€í•œ ìµœì ë°°ì • ì‹¤í–‰"""
    try:
        import pulp
        
        # ë°ì´í„° ì¤€ë¹„
        influencer_ids = influencers_df['contract_id'].tolist()
        months = monthly_targets.index.tolist()
        
        # ê³„ì•½ìˆ˜ëŸ‰ ë§¤í•‘
        contract_qty = {row['contract_id']: row[brand_column] for _, row in influencers_df.iterrows()}
        
        # ì›”ë³„ ëª©í‘œ ìˆ˜ëŸ‰ ë§¤í•‘
        target_qty = {month: int(monthly_targets[month]) for month in months}
        
        # ìµœì í™” ë¬¸ì œ ì •ì˜
        prob = pulp.LpProblem(f"{brand}_Assignment", pulp.LpMaximize)
        
        # ì˜ì‚¬ê²°ì • ë³€ìˆ˜ ìƒì„±
        x = pulp.LpVariable.dicts("assign", 
                                 [(i, j) for i in influencer_ids for j in months], 
                                 0, 1, pulp.LpBinary)
        
        # ëª©ì  í•¨ìˆ˜: ì´ ë°°ì • ìˆ˜ëŸ‰ ìµœëŒ€í™”
        prob += pulp.lpSum(x[i, j] for i in influencer_ids for j in months)
        
        # ì œì•½ ì¡°ê±´ 1: ì¸í”Œë£¨ì–¸ì„œë³„ ê³„ì•½ìˆ˜ ì œí•œ
        for i in influencer_ids:
            prob += pulp.lpSum(x[i, j] for j in months) <= contract_qty[i]
        
        # ì œì•½ ì¡°ê±´ 2: ì›”ë³„ ëª©í‘œ ìˆ˜ëŸ‰ ì œí•œ
        for j in months:
            if target_qty[j] > 0:
                prob += pulp.lpSum(x[i, j] for i in influencer_ids) == target_qty[j]
        
        # ì œì•½ ì¡°ê±´ 3: ì¤‘ë³µ ë°°ì • ë°©ì§€ (ì•ˆì „ì„± í™•ë³´)
        # ë™ì¼ ì¸í”Œë£¨ì–¸ì„œëŠ” ë™ì¼ ë¸Œëœë“œë¡œ ì›” 1íšŒ ì´ìƒ ë°°ì • ë¶ˆê°€
        for i in influencer_ids:
            for j in months:
                prob += x[i, j] <= 1  # ìµœëŒ€ 1íšŒ ë°°ì •
                prob += x[i, j] >= 0  # ìµœì†Œ 0íšŒ ë°°ì •
        
        # ìµœì í™” ì‹¤í–‰
        prob.solve()
        
        # ê²°ê³¼ ì²˜ë¦¬
        assignment_data = []
        if pulp.LpStatus[prob.status] == 'Optimal':
            # ìµœì í•´ë¥¼ ë°°ì • ë°ì´í„°ë¡œ ë³€í™˜
            for i in influencer_ids:
                for j in months:
                    if pulp.value(x[i, j]) == 1:
                        # ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ì°¾ê¸°
                        influencer_info = influencers_df[influencers_df['contract_id'] == i].iloc[0]
                        
                        assignment_info = {
                            'contract_id': i,
                            'SNS ID': influencer_info.get('sns_id', ''),
                            'ì´ë¦„': influencer_info.get('name', ''),
                            'ë¸Œëœë“œ': brand,
                            'ë°°ì •ì›”': j,
                            'ìƒíƒœ': 'ğŸ“‹ ë°°ì •ì™„ë£Œ',
                            'ë°°ì •ì¼': pd.Timestamp.now().strftime('%Y-%m-%d'),
                            'ì‹œì¦Œ': selected_season
                        }
                        assignment_data.append(assignment_info)
        else:
            st.warning(f"âš ï¸ {brand} ë¸Œëœë“œì˜ ìµœì í•´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return assignment_data
        
    except Exception as e:
        st.error(f"âŒ {brand} ë¸Œëœë“œ ìµœì ë°°ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def execute_automatic_assignment(selected_month, selected_season, quantities, df):
    """ìë™ ë°°ì • ì‹¤í–‰"""
    st.info("ìë™ ë°°ì •ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.success("ë°°ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def render_manual_assignment_section(selected_month, selected_season):
    """ìˆ˜ë™ ë°°ì • ì„¹ì…˜ ë Œë”ë§"""
    st.markdown("## ğŸ‘¤ ìˆ˜ë™ ë°°ì •")
    st.info("ìˆ˜ë™ ë°°ì • ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")

def analyze_advanced_statistics(execution_df, sales_df, influencer_df, question_lower):
    """ê³ ê¸‰ í†µê³„ ë¶„ì„"""
    results = []
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    if "ìƒê´€ê´€ê³„" in question_lower or "ì—°ê´€ì„±" in question_lower:
        if not execution_df.empty:
            # ìˆ«ìí˜• ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒ
            numeric_cols = execution_df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                correlation_matrix = execution_df[numeric_cols].corr()
                
                # ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
                high_corr = []
                for i in range(len(correlation_matrix.columns)):
                    for j in range(i+1, len(correlation_matrix.columns)):
                        corr_value = correlation_matrix.iloc[i, j]
                        if abs(corr_value) > 0.7:  # ë†’ì€ ìƒê´€ê´€ê³„
                            high_corr.append(f"â€¢ {correlation_matrix.columns[i]} â†” {correlation_matrix.columns[j]}: {corr_value:.3f}")
                
                if high_corr:
                    results.append("**ë†’ì€ ìƒê´€ê´€ê³„ ë°œê²¬:**")
                    results.extend(high_corr)
                else:
                    results.append("ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¶„í¬ ë¶„ì„
    if "ë¶„í¬" in question_lower:
        if not execution_df.empty and 'ë…¸ì¶œìˆ˜' in execution_df.columns:
            exposure_stats = execution_df['ë…¸ì¶œìˆ˜'].describe()
            results.append("**ë…¸ì¶œìˆ˜ ë¶„í¬:**")
            results.append(f"â€¢ í‰ê· : {exposure_stats['mean']:,.0f}")
            results.append(f"â€¢ ì¤‘ì•™ê°’: {exposure_stats['50%']:,.0f}")
            results.append(f"â€¢ í‘œì¤€í¸ì°¨: {exposure_stats['std']:,.0f}")
            results.append(f"â€¢ ìµœì†Ÿê°’: {exposure_stats['min']:,.0f}")
            results.append(f"â€¢ ìµœëŒ“ê°’: {exposure_stats['max']:,.0f}")
    
    # íŒ¨í„´ ë¶„ì„
    if "íŒ¨í„´" in question_lower:
        if not execution_df.empty and 'ë‚ ì§œ' in execution_df.columns:
            execution_df['ë‚ ì§œ'] = pd.to_datetime(execution_df['ë‚ ì§œ'])
            execution_df['ìš”ì¼'] = execution_df['ë‚ ì§œ'].dt.day_name()
            
            # ìš”ì¼ë³„ í‰ê·  ë…¸ì¶œìˆ˜
            daily_pattern = execution_df.groupby('ìš”ì¼')['ë…¸ì¶œìˆ˜'].mean().sort_values(ascending=False)
            results.append("**ìš”ì¼ë³„ í‰ê·  ë…¸ì¶œìˆ˜ íŒ¨í„´:**")
            for day, avg_exposure in daily_pattern.items():
                results.append(f"â€¢ {day}: {avg_exposure:,.0f}")
    
    return "\n".join(results) if results else "ê³ ê¸‰ í†µê³„ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

def analyze_predictions(execution_df, sales_df, question_lower):
    """ì˜ˆì¸¡ ë¶„ì„"""
    results = []
    
    # ì§‘í–‰ ë°ì´í„° ì˜ˆì¸¡
    if not execution_df.empty and 'ë‚ ì§œ' in execution_df.columns:
        execution_df['ë‚ ì§œ'] = pd.to_datetime(execution_df['ë‚ ì§œ'])
        daily_metrics = execution_df.groupby('ë‚ ì§œ').agg({
            'ë…¸ì¶œìˆ˜': 'sum',
            'ì¢‹ì•„ìš”': 'sum',
            'ëŒ“ê¸€ìˆ˜': 'sum',
            'ì¡°íšŒìˆ˜': 'sum'
        }).reset_index()
        
        if len(daily_metrics) >= 7:
            # ìµœê·¼ 7ì¼ í‰ê· ìœ¼ë¡œ ë‹¤ìŒ ì£¼ ì˜ˆì¸¡
            recent_7days = daily_metrics.tail(7)
            avg_exposure = recent_7days['ë…¸ì¶œìˆ˜'].mean()
            avg_likes = recent_7days['ì¢‹ì•„ìš”'].mean()
            avg_comments = recent_7days['ëŒ“ê¸€ìˆ˜'].mean()
            avg_views = recent_7days['ì¡°íšŒìˆ˜'].mean()
            
            results.append("**ë‹¤ìŒ ì£¼ ì˜ˆì¸¡ (ìµœê·¼ 7ì¼ í‰ê·  ê¸°ì¤€):**")
            results.append(f"â€¢ ì˜ˆìƒ ë…¸ì¶œìˆ˜: {avg_exposure:,.0f}")
            results.append(f"â€¢ ì˜ˆìƒ ì¢‹ì•„ìš”: {avg_likes:,.0f}")
            results.append(f"â€¢ ì˜ˆìƒ ëŒ“ê¸€ìˆ˜: {avg_comments:,.0f}")
            results.append(f"â€¢ ì˜ˆìƒ ì¡°íšŒìˆ˜: {avg_views:,.0f}")
    
    # ë§¤ì¶œ ë°ì´í„° ì˜ˆì¸¡
    if not sales_df.empty and 'DT' in sales_df.columns:
        sales_df['DT'] = pd.to_datetime(sales_df['DT'])
        daily_sales = sales_df.groupby('DT')['SALE_AMT_TY'].sum().reset_index()
        
        if len(daily_sales) >= 7:
            recent_sales = daily_sales.tail(7)
            avg_sales = recent_sales['SALE_AMT_TY'].mean()
            results.append(f"â€¢ ì˜ˆìƒ ì¼ì¼ ë§¤ì¶œ: {avg_sales:,.0f}ì›")
    
    return "\n".join(results) if results else "ì˜ˆì¸¡ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

def analyze_insights(execution_df, sales_df, influencer_df, question_lower):
    """ì¸ì‚¬ì´íŠ¸ ë¶„ì„"""
    results = []
    
    # ì§‘í–‰ ë°ì´í„° ì¸ì‚¬ì´íŠ¸
    if not execution_df.empty:
        # ìµœê³  ì„±ê³¼ ì¸í”Œë£¨ì–¸ì„œ
        if 'ì¸í”Œë£¨ì–¸ì„œ' in execution_df.columns and 'ë…¸ì¶œìˆ˜' in execution_df.columns:
            top_influencer = execution_df.loc[execution_df['ë…¸ì¶œìˆ˜'].idxmax()]
            results.append(f"**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
            results.append(f"â€¢ ìµœê³  ì„±ê³¼ ì¸í”Œë£¨ì–¸ì„œ: {top_influencer['ì¸í”Œë£¨ì–¸ì„œ']} (ë…¸ì¶œìˆ˜: {top_influencer['ë…¸ì¶œìˆ˜']:,})")
        
        # íš¨ìœ¨ì„± ë¶„ì„
        if 'ì¢‹ì•„ìš”' in execution_df.columns and 'ëŒ“ê¸€ìˆ˜' in execution_df.columns and 'ë…¸ì¶œìˆ˜' in execution_df.columns:
            execution_df['engagement_rate'] = (execution_df['ì¢‹ì•„ìš”'] + execution_df['ëŒ“ê¸€ìˆ˜']) / execution_df['ë…¸ì¶œìˆ˜'] * 100
            avg_engagement = execution_df['engagement_rate'].mean()
            results.append(f"â€¢ í‰ê·  ì°¸ì—¬ìœ¨: {avg_engagement:.2f}%")
        
        # ë¸Œëœë“œë³„ ì„±ê³¼ ì°¨ì´
        if 'ë¸Œëœë“œ' in execution_df.columns:
            brand_performance = execution_df.groupby('ë¸Œëœë“œ')['ë…¸ì¶œìˆ˜'].sum().sort_values(ascending=False)
            results.append("**ë¸Œëœë“œë³„ ì„±ê³¼ ìˆœìœ„:**")
            for i, (brand, exposure) in enumerate(brand_performance.items(), 1):
                results.append(f"â€¢ {i}ìœ„ {brand}: {exposure:,}")
    
    # ë§¤ì¶œ ë°ì´í„° ì¸ì‚¬ì´íŠ¸
    if not sales_df.empty and 'BRD_CD' in sales_df.columns:
        brand_sales = sales_df.groupby('BRD_CD')['SALE_AMT_TY'].sum().sort_values(ascending=False)
        brand_mapping = {'M': 'MLB', 'X': 'DX', 'V': 'DV', 'ST': 'ST'}
        
        results.append("**ë¸Œëœë“œë³„ ë§¤ì¶œ ìˆœìœ„:**")
        for i, (brand_code, sales) in enumerate(brand_sales.items(), 1):
            brand_name = brand_mapping.get(brand_code, brand_code)
            results.append(f"â€¢ {i}ìœ„ {brand_name}: {sales:,.0f}ì›")
    
    return "\n".join(results) if results else "ì¸ì‚¬ì´íŠ¸ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

if __name__ == "__main__":
    main()
